{"meta":{"title":"星辰大海","subtitle":"","description":"","author":"John Doe","url":"http://example.com","root":"/"},"pages":[],"posts":[{"title":"SpringBoot注解整理笔记","slug":"SpringBoot注解笔记","date":"2021-01-18T04:12:15.000Z","updated":"2021-01-18T06:59:50.137Z","comments":true,"path":"2021/01/18/SpringBoot注解笔记/","link":"","permalink":"http://example.com/2021/01/18/SpringBoot%E6%B3%A8%E8%A7%A3%E7%AC%94%E8%AE%B0/","excerpt":"","text":"一、注解(annotations)列表1.@SpringBootApplication 包含了@ComponentScan、@Configuration和@EnableAutoConfiguration注解。其中@ComponentScan让Spring Boot扫描到Configuration类并把它加入到程序上下文。 2.@ComponentScan 组件扫描，可自动发现和装配一下Bean 3.@Configuration 等同于Spring的XML配置文件；使用Java代码可以检查类型安全 4.@EnableAutoConfiguration 自动配置 5.@RestController该注解是@Controller和@ResponseBody的合集，表示这是个控制器Bean，并且是将函数的返回值直接填入HTPP响应体中，是REST风格的控制器 6.@Autowired自动导入 7.@PathVariable获取参数 8.@JsonBackReference (未使用过)解决嵌套外链问题 9.@RepositoryRestResourcepublic (未使用过)配合spring-boot-starter-data-rest使用 二、注解(annotations)详解1.@SpringBootApplication申明让Spring Boot自动给程序进行必要的配置，这个配置等同于：@Configuration ，@EnableAutoConfiguration 和 @ComponentScan 三个配置。 12345678910import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplication// same as @Configuration @EnableAutoConfiguration @ComponentScanpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; 2.@ResponseBody表示该方法的返回值结果直接写入HTTP Response Body中，一般在异步获取数据时使用，用于构建RESTful的api。 在使用 @RequestMapping 后，返回值通常解析为跳转路径，加上@ResponseBody后返回结果是不会被解析为跳转路径，而是直接写入HTTP Response Body中。 比如异步获取json数据，加上@ResponseBody后，会直接返回json数据。 该注解一般会配合@RequestMapping一起使用 示例代码： 12345@RequestMapping(“/test”)@ResponseBodypublic String test()&#123; return ”ok”;&#125; 3.@Controller 用于定义控制器类，在spring项目中由控制器负责将用户发来的URL请求转发到对应的服务接口（service层） 一般这个注解在类中，通常方法需要配合注解 @RequestMapping。 实例代码： 123456789101112131415@Controller@RequestMapping(&quot;/demoInfo&quot;)publicclass DemoController &#123; @Autowired private DemoInfoService demoInfoService; @RequestMapping(&quot;/hello&quot;) public String hello(Map map)&#123; System.out.println(&quot;DemoController.hello()&quot;); map.put(&quot;hello&quot;,&quot;from TemplateController.helloHtml&quot;); // 会使用hello.html或者hello.ftl模板进行渲染显示. return&quot;/hello&quot;; &#125;&#125; 4.@RestController 用于标注控制层组件(如struts中的action)，@ResponseBody和@Controller的合集。 实例代码： 123456789101112import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@RestController@RequestMapping(“/demoInfo2”)publicclass DemoController2 &#123; @RequestMapping(&quot;/test&quot;) public String test()&#123; return&quot;ok&quot;; &#125;&#125; 5.@RequestMapping 提供路由信息，负责URL到Controller中的具体函数的映射。 6.@EnableAutoConfiguration Spring Boot自动配置（auto-configuration）：尝试根据你添加的jar依赖自动配置你的Spring应用。 7.@ComponentScan 表示将该类自动发现扫描组件 8.@Configuration 相当于传统的xml配置文件，如果有些第三方库需要用到xml文件，建议仍然通过@Configuration类作为项目的配置主类——可以使用@ImportResource注解加载xml配置文件。 9.@Import 用来导入其他配置类 10.@ImportResource 用来加载xml配置文件。 11.@Autowired 自动导入依赖的bean。byType方式。把配置好的Bean拿来用，完成属性、方法的组装，它可以对类成员变量、方法及构造函数进行标注，完成自动装配的工作。当加上（required=false）时，就算找不到bean也不报错。 12.@Service 一般用于修饰service层的组件 13.@Repository 使用@Repository注解可以确保DAO或者repositories提供异常转译，这个注解修饰的DAO或者repositories类会被ComponetScan发现并配置，同时也不需要为它们提供XML配置项。 14.@Bean 用@Bean标注方法等价于XML中配置的bean。 相当于XML中的,放在方法的上面，而不是类，意思是产生一个bean,并交给spring管理 15.@Value 注入Spring boot application.properties配置的属性的值。 示例代码： 12@Value(value = “#&#123;message&#125;”)private String message; 16.@Inject 等价于默认的@Autowired，只是没有required属性； 17.@Component 泛指组件，当组件不好归类的时候，我们可以使用这个注解进行标注。 18.@Qualifier 当有多个同一类型的Bean时，可以用@Qualifier(“name”)来指定。与@Autowired配合使用。@Qualifier限定描述符除了能根据名字进行注入，但能进行更细粒度的控制如何选择候选者，具体使用方式如下： 123@Autowired@Qualifier(value = “demoInfoService”)private DemoInfoService demoInfoService; 19.@Resource(name=”name”,type=”type”) 没有括号内内容的话，默认byName。与@Autowired干类似的事。 三、JPA注解1、@Entity：@Table(name=”“)表明这是一个实体类。一般用于jpa这两个注解一般一块使用，但是如果表名和实体类名相同的话，@Table可以省略。 2、@MappedSuperClass用在确定是父类的entity上。父类的属性子类可以继承。 3、@NoRepositoryBean一般用作父类的repository，有这个注解，Spring不会去实例化该repository。 4、@Column如果字段名与列名相同，则可以省略。 5、@Id表示该属性为主键。 6@GeneratedValue(strategy=GenerationType.SEQUENCE,generator= “repair_seq”)表示主键生成策略是sequence（可以为Auto、IDENTITY、native等，Auto表示可在多个数据库间切换），指定sequence的名字是repair_seq。 7、@SequenceGeneretor(name = “repair_seq”, sequenceName = “seq_repair”, allocationSize = 1)name为sequence的名称，以便使用，sequenceName为数据库的sequence名称，两个名称可以一致。 8、@Transient表示该属性并非一个到数据库表的字段的映射,ORM框架将忽略该属性。 如果一个属性并非数据库表的字段映射,就务必将其标示为@Transient,否则,ORM框架默认其注解为@Basic。 9、@Basic(fetch=FetchType.LAZY)标记可以指定实体属性的加载方式。 10、@JsonIgnore作用是json序列化时将Java bean中的一些属性忽略掉,序列化和反序列化都受影响。 11、@JoinColumn（name=”loginId”）一对一：本表中指向另一个表的外键。一对多：另一个表指向本表的外键。 12、@OneToOne、@OneToMany、@ManyToOne对应hibernate配置文件中的一对一，一对多，多对一。 四、SpringMVC相关注解1.@RequestMapping@RequestMapping(“/path”)表示该控制器处理所有“/path”的UR L请求。 RequestMapping是一个用来处理请求地址映射的注解，可用于类或方法上。 用于类上，表示类中的所有响应请求的方法都是以该地址作为父路径。该注解有六个属性： params:指定request中必须包含某些参数值是，才让该方法处理。 headers:指定request中必须包含某些指定的header值，才能让该方法处理请求。 value:指定请求的实际地址，指定的地址可以是URI Template 模式 method:指定请求的method类型， GET、POST、PUT、DELETE等 consumes:指定处理请求的提交内容类型（Content-Type），如application/json,text/html; produces:指定返回的内容类型，仅当request请求头中的(Accept)类型中包含该指定类型才返回。 2.@RequestParam 用在方法的参数前面。 3. @PathVariable 路径变量。如： 1234RequestMapping(“user/get/&#123;macAddress&#125;”)public String getByMacAddress(@PathVariable String macAddress)&#123; //do something;&#125; 五、全局异常处理@ControllerAdvice：包含@Component。可以被扫描到。统一处理异常。 @ExceptionHandler（Exception.class）：用在方法上面表示遇到这个异常就执行以下方法。","categories":[],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://example.com/tags/SpringBoot/"}]},{"title":"什么是MySQL索引，为什么要有索引？（未完）","slug":"什么是MySQL索引，为什么要有索引？","date":"2021-01-18T03:19:00.000Z","updated":"2021-01-18T07:46:52.448Z","comments":true,"path":"2021/01/18/什么是MySQL索引，为什么要有索引？/","link":"","permalink":"http://example.com/2021/01/18/%E4%BB%80%E4%B9%88%E6%98%AFMySQL%E7%B4%A2%E5%BC%95%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E6%9C%89%E7%B4%A2%E5%BC%95%EF%BC%9F/","excerpt":"","text":"一、什么是索引？索引就好比字典的目录一样，我们通常都会先去目录查找关键偏旁或者字母再去查找，要比直接翻查字典查询要快很多 二、为什么要有索引？然而我们在使用mysql数据库的时候也像字典一样有索引的情况下去查询，肯定速度要快很多 2.1问题1.mysql数据存储在什么地方？磁盘 2.查询数据慢，一般卡在哪？磁盘IO 3.索引存储在哪？ 磁盘，查询数据的时候会优先将索引加载到内存中 4.索引在存储的时候，需要什么信息？需要存储什么字段值？key:实际数据行中存储的值 文件地址 offset:偏移量 三、mysql的索引数据结构3.1哈希表 HashMap数据加链表的结构，不适合作为索引的原因： 1.哈希冲突会造成数据散列不均匀，会产生大量的线性查询，比较浪费时间 2.不支持范围查询，当进行范围查询的时候，必须挨个遍历 3.对于内存空间的要求比较高 优点： 如果是等值查询，非常快","categories":[],"tags":[]},{"title":"springcloud笔记","slug":"springcloud笔记","date":"2021-01-17T09:54:27.000Z","updated":"2021-01-18T04:57:43.727Z","comments":true,"path":"2021/01/17/springcloud笔记/","link":"","permalink":"http://example.com/2021/01/17/springcloud%E7%AC%94%E8%AE%B0/","excerpt":"","text":"1、前言1.1、回顾回顾之前的知识 JavaSE 数据库 前端 Servlet Http Mybatis Spring SpringMVC SpringBoot Dubbo、Zookeeper、分布式基础 Maven、Git Ajax、Json … 串一下自己会的东西 数据库 Mybatis Spring SpringMVC SpringBoot Dubbo、Zookeeper、分布式基础 Maven、Git Ajax、Json 这个阶段该如何学习 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051三层架构 + MVC框架： Spring IOC AOP SpringBoot：新一代的javaEE开发标准，自动装配 模块化 all in one 模块化的开发&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;all in one 代码没有变化 微服务的四个核心问题？ 1.服务很多，客户端怎么访问？ 2.这么多服务？服务之间如何通信？ 3.这么多服务？如何治理？ 4.服务挂了怎么办？ 解决方案： Spring Cloud 生态！ SprintBoot 1.Spring Cloud NetFlix 一站式解决方案 api网关：zuul组件 通信：Feign ---- HttpClient ---- Http通信方式,同步,阻塞 服务注册和发现：Eureka 熔断机制：Hystrix ...... 2. Apache Dubbo Zookeeper：半自动！需要整合别人的 API网关：没有,找第三方组件(比如整合zull组件),或者自己实现 通信：Dubbo 是一个基于Java的高性能的RPC通信框架(性能比Feign强大) 服务注册和发现：Zookeeper 熔断机制：没有,需要借助Hystrix Dubbo这个方案并不完善 3. Spring Cloud Alibaba：目前最新的一站式解决方案！可解决上述4个核心问题,更简单 API网关： 通信： 服务注册和发现： 熔断机制： 新概念：服务网格~ Server Mesh istio 万变不离其宗4个问题： 1. API网关 2. HTTP,RPC通信 3. 注册和发现 4. 熔断机制 网络不可靠！ 1.2 、常见面试题1.1、 什么是微服务？ 1.2 、微服务之间是如何独立通讯的？ 1.3 、SpringCloud 和 Dubbo有那些区别？ 1.4 、SpringBoot 和 SpringCloud，请谈谈你对他们的理解 1.5 、什么是服务熔断？什么是服务降级？ 1.6 、微服务的优缺点分别是什么？说下你在项目开发中遇到的坑 1.7 、你所知道的微服务技术栈有哪些？列举一二 1.8、 Eureka和Zookeeper都可以提供服务注册与发现的功能，请说说两者的区别 2. 微服务概述2.1 什么是微服务？什么是微服务？微服务(Microservice Architecture) 是近几年流行的一种架构思想，关于它的概念很难一言以蔽之。 究竟什么是微服务呢？我们在此引用ThoughtWorks 公司的首席科学家 Martin Fowler 于2014年提出的一段话： 原文：https://martinfowler.com/articles/microservices.html 汉化：https://www.cnblogs.com/liuning8023/p/4493156.html 就目前而言，对于微服务，业界并没有一个统一的，标准的定义。 但通常而言，微服务架构是一种架构模式，或者说是一种架构风。格，它体长将单一的应用程序划分成一组小的服务，每个服务运行在其独立的自己的进程内，服务之间互相协调，互相配置，为用户提供最终价值，服务之间采用轻量级的通信机制(HTTP)互相沟通，每个服务都围绕着具体的业务进行构建，并且能狗被独立的部署到生产环境中，另外，应尽量避免统一的，集中式的服务管理机制，对具体的一个服务而言，应该根据业务上下文，选择合适的语言，工具(Maven)对其进行构建，可以有一个非常轻量级的集中式管理来协调这些服务，可以使用不同的语言来编写服务，也可以使用不同的数据存储。 再来从技术维度角度理解下： 微服务化的核心就是将传统的一站式应用，根据业务拆分成一个一个的服务，彻底地去耦合，每一个微服务提供单个业务功能的服务，一个服务做一件事情，从技术角度看就是一种小而独立的处理过程，类似进程的概念，能够自行单独启动或销毁，拥有自己独立的数据库。 2.2 微服务与微服务架构微服务 强调的是服务的大小，它关注的是某一个点，是具体解决某一个问题/提供落地对应服务的一个服务应用，狭义的看，可以看作是IDEA中的一个个微服务工程，或者Moudel。 12IDEA 工具里面使用Maven开发的一个个独立的小Moudel，它具体是使用SpringBoot开发的一个小模块，专业的事情交给专业的模块来做，一个模块就做着一件事情。强调的是一个个的个体，每个个体完成一个具体的任务或者功能。 微服务架构 一种新的架构形式，Martin Fowler 于2014年提出。 微服务架构是一种架构模式，它体长将单一应用程序划分成一组小的服务，服务之间相互协调，互相配合，为用户提供最终价值。每个服务运行在其独立的进程中，服务与服务之间采用轻量级的通信机制**(如HTTP)互相协作，每个服务都围绕着具体的业务进行构建，并且能够被独立的部署到生产环境中，另外，应尽量避免统一的，集中式的服务管理机制，对具体的一个服务而言，应根据业务上下文，选择合适的语言、工具(如Maven)**对其进行构建。 2.3 微服务优缺点优点 单一职责原则； 每个服务足够内聚，足够小，代码容易理解，这样能聚焦一个指定的业务功能或业务需求； 开发简单，开发效率高，一个服务可能就是专一的只干一件事； 微服务能够被小团队单独开发，这个团队只需2-5个开发人员组成； 微服务是松耦合的，是有功能意义的服务，无论是在开发阶段或部署阶段都是独立的； 微服务能使用不同的语言开发； 易于和第三方集成，微服务允许容易且灵活的方式集成自动部署，通过持续集成工具，如jenkins，Hudson，bamboo； 微服务易于被一个开发人员理解，修改和维护，这样小团队能够更关注自己的工作成果，无需通过合作才能体现价值； 微服务允许利用和融合最新技术； 微服务只是业务逻辑的代码，不会和HTML，CSS，或其他的界面混合; 每个微服务都有自己的存储能力，可以有自己的数据库，也可以有统一的数据库； 缺点 开发人员要处理分布式系统的复杂性； 多服务运维难度，随着服务的增加，运维的压力也在增大； 系统部署依赖问题； 服务间通信成本问题； 数据一致性问题； 系统集成测试问题； 性能和监控问题； 2.4 微服务技术栈有那些？ 微服务技术条目 落地技术 服务开发 SpringBoot、Spring、SpringMVC等 服务配置与管理 Netfix公司的Archaius、阿里的Diamond等 服务注册与发现 Eureka、Consul、Zookeeper等 服务调用 Rest、PRC、gRPC 服务熔断器 Hystrix、Envoy等 负载均衡 Ribbon、Nginx等 服务接口调用(客户端调用服务的简化工具) Fegin等 消息队列 Kafka、RabbitMQ、ActiveMQ等 服务配置中心管理 SpringCloudConfig、Chef等 服务路由(API网关) Zuul等 服务监控 Zabbix、Nagios、Metrics、Specatator等 全链路追踪 Zipkin、Brave、Dapper等 数据流操作开发包 SpringCloud Stream(封装与Redis，Rabbit，Kafka等发送接收消息) 时间消息总栈 SpringCloud Bus 服务部署 Docker、OpenStack、Kubernetes等 2.5 为什么选择SpringCloud作为微服务架构 选型依据 整体解决方案和框架成熟度 社区热度 可维护性 学习曲线 当前各大IT公司用的微服务架构有那些？ 阿里：dubbo+HFS 京东：JFS 新浪：Motan 当当网：DubboX … 各微服务框架对比 功能点/服务框架 Netflix/SpringCloud Motan gRPC Thrift Dubbo/DubboX 功能定位 完整的微服务框架 RPC框架，但整合了ZK或Consul，实现集群环境的基本服务注册发现 RPC框架 RPC框架 服务框架 支持Rest 是，Ribbon支持多种可拔插的序列号选择 否 否 否 否 支持RPC 否 是(Hession2) 是 是 是 支持多语言 是(Rest形式) 否 是 是 否 负载均衡 是(服务端zuul+客户端Ribbon)，zuul-服务，动态路由，云端负载均衡Eureka（针对中间层服务器） 是(客户端) 否 否 是(客户端) 配置服务 Netfix Archaius，Spring Cloud Config Server 集中配置 是(Zookeeper提供) 否 否 否 服务调用链监控 是(zuul)，zuul提供边缘服务，API网关 否 否 否 否 高可用/容错 是(服务端Hystrix+客户端Ribbon) 是(客户端) 否 否 是(客户端) 典型应用案例 Netflix Sina Google Facebook 社区活跃程度 高 一般 高 一般 2017年后重新开始维护，之前中断了5年 学习难度 中等 低 高 高 低 文档丰富程度 高 一般 一般 一般 高 其他 Spring Cloud Bus为我们的应用程序带来了更多管理端点 支持降级 Netflix内部在开发集成gRPC IDL定义 实践的公司比较多 3. SpringCloud入门概述3.1 SpringCloud是什么？Spring官网：https://spring.io/ 原文 Spring Cloud provides tools for developers to quickly build some of the common patterns in distributed systems (e.g. configuration management, service discovery, circuit breakers, intelligent routing, micro-proxy, control bus, one-time tokens, global locks, leadership election, distributed sessions, cluster state). Coordination of distributed systems leads to boiler plate patterns, and using Spring Cloud developers can quickly stand up services and applications that implement those patterns. They will work well in any distributed environment, including the developer’s own laptop, bare metal data centres, and managed platforms such as Cloud Foundry. 翻译：SpringCloud,基于SpringBoot提供了一套微服务解决方案，包括服务注册与发现，配置中心，全链路监控，服务网关，负载均衡，熔断器等组件，除了基于NetFlix的开源组件做高度抽象封装之外，还有一些选型中立的开源组件。 SpringCloud利用SpringBoot的开发便利性，巧妙地简化了分布式系统基础设施的开发，SpringCloud为开发人员提供了快速构建分布式系统的一些工具，包括配置管理，服务发现，断路器，路由，微代理，事件总线，全局锁，决策竞选，分布式会话等等，他们都可以用SpringBoot的开发风格做到一键启动和部署。 SpringBoot并没有重复造轮子，它只是将目前各家公司开发的比较成熟，经得起实际考研的服务框架组合起来，通过SpringBoot风格进行再封装，屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂，易部署和易维护的分布式系统开发工具包 SpringCloud是分布式微服务架构下的一站式解决方案，是各个微服务架构落地技术的集合体，俗称微服务全家桶。 3.2 SpringCloud和SpringBoot的关系 SpringBoot专注于开苏方便的开发单个个体微服务； SpringCloud是关注全局的微服务协调整理治理框架，它将SpringBoot开发的一个个单体微服务，整合并管理起来，为各个微服务之间提供：配置管理、服务发现、断路器、路由、为代理、事件总栈、全局锁、决策竞选、分布式会话等等集成服务； SpringBoot可以离开SpringCloud独立使用，开发项目，但SpringCloud离不开SpringBoot，属于依赖关系； SpringBoot专注于快速、方便的开发单个个体微服务，SpringCloud关注全局的服务治理框架； 3.3 Dubbo 和 SpringCloud技术选型1. 分布式+服务治理Dubbo 目前成熟的互联网架构，应用服务化拆分+消息中间件 2. Dubbo 和 SpringCloud对比 可以看一下社区活跃度： https://github.com/dubbo https://github.com/spring-cloud 对比结果： Dubbo SpringCloud 服务注册中心 Zookeeper Spring Cloud Netfilx Eureka 服务调用方式 RPC REST API 服务监控 Dubbo-monitor Spring Boot Admin 断路器 不完善 Spring Cloud Netfilx Hystrix 服务网关 无 Spring Cloud Netfilx Zuul 分布式配置 无 Spring Cloud Config 服务跟踪 无 Spring Cloud Sleuth 消息总栈 无 Spring Cloud Bus 数据流 无 Spring Cloud Stream 批量任务 无 Spring Cloud Task 最大区别：Spring Cloud 抛弃了Dubbo的RPC通信，采用的是基于HTTP的REST方式 严格来说，这两种方式各有优劣。虽然从一定程度上来说，后者牺牲了服务调用的性能，但也避免了上面提到的原生RPC带来的问题。而且REST相比RPC更为灵活，服务提供方和调用方的依赖只依靠一纸契约，不存在代码级别的强依赖，这个优点在当下强调快速演化的微服务环境下，显得更加合适。 品牌机和组装机的区别 很明显，Spring Cloud的功能比DUBBO更加强大，涵盖面更广，而且作为Spring的拳头项目，它也能够与SpringFramework、Spring Boot、Spring Data、Spring Batch等其他Spring项目完美融合，这些对于微服务而言是至关重要的。使用Dubbo构建的微服务架构就像组装电脑，各环节我们的选择自由度很高，但是最终结果很有可能因为一条内存质量不行就点不亮了，总是让人不怎么放心，但是如果你是一名高手，那这些都不是问题;而SpringCloud就像品牌机，在Spring Source的整合下，做了大量的兼容性测试，保证了机器拥有更高的稳定性，但是如果要在使用非原装组件外的东西，就需要对其基础有足够的了解。 社区支持与更新力度的区别 最为重要的是，DUBBO停止了5年左右的更新，虽然2017.7重启了。对于技术发展的新需求，需要由开发者自行拓展升级（比如当当网弄出了DubboX)，这对于很多想要采用微服务架构的中小软件组织，显然是不太合适的，中小公司没有这么强大的技术能力去修改Dubbo源码+周边的一整套解决方案，并不是每一个公司都有阿里的大牛+真实的线上生产环境测试过。 设计模式+微服务拆分思想：不一定善于表达，软实力 总结： 二者解决的问题域不一样：Dubbo的定位是一款RPC框架，而SpringCloud的目标是微服务架构下的一站式解决方案。 3.4 SpringCloud能干嘛？ Distributed/versioned configuration 分布式/版本控制配置 Service registration and discovery 服务注册与发现 Routing 路由 Service-to-service calls 服务到服务的调用 Load balancing 负载均衡配置 Circuit Breakers 断路器 Distributed messaging 分布式消息管理 … 3.5 SpringCloud下载官网：http://projects.spring.io/spring-cloud/ 版本号有点特别： spring cloud是一个由众多独立子项目组成的大型综合项目，每个子项目有不同的发行节奏，都维护着自己的发布版木号。spring cloud通过一个资源清单BOM(Bil1 of Materials）来管理每个版木的子项目清单。为避免与子项目的发布号混淆，所以没有采用版本号的方式，而是通过命名的方式。 SpringCloud没有采用数字编号的方式命名版本号，而是采用了伦敦地铁站的名称，同时根据字母表的顺序来对应版本时间顺序，比如最早的Realse版本：Angel，第二个Realse版本：Brixton，然后是Camden、Dalston、Edgware，目前最新的是Hoxton SR4 CURRENT GA通用稳定版。 自学参考书： SpringCloud Netflix 中文文档：https://springcloud.cc/spring-cloud-netflix.html SpringCloud 中文API文档(官方文档翻译版)：https://springcloud.cc/spring-cloud-dalston.html SpringCloud中国社区：http://springcloud.cn/ SpringCloud中文网：https://springcloud.cc 4. SpringCloud Rest学习环境搭建：服务提供者4.1 介绍 我们会使用一个Dept部门模块做一个微服务通用案例Consumer消费者(Client)通过REST调用Provider提供者(Server)提供的服务。 回顾Spring，SpringMVC，Mybatis等以往学习的知识。 Maven的分包分模块架构复习。 123456789101112一个简单的Maven模块结构是这样的：-- app-parent: 一个父项目(app-parent)聚合了很多子项目(app-util\\app-dao\\app-web...) |-- pom.xml | |-- app-core ||---- pom.xml | |-- app-web ||---- pom.xml ......1234567891011 一个父工程带着多个Moudule子模块 MicroServiceCloud父工程(Project)下初次带着3个子模块(Module) microservicecloud-api 【封装的整体entity/接口/公共配置等】 microservicecloud-consumer-dept-80 【服务提供者】 microservicecloud-provider-dept-8001 【服务消费者】 4.2 SpringCloud版本选择大版本说明 SpringBoot SpringCloud 关系 1.2.x Angel版本(天使) 兼容SpringBoot1.2x 1.3.x Brixton版本(布里克斯顿) 兼容SpringBoot1.3x，也兼容SpringBoot1.4x 1.4.x Camden版本(卡姆登) 兼容SpringBoot1.4x，也兼容SpringBoot1.5x 1.5.x Dalston版本(多尔斯顿) 兼容SpringBoot1.5x，不兼容SpringBoot2.0x 1.5.x Edgware版本(埃奇韦尔) 兼容SpringBoot1.5x，不兼容SpringBoot2.0x 2.0.x Finchley版本(芬奇利) 兼容SpringBoot2.0x，不兼容SpringBoot1.5x 2.1.x Greenwich版本(格林威治) 实际开发版本关系 spring-boot-starter-parent spring-cloud-dependencles 版本号 发布日期 版本号 发布日期 1.5.2.RELEASE 2017-03 Dalston.RC1 2017-x 1.5.9.RELEASE 2017-11 Edgware.RELEASE 2017-11 1.5.16.RELEASE 2018-04 Edgware.SR5 2018-10 1.5.20.RELEASE 2018-09 Edgware.SR5 2018-10 2.0.2.RELEASE 2018-05 Fomchiey.BULD-SNAPSHOT 2018-x 2.0.6.RELEASE 2018-10 Fomchiey-SR2 2018-10 2.1.4.RELEASE 2019-04 Greenwich.SR1 2019-03 使用后两个 4.3 创建工程1、创建父工程 新建父工程项目springcloud，切记Packageing是pom模式 主要是定义POM文件，将后续各个子模块公用的jar包等统一提取出来，类似一个抽象父类 父工程pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;nuc.ss&lt;/groupId&gt; &lt;artifactId&gt;springcloud&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;modules&gt; &lt;/modules&gt; &lt;!--打包方式 pom--&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;lombok.version&gt;1.18.12&lt;/lombok.version&gt; &lt;log4j.version&gt;1.2.17&lt;/log4j.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--springcloud的依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Hoxton.SR8&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--springboot的依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.3.1.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--数据库--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.20&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.0.9&lt;/version&gt; &lt;/dependency&gt; &lt;!--springboot启动器--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.3&lt;/version&gt; &lt;/dependency&gt; &lt;!--日志测试~--&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;$&#123;junit.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;$&#123;log4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--lombok--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;$&#123;lombok.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.yml&lt;/include&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.yml&lt;/include&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt;&lt;/project&gt; 2、创建子模块springcloud-api pom配置： 123456789101112131415161718192021&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud&lt;/artifactId&gt; &lt;groupId&gt;nuc.ss&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;sprintcloud-api&lt;/artifactId&gt; &lt;!--当前的module自己需要的依赖，如果父依赖中已经配置了版本，这里就不用写了--&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 数据库的创建 实体类的编写 1234567891011121314151617181920212223242526272829package nuc.ss.springcloud.pojo; import lombok.Data;import lombok.NoArgsConstructor;import lombok.experimental.Accessors;import java.io.Serializable; @Data@NoArgsConstructor@Accessors(chain = true)public class Dept implements Serializable &#123;//实体类 orm 类表关系映射 private long deptno;//主键 private String dname; //这个数据存在那个数据库的字段，微服务，一个服务对应一个数据库，同一个信息可能存在不同的数据库 private String db_source; public Dept(String dname) &#123; this.dname = dname; &#125; /* * 链式写法： * Dept dept = new Dept(); * * dept.setDeptNo(11).setDname(&#x27;ssss&#x27;).setDb_source(&#x27;db01&#x27;) * */&#125; 3、子模块springcloud-provider-dept-8081服务的提供者的编写 ​ pom配置： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud&lt;/artifactId&gt; &lt;groupId&gt;nuc.ss&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;springcloud-provider-dept-8081&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--我们需要拿到实体类，所以要配置api module--&gt; &lt;dependency&gt; &lt;groupId&gt;nuc.ss&lt;/groupId&gt; &lt;artifactId&gt;springcloud-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--junit--&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--test--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--jetty--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--热部署工具--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; application.yml的配置 12345678910111213141516171819server: port: 8081# mybatis的配置mybatis: type-aliases-package: nuc.ss.springcloud.pojo config-location: classpath:mybatis/mybatis-config.xml mapper-locations: classpath:mybatis/mapper/*.xml# spring的配置spring: application: name: springcloud-provider-dept datasource: type: com.alibaba.druid.pool.DruidDataSource #数据库 driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql//localhost:3306/db01?useUnicode=true&amp;characterEncoding=utf-8 username: root password: admin mybatis-config.xml的配置 1234567891011&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt; &lt;settings&gt; &lt;setting name=&quot;cacheEnabled&quot; value=&quot;true&quot;/&gt; &lt;/settings&gt;&lt;/configuration&gt; DeptMapper.xml的编写 12345678910111213141516171819202122&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;nuc.ss.springcloud.dao.DeptDao&quot;&gt; &lt;insert id=&quot;addDept&quot; parameterType=&quot;Dept&quot;&gt; insert into dept (dname,db_source) values (#&#123;dname&#125;,DATABASE()) &lt;/insert&gt; &lt;select id=&quot;queryById&quot; resultType=&quot;Dept&quot; parameterType=&quot;Long&quot;&gt; select * from dept where deptno = #&#123;id&#125; &lt;/select&gt; &lt;select id=&quot;queryAll&quot; resultType=&quot;Dept&quot;&gt; select * from dept &lt;/select&gt;&lt;/mapper&gt; 接口DeptController的编写 12345678910111213141516171819202122//视图Restful服务@RestControllerpublic class DeptController &#123; @Autowired DeptService deptService; @PostMapping(&quot;/dept/add&quot;) public boolean addDept(Dept dept) &#123; return deptService.addDept(dept); &#125; @GetMapping(&quot;/dept/get/&#123;id&#125;&quot;) public Dept get(@PathVariable(&quot;id&quot;) Long id) &#123; return deptService.queryById(id); &#125; @GetMapping(&quot;/dept/list&quot;) public List&lt;Dept&gt; queryAll() &#123; return deptService.queryAll(); &#125;&#125; 整体目录结构 4、子模块springcloud-consumer-dept-80的编写 pom依赖编写 123456789101112131415161718192021222324252627&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud&lt;/artifactId&gt; &lt;groupId&gt;nuc.ss&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;springcloud-consumer-dept-80&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;nuc.ss&lt;/groupId&gt; &lt;artifactId&gt;springcloud-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; application.yml 123server: port: 80 将RestTemplate注册到spring中：ConfigBean.java 123456789@Configurationpublic class ConfigBean &#123; //Cofiguration -- spring applicationContext.xml @Bean public RestTemplate getRestTemplate() &#123; return new RestTemplate(); &#125;&#125; DeptConsumerController.java 123456789101112131415161718192021222324252627@RestControllerpublic class DeptConsumerController &#123; // 理解：消费者，不应该有service层 // RestTemplate ... 供我们直接调用就可以了！注解到spring中 // (url,实体:Map, Class&lt;T&gt; responseType) @Autowired private RestTemplate restTemplate;//提供多种便捷访问Http的方法 private static final String REST_URL_PREFIX = &quot;http://localhost:8081&quot;; @RequestMapping(&quot;/consumer/dept/add&quot;) public boolean add(Dept dept) &#123; return restTemplate.postForObject(REST_URL_PREFIX+&quot;/dept/add&quot;,dept,Boolean.class); &#125; @RequestMapping(&quot;/consumer/dept/get/&#123;id&#125;&quot;) public Dept get(@PathVariable(&quot;id&quot;) Long id) &#123; return restTemplate.getForObject(REST_URL_PREFIX+&quot;/dept/get/&quot;+id,Dept.class); &#125; @RequestMapping(&quot;/consumer/dept/list&quot;) public List&lt;Dept&gt; list() &#123; return restTemplate.getForObject(REST_URL_PREFIX+&quot;/dept/list&quot;,List.class); &#125;&#125; **启动服务: **DeptConsumer_80 1234567@SpringBootApplicationpublic class DeptConsumer_80 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptConsumer_80.class,args); &#125;&#125; 整体目录结构 5、Eureka服务注册与发现5.1 什么是Eureka Eureka：怎么读 Netflix在涉及Eureka时，遵循的就是API原则. Eureka是Netflix的有个子模块，也是核心模块之一。Eureka是基于REST的服务，用于定位服务，以实现云端中间件层服务发现和故障转移，服务注册与发现对于微服务来说是非常重要的，有了服务注册与发现，只需要使用服务的标识符，就可以访问到服务，而不需要修改服务调用的配置文件了，功能类似于Dubbo的注册中心，比如Zookeeper. 5.2 原理理解 Eureka基本的架构 Springcloud 封装了Netflix公司开发的Eureka模块来实现服务注册与发现 (对比Zookeeper). Eureka采用了C-S的架构设计，EurekaServer作为服务注册功能的服务器，他是服务注册中心. 而系统中的其他微服务，使用Eureka的客户端连接到EurekaServer并维持心跳连接。这样系统的维护人员就可以通过EurekaServer来监控系统中各个微服务是否正常运行，Springcloud 的一些其他模块 (比如Zuul) 就可以通过EurekaServer来发现系统中的其他微服务，并执行相关的逻辑. 和Dubbo架构对比 Eureka 包含两个组件：Eureka Server 和 Eureka Client. Eureka Server 提供服务注册，各个节点启动后，回在EurekaServer中进行注册，这样Eureka Server中的服务注册表中将会储存所有课用服务节点的信息，服务节点的信息可以在界面中直观的看到. Eureka Client 是一个Java客户端，用于简化EurekaServer的交互，客户端同时也具备一个内置的，使用轮询负载算法的负载均衡器。在应用启动后，将会向EurekaServer发送心跳 (默认周期为30秒) 。如果Eureka Server在多个心跳周期内没有接收到某个节点的心跳，EurekaServer将会从服务注册表中把这个服务节点移除掉 (默认周期为90s). 三大角色 Eureka Server：提供服务的注册与发现 Service Provider：服务生产方，将自身服务注册到Eureka中，从而使服务消费方能狗找到 Service Consumer：服务消费方，从Eureka中获取注册服务列表，从而找到消费服务 目前工程状况 5.3 构建步骤1. eureka-server springcloud-eureka-7001 模块建立 pom.xml 配置 123456789101112131415&lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-starter-eureka-server --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt; &lt;version&gt;1.4.6.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--热部署--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; application.yml 12345678910111213server: port: 7001# Eureka配置eureka: instance: hostname: localhost # Eureka服务端的名字 client: register-with-eureka: false # 表示是否想Eureka中心注册自己 fetch-registry: false # fetch-registry如果为false，则表示自己为注册中心 service-url: defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ 源码中Eureka的默认端口以及访问路径: 主启动类EurekaServer_7001.java 12345678@SpringBootApplication@EnableEurekaServerpublic class EurekaServer_7001 &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServer_7001.class,args); &#125;&#125; 启动成功后访问 http://localhost:7001/ 得到以下页面 2. eureka-client 调整之前创建的springlouc-provider-dept-8081 导入Eureca依赖 1234567&lt;!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-starter-eureka --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt;&lt;/dependency&gt; application.yml中新增Eureca配置 123456# Eureka的配置eureka: client: service-url: defaultZone: http://localhost:7001/eureka/ 为主启动类添加@EnableEurekaClient注解 123456789//启动类@SpringBootApplication@EnableEurekaClient //在服务启动后自动注册到Eureka中public class DeptProvider_8081 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptProvider_8081.class,args); &#125;&#125; 先启动7001服务端后启动8001客户端进行测试，然后访问监控页http://localhost:7001/ 产看结果如图，成功 修改Eureka上的默认描述信息 12345678# Eureka的配置eureka: client: service-url: defaultZone: http://localhost:7001/eureka/ instance: instance-id: springcloud-provider-dept-8081 #修改Eureka上的默认描述信息 结果如图： 等30s后 监控会开启保护机制 配置关于服务加载的监控信息 pom.xml中添加依赖 123456&lt;!--actuator完善监控信息--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; application.yml中添加配置 12345#info配置info: app.name: lzh-springcloud #项目的名称 company.name: com.lzh #公司的名称 刷新页面，点击 3. EureKa自我保护机制：好死不如赖活着 一句话总结就是：某时刻某一个微服务不可用，eureka不会立即清理，依旧会对该微服务的信息进行保存！ 默认情况下，当eureka server在一定时间内没有收到实例的心跳，便会把该实例从注册表中删除（默认是90秒），但是，如果短时间内丢失大量的实例心跳，便会触发eureka server的自我保护机制，比如在开发测试时，需要频繁地重启微服务实例，但是我们很少会把eureka server一起重启（因为在开发过程中不会修改eureka注册中心），当一分钟内收到的心跳数大量减少时，会触发该保护机制。可以在eureka管理界面看到Renews threshold和Renews(last min)，当后者（最后一分钟收到的心跳数）小于前者（心跳阈值）的时候，触发保护机制，会出现红色的警告：**EMERGENCY!EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY’RE NOT.RENEWALS ARE LESSER THAN THRESHOLD AND HENCE THE INSTANCES ARE NOT BEGING EXPIRED JUST TO BE SAFE.**从警告中可以看到，eureka认为虽然收不到实例的心跳，但它认为实例还是健康的，eureka会保护这些实例，不会把它们从注册表中删掉。 该保护机制的目的是避免网络连接故障，在发生网络故障时，微服务和注册中心之间无法正常通信，但服务本身是健康的，不应该注销该服务，如果eureka因网络故障而把微服务误删了，那即使网络恢复了，该微服务也不会重新注册到eureka server了，因为只有在微服务启动的时候才会发起注册请求，后面只会发送心跳和服务列表请求，这样的话，该实例虽然是运行着，但永远不会被其它服务所感知。所以，eureka server在短时间内丢失过多的客户端心跳时，会进入自我保护模式，该模式下，eureka会保护注册表中的信息，不在注销任何微服务，当网络故障恢复后，eureka会自动退出保护模式。自我保护模式可以让集群更加健壮。 但是我们在开发测试阶段，需要频繁地重启发布，如果触发了保护机制，则旧的服务实例没有被删除，这时请求有可能跑到旧的实例中，而该实例已经关闭了，这就导致请求错误，影响开发测试。所以，在开发测试阶段，我们可以把自我保护模式关闭，只需在eureka server配置文件中加上如下配置即可：eureka.server.enable-self-preservation=false· 4. 注册进来的微服务，获取一些消息（团队开发会用到） 启动类添加注解@EnableDiscoveryClient 12345678910//启动类@SpringBootApplication@EnableEurekaClient //在服务启动后自动注册到Eureka中@EnableDiscoveryClientpublic class DeptProvider_8081 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptProvider_8081.class,args); &#125;&#125; DeptController.java新增方法 123456789101112131415161718192021222324//获取一些配置的信息，得到具体的微服务！@Autowiredprivate DiscoveryClient client; //注册进来的微服务~，获取一些消息~ @GetMapping(&quot;/dept/discovery&quot;) public Object discovery() &#123; //获取微服务列表的清单 List&lt;String&gt; services = client.getServices(); System.out.println(&quot;discovery=&gt;services:&quot; + services); //得到一个具体的微服务信息,通过具体的微服务id，applicaioinName； List&lt;ServiceInstance&gt; instances = client.getInstances(&quot;SPRINGCLOUD-PROVIDER-DEPT&quot;); for (ServiceInstance instance : instances) &#123; System.out.println( instance.getHost() + &quot;\\t&quot; + // 主机名称 instance.getPort() + &quot;\\t&quot; + // 端口号 instance.getUri() + &quot;\\t&quot; + // uri instance.getServiceId() // 服务id ); &#125; return this.client; &#125; 结果 5.4 Eureka：集群环境配置1.初始化 新建springcloud-eureka-7002、springcloud-eureka-7003 模块 为pom.xml添加依赖 (与springcloud-eureka-7001相同) 123456789101112131415&lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-starter-eureka-server --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--热部署--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; application.yml配置(与springcloud-eureka-7001相同) 端口号分别换成7002和7003 主启动类(与springcloud-eureka-7001相同) 2.集群成员相互关联 配置一些自定义本机名字，找到本机hosts文件并打开 在hosts文件最后加上，要访问的本机名称，默认是localhost 修改application.yml的配置，如图为springcloud-eureka-7001配置，springcloud-eureka-7002/springcloud-eureka-7003同样分别修改为其对应的名称即可 在集群中使springcloud-eureka-7001关联springcloud-eureka-7002、springcloud-eureka-7003 以7001为例：完整的springcloud-eureka-7001下的application.yml如下 1234567891011121314151617server: port: 7001# Eureka配置eureka: instance: hostname: eureka7001.com # Eureka服务端的名字 client: register-with-eureka: false # 表示是否想Eureka中心注册自己 fetch-registry: false # fetch-registry如果为false，则表示自己为注册中心 service-url: #监控页面~ #重写Eureka的默认端口以及访问路径 ---&gt;http://localhost:7001/eureka/ # 单机 defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ # 集群（关联）：7001关联7002、7003 defaultZone: http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ 通过springcloud-provider-dept-8081下的yml配置文件，修改Eureka配置：配置服务注册中心地址 12345678# Eureka的配置eureka: client: service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ instance: instance-id: springcloud-provider-dept-8081 #修改Eureka上的默认描述信息 这样模拟集群就搭建号了，就可以把一个项目挂载到三个服务器上了 5.5 对比和Zookeeper区别1. 回顾CAP原则 RDBMS (MySQL\\Oracle\\sqlServer) ===&gt; ACID NoSQL (Redis\\MongoDB) ===&gt; CAP 2. ACID是什么？ A (Atomicity) 原子性 C (Consistency) 一致性 I (Isolation) 隔离性 D (Durability) 持久性 3. CAP是什么? C (Consistency) 强一致性 A (Availability) 可用性 P (Partition tolerance) 分区容错性 CAP的三进二：CA、AP、CP 4. CAP理论的核心 一个分布式系统不可能同时很好的满足一致性，可用性和分区容错性这三个需求 根据CAP原理，将NoSQL数据库分成了满足CA原则，满足CP原则和满足AP原则三大类 CA：单点集群，满足一致性，可用性的系统，通常可扩展性较差 CP：满足一致性，分区容错的系统，通常性能不是特别高 AP：满足可用性，分区容错的系统，通常可能对一致性要求低一些 5. 作为分布式服务注册中心，Eureka比Zookeeper好在哪里？ 著名的CAP理论指出，一个分布式系统不可能同时满足C (一致性) 、A (可用性) 、P (容错性)，由于分区容错性P再分布式系统中是必须要保证的，因此我们只能再A和C之间进行权衡。 Zookeeper 保证的是CP Eureka 保证的是AP Zookeeper保证的是CP 当向注册中心查询服务列表时，我们可以容忍注册中心返回的是几分钟以前的注册信息，但不能接收服务直接down掉不可用。也就是说，服务注册功能对可用性的要求要高于一致性。但zookeeper会出现这样一种情况，当master节点因为网络故障与其他节点失去联系时，剩余节点会重新进行leader选举。问题在于，选举leader的时间太长，30-120s，且选举期间整个zookeeper集群是不可用的，这就导致在选举期间注册服务瘫痪。在云部署的环境下，因为网络问题使得zookeeper集群失去master节点是较大概率发生的事件，虽然服务最终能够恢复，但是，漫长的选举时间导致注册长期不可用，是不可容忍的。 Eureka保证的是AP Eureka看明白了这一点，因此在设计时就优先保证可用性。Eureka各个节点都是平等的，几个节点挂掉不会影响正常节点的工作，剩余的节点依然可以提供注册和查询服务。而Eureka的客户端在向某个Eureka注册时，如果发现连接失败，则会自动切换至其他节点，只要有一台Eureka还在，就能保住注册服务的可用性，只不过查到的信息可能不是最新的，除此之外，Eureka还有之中自我保护机制，如果在15分钟内超过85%的节点都没有正常的心跳，那么Eureka就认为客户端与注册中心出现了网络故障，此时会出现以下几种情况： Eureka不在从注册列表中移除因为长时间没收到心跳而应该过期的服务 Eureka仍然能够接受新服务的注册和查询请求，但是不会被同步到其他节点上 (即保证当前节点依然可用) 当网络稳定时，当前实例新的注册信息会被同步到其他节点中 因此，Eureka可以很好的应对因网络故障导致部分节点失去联系的情况，而不会像zookeeper那样使整个注册服务瘫痪 6. Ribbon：负载均衡(基于客户端)6.1 负载均衡以及RibbonRibbon是什么？ Spring Cloud Ribbon 是基于Netflix Ribbon 实现的一套客户端负载均衡的工具。 简单的说，Ribbon 是 Netflix 发布的开源项目，主要功能是提供客户端的软件负载均衡算法，将 Netflix 的中间层服务连接在一起。Ribbon 的客户端组件提供一系列完整的配置项，如：连接超时、重试等。简单的说，就是在配置文件中列出 LoadBalancer (简称LB：负载均衡) 后面所有的及其，Ribbon 会自动的帮助你基于某种规则 (如简单轮询，随机连接等等) 去连接这些机器。我们也容易使用 Ribbon 实现自定义的负载均衡算法！ 面试造飞机，工作拧螺丝 Ribbon能干嘛？ LB，即负载均衡 (LoadBalancer) ，在微服务或分布式集群中经常用的一种应用。 负载均衡简单的说就是将用户的请求平摊的分配到多个服务上，从而达到系统的HA (高用)。 常见的负载均衡软件有 Nginx、Lvs 等等。 Dubbo、SpringCloud 中均给我们提供了负载均衡，SpringCloud 的负载均衡算法可以自定义。 负载均衡简单分类： 集中式LB 即在服务的提供方和消费方之间使用独立的LB设施，如Nginx，由该设施负责把访问请求通过某种策略转发至服务的提供方！ 进程式LB 将LB逻辑集成到消费方，消费方从服务注册中心获知有哪些地址可用，然后自己再从这些地址中选出一个合适的服务器。 Ribbon 就属于进程内LB，它只是一个类库，集成于消费方进程，消费方通过它来获取到服务提供方的地址！ 6.2 集成Ribbon springcloud-consumer-dept-80向pom.xml中添加Ribbon和Eureka依赖 1234567891011121314&lt;!-- Ribbon --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!--eureka--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt;&lt;/dependency&gt; 在application.yml文件中配置Eureka 1234567# Eureka配置eureka: client: register-with-eureka: false # 不向 Eureka注册自己 service-url: # 从三个注册中心中随机取一个去访问 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ 主启动类加上@EnableEurekaClient注解，开启Eureka 12345678@SpringBootApplication@EnableEurekaClient //开启Eureka 客户端public class DeptConsumer_80 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptConsumer_80.class,args); &#125;&#125; 自定义Spring配置类：ConfigBean.java 配置负载均衡实现RestTemplate 12345678910@Configurationpublic class ConfigBean &#123; //Cofiguration -- spring applicationContext.xml @LoadBalanced //配置负载均衡实现RestTemplate @Bean public RestTemplate getRestTemplate() &#123; return new RestTemplate(); &#125; &#125; ​ 6.3 使用Ribbon实现负载均衡1.实现负载均衡 流程图： 创建db02和db03数据库(一样的) 1234567891011121314151617CREATE DATABASE &#96;db02&#96;USE &#96;db02&#96;;DROP TABLE IF EXISTS &#96;dept&#96;;CREATE TABLE &#96;dept&#96; ( &#96;deptno&#96; BIGINT(20) NOT NULL AUTO_INCREMENT, &#96;dname&#96; VARCHAR(60) DEFAULT NULL, &#96;db_source&#96; VARCHAR(60) DEFAULT NULL, PRIMARY KEY (&#96;deptno&#96;)) ENGINE&#x3D;INNODB AUTO_INCREMENT&#x3D;1 DEFAULT CHARSET&#x3D;utf8 COMMENT&#x3D;&#39;部门表&#39;;INSERT INTO &#96;dept&#96;(&#96;dname&#96;,&#96;db_source&#96;) VALUES (&#39;开发部&#39;,DATABASE()),(&#39;人事部&#39;,DATABASE()),(&#39;财务部&#39;,DATABASE()),(&#39;市场部&#39;,DATABASE()),(&#39;运维部&#39;,DATABASE()); 新建两个服务提供者Moudle：springcloud-provider-dept-8082、springcloud-provider-dept-8083 参照springcloud-provider-dept-8081 依次为另外两个Moudle添加pom.xml依赖 、resourece下的mybatis和application.yml配置，Java代码 三个服务（spring.application.name）的名称必须一致 启动所有服务测试(根据自身电脑配置决定启动服务的个数)，访问http://eureka7001.com:7001/查看结果 测试访问http://localhost/consumer/dept/list 这时候随机访问的是服务提供者8081 再次访问http://localhost/consumer/dept/list这时候随机的是服务提供者8083 再次访问http://localhost/consumer/dept/list这时候随机的是服务提供者8082 以上这种每次访问http://localhost/consumer/dept/list随机访问集群中某个服务提供者，这种情况叫做轮询，轮询算法在SpringCloud中可以自定义。 2.如何切换或者自定义规则呢？ 在springcloud-provider-dept-80模块下的ConfigBean中进行配置，切换使用不同的规则 1234567891011121314151617181920212223@Configurationpublic class ConfigBean &#123;//@Configuration -- spring applicationContext.xml /** * IRule: * RoundRobinRule 轮询 * RandomRule 随机 * AvailabilityFilteringRule ： 会先过滤掉，跳闸，访问故障的服务~，对剩下的进行轮询~ * RetryRule ： 会先按照轮询获取服务~，如果服务获取失败，则会在指定的时间内进行，重试 */ @LoadBalanced //配置负载均衡实现RestTemplate @Bean public RestTemplate getRestTemplate() &#123; return new RestTemplate(); &#125; @Bean public IRule myRule()&#123; return new RandomRule();//使用随机规则 &#125;&#125; 也可以自定义规则，在myRule包下自定义一个配置类MyRule.java，注意：**该包不要和主启动类所在的包同级，要跟启动类所在包同级**： MyRule.java 123456789@Configurationpublic class MyRule &#123; @Bean public IRule lzhMyRule() &#123; return new MyRandomRule();//默认是轮循，现在我们自定义 &#125;&#125; 主启动类开启负载均衡并指定自定义的MyRule配置类 1234567891011// Ribbon和Eureka整合之后，客户端可以直接调用，不用关系IP地址@SpringBootApplication@EnableEurekaClient //开启Eureka 客户端//在微服务启动的时候就能加载自定义的Ribbon类(自定义的规则会覆盖原有默认的规则)@RibbonClient(name = &quot;SPRINGCLOUD-PROVIDER-DEPT&quot;,configuration = MyRule.class)//开启负载均衡,并指定自定义的规则public class DeptConsumer_80 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptConsumer_80.class,args); &#125;&#125; 自定义的规则(这里我们参考Ribbon中默认的规则代码自己稍微改动)：MyRandomRule.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990package nuc.ss.myrule;import com.netflix.client.config.IClientConfig;import com.netflix.loadbalancer.AbstractLoadBalancerRule;import com.netflix.loadbalancer.ILoadBalancer;import com.netflix.loadbalancer.Server;import java.util.List;import java.util.concurrent.ThreadLocalRandom;public class MyRandomRule extends AbstractLoadBalancerRule &#123; /** * 每个服务访问5次，则换下一个服务(总共3个服务) * total=0,默认=0,如果=5,指向下一个服务节点 * index=0,默认=0,如果total=5,index+1 */ private int total = 0; //被调用的次数 private int currentIndex = 0; //当前是谁在提供服务 public Server choose(ILoadBalancer lb, Object key) &#123; if (lb == null) &#123; return null; &#125; Server server = null; while (server == null) &#123; if (Thread.interrupted()) &#123; return null; &#125; List&lt;Server&gt; upList = lb.getReachableServers(); //获得当前活着的服务 List&lt;Server&gt; allList = lb.getAllServers(); //获取所有的服务 int serverCount = allList.size(); if (serverCount == 0) &#123; return null; &#125; //int index = chooseRandomInt(serverCount);//生成区间随机数 //server = upList.get(index);//从或活着的服务中,随机获取一个 //=====================自定义代码========================= if (total &lt; 5) &#123; server = upList.get(currentIndex); total++; &#125; else &#123; total = 0; currentIndex++; if (currentIndex &gt;= upList.size()) &#123; currentIndex = 0; &#125; //server = upList.get(currentIndex);//从活着的服务中,获取指定的服务来进行操作 &#125; //====================================================== if (server == null) &#123; Thread.yield(); continue; &#125; if (server.isAlive()) &#123; return (server); &#125; server = null; Thread.yield(); &#125; return server; &#125; protected int chooseRandomInt(int serverCount) &#123; return ThreadLocalRandom.current().nextInt(serverCount); &#125; @Override public Server choose(Object key) &#123; return choose(getLoadBalancer(), key); &#125; @Override public void initWithNiwsConfig(IClientConfig clientConfig) &#123; // TODO Auto-generated method stub &#125;&#125; 7.Feign：负载均衡(基于服务端)7.1 Feign简介Feign是声明式Web Service客户端，它让微服务之间的调用变得更简单，类似controller调用service。SpringCloud集成了Ribbon和Eureka，可以使用Feigin提供负载均衡的http客户端 只需要创建一个接口，然后添加注解即可~ Feign，主要是社区版，大家都习惯面向接口编程。这个是很多开发人员的规范。调用微服务访问两种方法 微服务名字 【ribbon】 接口和注解 【feign】 Feign能干什么？ Feign旨在使编写Java Http客户端变得更容易 前面在使用Ribbon + RestTemplate时，利用RestTemplate对Http请求的封装处理，形成了一套模板化的调用方法。但是在实际开发中，由于对服务依赖的调用可能不止一处，往往一个接口会被多处调用，所以通常都会针对每个微服务自行封装一个客户端类来包装这些依赖服务的调用。所以，Feign在此基础上做了进一步的封装，由他来帮助我们定义和实现依赖服务接口的定义，在Feign的实现下，我们只需要创建一个接口并使用注解的方式来配置它 (类似以前Dao接口上标注Mapper注解，现在是一个微服务接口上面标注一个Feign注解即可)，即可完成对服务提供方的接口绑定，简化了使用Spring Cloud Ribbon 时，自动封装服务调用客户端的开发量。 Feign默认集成了Ribbon 利用Ribbon维护了MicroServiceCloud-Dept的服务列表信息，并且通过轮询实现了客户端的负载均衡，而与Ribbon不同的是，通过Feign只需要定义服务绑定接口且以声明式的方法，优雅而简单的实现了服务调用。 7.2 Feign的使用步骤 改造springcloud-api模块 pom.xml添加feign依赖 123456&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt;&lt;/dependency&gt; 新建service层，并新建DeptClientService.java接口， 123456789101112131415@Service//@FeignClient:微服务客户端注解,value:指定微服务的名字,这样就可以使Feign客户端直接找到对应的微服务@FeignClient(value = &quot;SPRINGCLOUD-PROVIDER-DEPT&quot;)public interface DeptClientService &#123; @GetMapping(&quot;/dept/get/&#123;id&#125;&quot;) Dept queryById(@PathVariable(&quot;id&quot;) Long id); @GetMapping(&quot;/dept/list&quot;) List&lt;Dept&gt; queryAll(); @PostMapping(&quot;/dept/add&quot;) boolean addDept(Dept dept);&#125; 创建springcloud-consumer-dept-feign模块 拷贝springcloud-consumer-dept-80模块下的pom.xml，resource，以及java代码到springcloud-consumer-feign模块，并添加feign依赖。 1234567&lt;!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-starter-feign --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt;&lt;/dependency&gt; 通过Feign实现DeptConsumerController.java 1234567891011121314151617181920212223@RestControllerpublic class DeptConsumerController &#123; @Autowired private DeptClientService deptClientService = null; @RequestMapping(&quot;/consumer/dept/add&quot;) public boolean add(Dept dept) &#123; return this.deptClientService.addDept(dept); &#125; @RequestMapping(&quot;/consumer/dept/get/&#123;id&#125;&quot;) public Dept get(@PathVariable(&quot;id&quot;) Long id) &#123; return this.deptClientService.queryById(id); &#125; @RequestMapping(&quot;/consumer/dept/list&quot;) public List&lt;Dept&gt; list() &#123; return this.deptClientService.queryAll(); &#125;&#125; 主配置类 123456789@SpringBootApplication@EnableEurekaClient //开启Eureka 客户端@EnableFeignClients(basePackages = &#123;&quot;nuc.ss.springcloud&quot;&#125;)public class FeignDeptConsumer_80 &#123; public static void main(String[] args) &#123; SpringApplication.run(FeignDeptConsumer_80.class,args); &#125;&#125; 结果 7.3 Feign和Ribbon如何选择？根据个人习惯而定，如果喜欢REST风格使用Ribbon；如果喜欢社区版的面向接口风格使用Feign. 8. Hystrix：服务熔断分布式系统面临的问题 复杂分布式体系结构中的应用程序有数十个依赖关系，每个依赖关系在某些时候将不可避免失败！ 8.1 服务雪崩 多个微服务之间调用的时候，假设微服务A调用微服务B和微服务C，微服务B和微服务C又调用其他的微服务，这就是所谓的“扇出”，如果扇出的链路上某个微服务的调用响应时间过长，或者不可用，对微服务A的调用就会占用越来越多的系统资源，进而引起系统崩溃，所谓的“雪崩效应”。 对于高流量的应用来说，单一的后端依赖可能会导致所有服务器上的所有资源都在几十秒内饱和。比失败更糟糕的是，这些应用程序还可能导致服务之间的延迟增加，备份队列，线程和其他系统资源紧张，导致整个系统发生更多的级联故障，这些都表示需要对故障和延迟进行隔离和管理，以便单个依赖关系的失败，不能取消整个应用程序或系统。 我们需要，弃车保帅 8.2 什么是Hystrix？ Hystrix是一个应用于处理分布式系统的延迟和容错的开源库，在分布式系统里，许多依赖不可避免的会调用失败，比如超时，异常等，Hystrix能够保证在一个依赖出问题的情况下，不会导致整个体系服务失败，避免级联故障，以提高分布式系统的弹性。 “断路器”本身是一种开关装置，当某个服务单元发生故障之后，通过断路器的故障监控 (类似熔断保险丝) ，向调用方方茴一个服务预期的，可处理的备选响应 (FallBack) ，而不是长时间的等待或者抛出调用方法无法处理的异常，这样就可以保证了服务调用方的线程不会被长时间，不必要的占用，从而避免了故障在分布式系统中的蔓延，乃至雪崩。 8.3 Hystrix能干嘛？ 服务降级 服务熔断 服务限流 接近实时的监控 … 当一切正常时，请求流可以如下所示： 当许多后端系统中有一个潜在时，它可以阻止整个用户请求： 随着大容量通信量的增加，单个后端依赖项的潜在性会导致所有服务器上的所有资源在几秒钟内饱和。 应用程序中通过网络或客户端库可能导致网络请求的每个点都是潜在故障的来源。比失败更糟糕的是，这些应用程序还可能导致服务之间的延迟增加，从而备份队列、线程和其他系统资源，从而导致更多跨系统的级联故障。 当使用hystrix包装每个基础依赖项时，上面的图表中所示的体系结构会发生类似于以下关系图的变化。每个依赖项是相互隔离的，限制在延迟发生时它可以填充的资源中，并包含在回退逻辑中，该逻辑决定在依赖项中发生任何类型的故障时要做出什么样的响应： 官网资料：https://github.com/Netflix/Hystrix/wiki，图片加载不出来请看另一篇文章 github加载图片失败问题 8.4、服务熔断8.4.1、什么是服务熔断 熔断机制是赌赢雪崩效应的一种微服务链路保护机制。 在微服务架构中，微服务之间的数据交互通过远程调用完成，微服务A调用微服务B和微服务C，微服务B和微服务C又调用其它的微服务，此时如果链路上某个微服务的调用响应时间过长或者不可用，那么对微服务A的调用就会占用越来越多的系统资源，进而引起系统崩溃，导致“雪崩效应”。 服务熔断是应对雪崩效应的一种微服务链路保护机制。例如在高压电路中，如果某个地方的电压过高，熔断器就会熔断，对电路进行保护。同样，在微服务架构中，熔断机制也是起着类似的作用。当调用链路的某个微服务不可用或者响应时间太长时，会进行服务熔断，不再有该节点微服务的调用，快速返回错误的响应信息。当检测到该节点微服务调用响应正常后，恢复调用链路。 当扇出链路的某个微服务不可用或者响应时间太长时，会进行服务的降级，进而熔断该节点微服务的调用，快速返回错误的响应信息。检测到该节点微服务调用响应正常后恢复调用链路。在SpringCloud框架里熔断机制通过Hystrix实现。Hystrix会监控微服务间调用的状况，当失败的调用到一定阀值缺省是5秒内20次调用失败，就会启动熔断机制。熔断机制的注解是：**@HystrixCommand** 。 服务熔断解决如下问题： 当所依赖的对象不稳定时，能够起到快速失败的目的 快速失败后，能够根据一定的算法动态试探所依赖对象是否恢复 8.4.2、入门案例新建springcloud-provider-dept-hystrix-8081模块并拷贝springcloud-provider-dept–8081内的pom.xml、resource和Java代码进行初始化并调整。 导入hystrix依赖 1234567&lt;!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-starter-hystrix --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt;&lt;/dependency&gt; 调整yml配置文件 123456789# Eureka的配置eureka: client: service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ instance: instance-id: springcloud-provider-dept-hystrix-8081 #修改Eureka上的默认描述信息 prefer-ip-address: true #改为true后默认显示的是ip地址而不再是localhost prefer-ip-address: false： prefer-ip-address: true： 修改controller 1234567891011121314151617181920212223242526272829//视图Restful服务@RestControllerpublic class DeptController &#123; @Autowired private DeptService deptService; //获取一些配置的信息，得到具体的微服务！ @Autowired private DiscoveryClient client; @HystrixCommand(fallbackMethod = &quot;hystrixGet&quot;)//如果根据id查询出现异常,走这段代码 @GetMapping(&quot;/dept/get/&#123;id&#125;&quot;) public Dept get(@PathVariable(&quot;id&quot;) Long id) &#123; Dept dept = deptService.queryById(id); if (dept==null)&#123; throw new RuntimeException(&quot;这个id=&gt;&quot;+id+&quot;,不存在该用户，或信息无法找到~&quot;); &#125; return dept; &#125; //根据id查询备选方案(熔断) public Dept hystrixGet(@PathVariable(&quot;id&quot;) Long id)&#123; return new Dept().setDeptno(id) .setDname(&quot;这个id=&gt;&quot;+id+&quot;,没有对应的信息,null---@Hystrix~&quot;) .setDb_source(&quot;在MySQL中没有这个数据库&quot;); &#125;&#125; 为主启动类添加对熔断的支持注解@EnableCircuitBreaker 1234567891011//启动类@SpringBootApplication@EnableEurekaClient //在服务启动后自动注册到Eureka中@EnableDiscoveryClient //服务发现~@EnableCircuitBreaker//添加对熔断的支持public class DeptProviderHystrix_8081 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptProviderHystrix_8081.class,args); &#125;&#125; 测试： 使用熔断后，当访问一个存在的id时，前台页展示数据如下 使用熔断后，当访问一个不存在的id时，前台页展示数据如下 而不适用熔断的springcloud-provider-dept–8081模块访问相同地址会出现下面状况 因此，为了避免因某个微服务后台出现异常或错误而导致整个应用或网页报错，使用熔断是必要的 8.5 服务降级什么是服务降级​ 服务降级是指 当服务器压力剧增的情况下，根据实际业务情况及流量，对一些服务和页面有策略的不处理或换种简单的方式处理，从而释放服务器资源以保证核心业务正常运作或高效运作。说白了，就是尽可能的把系统资源让给优先级高的服务。 资源有限，而请求是无限的。如果在并发高峰期，不做服务降级处理，一方面肯定会影响整体服务的性能，严重的话可能会导致宕机某些重要的服务不可用。所以，一般在高峰期，为了保证核心功能服务的可用性，都要对某些服务降级处理。比如当双11活动时，把交易无关的服务统统降级，如查看蚂蚁深林，查看历史订单等等。 服务降级主要用于什么场景呢？当整个微服务架构整体的负载超出了预设的上限阈值或即将到来的流量预计将会超过预设的阈值时，为了保证重要或基本的服务能正常运行，可以将一些 不重要 或 不紧急 的服务或任务进行服务的 延迟使用 或 暂停使用。 降级的方式可以根据业务来，可以延迟服务，比如延迟给用户增加积分，只是放到一个缓存中，等服务平稳之后再执行 ；或者在粒度范围内关闭服务，比如关闭相关文章的推荐。 由上图可得，当某一时间内服务A的访问量暴增，而B和C的访问量较少，为了缓解A服务的压力，这时候需要B和C暂时关闭一些服务功能，去承担A的部分服务，从而为A分担压力，叫做服务降级。 服务降级需要考虑的问题 1）那些服务是核心服务，哪些服务是非核心服务 2）那些服务可以支持降级，那些服务不能支持降级，降级策略是什么 3）除服务降级之外是否存在更复杂的业务放通场景，策略是什么？ 自动降级分类1）超时降级：主要配置好超时时间和超时重试次数和机制，并使用异步机制探测回复情况 2）失败次数降级：主要是一些不稳定的api，当失败调用次数达到一定阀值自动降级，同样要使用异步机制探测回复情况 3）故障降级：比如要调用的远程服务挂掉了（网络故障、DNS故障、http服务返回错误的状态码、rpc服务抛出异常），则可以直接降级。降级后的处理方案有：默认值（比如库存服务挂了，返回默认现货）、兜底数据（比如广告挂了，返回提前准备好的一些静态页面）、缓存（之前暂存的一些缓存数据） 4）限流降级：秒杀或者抢购一些限购商品时，此时可能会因为访问量太大而导致系统崩溃，此时会使用限流来进行限制访问量，当达到限流阀值，后续请求会被降级；降级后的处理方案可以是：排队页面（将用户导流到排队页面等一会重试）、无货（直接告知用户没货了）、错误页（如活动太火爆了，稍后重试）。 入门案例在springcloud-api模块下的service包中新建降级配置类DeptClientServiceFallBackFactory.java 12345678910111213141516171819202122232425262728//降级 ~@Componentpublic class DeptClientServiceFallBackFactory implements FallbackFactory &#123; @Override public Object create(Throwable throwable) &#123; return new DeptClientService() &#123; @Override public Dept queryById(Long id) &#123; return new Dept() .setDeptno(id) .setDname(&quot;id=&gt;&quot; + id + &quot;没有对应的信息，客户端提供了降级的信息，这个服务现在已经被关闭&quot;) .setDb_source(&quot;没有数据~&quot;); &#125; @Override public List&lt;Dept&gt; queryAll() &#123; return null; &#125; @Override public boolean addDept(Dept dept) &#123; return false; &#125; &#125;; &#125;&#125; 在DeptClientService中指定降级配置类DeptClientServiceFallBackFactory 123456789101112131415@Service//@FeignClient:微服务客户端注解,value:指定微服务的名字,这样就可以使Feign客户端直接找到对应的微服务@FeignClient(value = &quot;SPRINGCLOUD-PROVIDER-DEPT&quot;,fallbackFactory = DeptClientServiceFallBackFactory.class)public interface DeptClientService &#123; @GetMapping(&quot;/dept/get/&#123;id&#125;&quot;) Dept queryById(@PathVariable(&quot;id&quot;) Long id); @GetMapping(&quot;/dept/list&quot;) List&lt;Dept&gt; queryAll(); @PostMapping(&quot;/dept/add&quot;) boolean addDept(Dept dept);&#125; 在springcloud-consumer-dept-feign模块中开启降级 12345# 开启降级feign.hystrixfeign: hystrix: enabled: true 测试 正常访问 关掉服务DeptProvider_8081继续访问 8.6 服务熔断和降级的区别 服务熔断—&gt;服务端：某个服务超时或异常，引起熔断~，类似于保险丝(自我熔断) 服务降级—&gt;客户端：从整体网站请求负载考虑，当某个服务熔断或者关闭之后，服务将不再被调用，此时在客户端，我们可以准备一个 FallBackFactory ，返回一个默认的值(缺省值)。会导致整体的服务下降，但是好歹能用，比直接挂掉强。 触发原因不太一样，服务熔断一般是某个服务（下游服务）故障引起，而服务降级一般是从整体负荷考虑；管理目标的层次不太一样，熔断其实是一个框架级的处理，每个微服务都需要（无层级之分），而降级一般需要对业务有层级之分（比如降级一般是从最外围服务开始） 实现方式不太一样，服务降级具有代码侵入性(由控制器完成/或自动降级)，熔断一般称为自我熔断。 限流：限制并发的请求访问量，超过阈值则拒绝；降级：服务分优先级，牺牲非核心服务（不可用），保证核心服务稳定；从整体负荷考虑；熔断：依赖的下游服务故障触发熔断，避免引发本系统崩溃；系统自动执行和恢复 8.7 Dashboard 流监控新建springcloud-consumer-hystrix-dashboard模块 添加依赖 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-starter-hystrix --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix-dashboard&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Ribbon --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--eureka--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;nuc.ss&lt;/groupId&gt; &lt;artifactId&gt;springcloud-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 主启动类 123456789@SpringBootApplication@EnableHystrixDashboard //开启public class DeptConsumerDashboard_9001 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptConsumerDashboard_9001.class,args); &#125;&#125; 启动应用程序，访问：localhost:9001/hystrix 服务端8081是否有监控应用程依赖，没有添加 123456&lt;!--actuator完善监控信息--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 给springcloud-provider-dept-hystrix-8081模块下的主启动类添加如下代码,添加监控 1234567891011121314151617181920//启动类@SpringBootApplication@EnableEurekaClient //在服务启动后自动注册到Eureka中@EnableDiscoveryClient //服务发现~@EnableCircuitBreaker//添加对熔断的支持public class DeptProviderHystrix_8081 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptProviderHystrix_8081.class,args); &#125; //增加一个 Servlet @Bean public ServletRegistrationBean hystrixMetricsStreamServlet()&#123; ServletRegistrationBean registrationBean = new ServletRegistrationBean(new HystrixMetricsStreamServlet()); //访问该页面就是监控页面 registrationBean.addUrlMappings(&quot;/actuator/hystrix.stream&quot;); return registrationBean; &#125;&#125; 注意：先访问localhost:8081/dept/get/1，在访问localhost:8081/actuator/hystrix.stream，不然也会报错 在springcloud-consumer-hystrix-dashboard中的yml中添加配置（刚开始没加，一直报这个错: Unable to connect to Command Metric Stream） 1234hystrix: dashboard: proxy-stream-allow-list: &quot;*&quot; 运行结果：（注意心跳和圆的大小变化） 如何看运行结果 七色 绿色：成功数 蓝色：熔断数 浅绿色：错误请求数 黄色：超时数 紫色：线程池拒绝数 红色：失败/异常数 Hosts：服务请求频率 Circuit Closed：断路状态 一圈实心圆:公有两种含义，他通过颜色的变化代表了实例的健康程度它的健康程度从绿色&lt;黄色&lt;橙色&lt;红色 递减该实心圆除了颜色的变化之外，它的大小也会根据实例的请求流量发生变化，流量越大，该实心圆就越大，所以通过该实心圆的展示，就可以在大量的实例中快速发现故障实例和高压力实例。 一线曲线：用来记录2分钟内流量的相对变化，可以通过它来观察到流量的上升和下降趋势! 9. Zull路由网关概述什么是zuul? Zull包含了对请求的路由(用来跳转的)和过滤两个最主要功能： 其中路由功能负责将外部请求转发到具体的微服务实例上，是实现外部访问统一入口的基础，而过滤器功能则负责对请求的处理过程进行干预，是实现请求校验，服务聚合等功能的基础。Zuul和Eureka进行整合，将Zuul自身注册为Eureka服务治理下的应用，同时从Eureka中获得其他服务的消息，也即以后的访问微服务都是通过Zuul跳转后获得。 注意：Zuul服务最终还是会注册进Eureka 提供：代理+路由+过滤 三大功能！ Zuul能干嘛？ 路由 过滤 官方文档：https://github.com/Netflix/zuul/ 入门案例新建springcloud-zuul模块，并导入依赖 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;dependencies&gt; &lt;!--zuul--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zuul&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Hystrix依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix-dashboard&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Ribbon --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--eureka--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;nuc.ss&lt;/groupId&gt; &lt;artifactId&gt;springcloud-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; application.yml 1234567891011121314151617server: port: 9527spring: application: name: springcloud-zuuleureka: client: service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ instance: instance-id: zuul9527.com prefer-ip-address: trueinfo: app.name: springcloud company.name: blog.kuangstudy.com 启动如下图三个服务（先去host文件里面添加www.kuangstudy.com的服务） 访问http://localhost:8081/dept/get/1和http://www.kuangstudy.com:9527/springcloud-provider-dept/dept/get/1都可以获得数据 隐藏微服务springcloud-provider-dept的名称在地址栏，application.yml中添加配置 12345zuul: routes: mydept.serviceId: springcloud-provider-dept mydept.path: /mydept/** 访问这个地址即可http://www.kuangstudy.com:9527/mydept/dept/get/1 但是原路径http://www.kuangstudy.com:9527/springcloud-provider-dept/dept/get/1也能访问 继续配置application.yml,原来的http://www.kuangstudy.com:9527/springcloud-provider-dept/dept/get/1不能访问了 123456zuul: routes: mydept.serviceId: springcloud-provider-dept mydept.path: /mydept/** ignored-services: &quot;*&quot; # 不能再使用某个(*：全部)路径访问了，ignored ： 忽略,隐藏全部的~ 继续想application添加公共的访问前缀,访问路径变为http://www.kuangstudy.com:9527/kuang/mydept/dept/get/1 1234567zuul: routes: mydept.serviceId: springcloud-provider-dept mydept.path: /mydept/** ignored-services: &quot;*&quot; # 不能再使用某个(*：全部)路径访问了，ignored ： 忽略,隐藏全部的~ prefix: /kuang # 设置公共的前缀,实现隐藏原有路由 10. Spring Cloud Config 分布式配置概述分布式系统面临的–配置文件问题 微服务意味着要将单体应用中的业务拆分成一个个子服务，每个服务的粒度相对较小，因此系统中会出现大量的服务，由于每个服务都需要必要的配置信息才能运行，所以一套集中式的，动态的配置管理设施是必不可少的。spring cloud提供了configServer来解决这个问题，我们每一个微服务自己带着一个application.yml，那上百个的配置文件修改起来，令人头疼！ 什么是SpringCloud config分布式配置中心？ spring cloud config 为微服务架构中的微服务提供集中化的外部支持，配置服务器为各个不同微服务应用的所有环节提供了一个中心化的外部配置。 spring cloud config 分为服务端和客户端两部分。 服务端也称为 分布式配置中心，它是一个独立的微服务应用，用来连接配置服务器并为客户端提供获取配置信息，加密，解密信息等访问接口。 客户端则是通过指定的配置中心来管理应用资源，以及与业务相关的配置内容，并在启动的时候从配置中心获取和加载配置信息。配置服务器默认采用git来存储配置信息，这样就有助于对环境配置进行版本管理。并且可用通过git客户端工具来方便的管理和访问配置内容。 spring cloud config 分布式配置中心能干嘛？ 集中式管理配置文件 不同环境，不同配置，动态化的配置更新，分环境部署，比如 /dev /test /prod /beta /release 运行期间动态调整配置，不再需要在每个服务部署的机器上编写配置文件，服务会向配置中心统一拉取配置自己的信息 当配置发生变动时，服务不需要重启，即可感知到配置的变化，并应用新的配置 将配置信息以REST接口的形式暴露 spring cloud config 分布式配置中心与GitHub整合 由于spring cloud config 默认使用git来存储配置文件 (也有其他方式，比如自持SVN 和本地文件)，但是最推荐的还是git ，而且使用的是 http / https 访问的形式。 入门案例服务端编写application.yml提交到github上或者码云上面（注意：—和空格的输入，否则之后访问补到） 12345678910111213141516spring: profiles: active: dev---spring: profiles: dev application: name: springcloud-config-dev---spring: profiles: test application: name: springcloud-config-test 新建springcloud-config-server-3344模块导入pom.xml依赖 123456789101112131415161718192021&lt;dependencies&gt; &lt;!--web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--config--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;version&gt;2.2.5.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--eureka--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; resource下创建application.yml配置文件，Spring Cloud Config服务器从git存储库（必须提供）为远程客户端提供配置： 1234567891011121314151617181920212223server: port: 3344spring: application: name: springcloud-config-server # 连接github远程仓库 cloud: config: server: git: # 注意是https的而不是ssh uri: https://github.com/lzh66666/spring-cloud-kuang.git # 通过 config-server可以连接到git，访问其中的资源以及配置~ default-label: main# 不加这个配置会报Cannot execute request on any known server 这个错：连接Eureka服务端地址不对# 或者直接注释掉eureka依赖 这里暂时用不到eurekaeureka: client: register-with-eureka: false fetch-registry: false 注意：default-label属性，默认是master提交，我改成main提交之后页面死活出不来 可以输入git status查看自己的分支 访问：http://localhost:3344/application-dev.yml页面 访问：http://localhost:3344/application-test.yml页面 HTTP服务具有以下格式的资源：（main是我的分支，默认为master） 123456/&#123;application&#125;/&#123;profile&#125;[/&#123;label&#125;] // http://localhost:3344/application/test/main/&#123;application&#125;-&#123;profile&#125;.yml // http://localhost:3344/application-test.yml/&#123;label&#125;/&#123;application&#125;-&#123;profile&#125;.yml // http://localhost:3344/main/application-test.yml/&#123;application&#125;-&#123;profile&#125;.properties/&#123;label&#125;/&#123;application&#125;-&#123;profile&#125;.properties 客户端将本地git仓库springcloud-config文件夹下新建的config-client.yml提交到github或码云仓库：（千万别加注释，否则路径找不到） 12345678910111213141516171819202122232425262728spring: profiles: active: dev---server: port: 8201spring: profiles: dev application: name: springcloud-provider-depteureka: client: service-url: defaultZone: http://eureka7001.com:7001/eureka/---server: port: 8202spring: profiles: test application: name: springcloud-provider-depteureka: client: service-url: defaultZone: http://eureka7001.com:7001/eureka/ 新建一个springcloud-config-client-3355模块，并导入依赖 123456789101112131415161718192021&lt;dependencies&gt; &lt;!--web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--config--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;version&gt;2.1.1.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--actuator--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; resources下创建application.yml和bootstrap.yml配置文件 bootstrap.yml是系统级别的配置 12345678910# 系统级别的配置spring: cloud: config: name: config-client # 需要从git上读取的资源名称，不要后缀 profile: dev label: main uri: http://localhost:3344 application.yml是用户级别的配置 12345# 用户级别的配置spring: application: name: springcloud-config-client 创建controller包下的ConfigClientController.java用于测试 1234567891011121314151617181920@RestControllerpublic class ConfigClientController &#123; @Value(&quot;$&#123;spring.application.name&#125;&quot;) private String applicationName; //获取微服务名称 @Value(&quot;$&#123;eureka.client.service-url.defaultZone&#125;&quot;) private String eurekaServer; //获取Eureka服务 @Value(&quot;$&#123;server.port&#125;&quot;) private String port; //获取服务端的端口号 @RequestMapping(&quot;/config&quot;) public String getConfig()&#123; return &quot;applicationName:&quot;+applicationName + &quot;eurekaServer:&quot;+eurekaServer + &quot;port:&quot;+port; &#125;&#125; 主启动类 1234567@SpringBootApplicationpublic class ConfigClient_3355 &#123; public static void main(String[] args) &#123; SpringApplication.run(ConfigClient_3355.class,args); &#125;&#125; 测试： 启动服务端Config_server_3344 再启动客户端ConfigClient 访问：http://localhost:8201/config/ 小案例本地新建config-dept.yml和config-eureka.yml并提交到码云仓库 config-dept.yml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566spring: profiles: active: dev---server: port: 8081mybatis: type-aliases-package: nuc.ss.springcloud.pojo config-location: classpath:mybatis/mybatis-config.xml mapper-locations: classpath:mybatis/mapper/*.xmlspring: profiles: dev application: name: springcloud-config-dept datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: org.gjt.mm.mysql.Driver url: jdbc:mysql://localhost:3306/db01?characterEncoding=utf-8&amp;useUnicode=true username: root password: admineureka: client: service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ instance: instance-id: springcloud-provider-dept-8081info: app.name: lzh-springcloud company.name: com.lzh---server: port: 8081mybatis: type-aliases-package: nuc.ss.springcloud.pojo config-location: classpath:mybatis/mybatis-config.xml mapper-locations: classpath:mybatis/mapper/*.xmlspring: profiles: test application: name: springcloud-config-dept datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: org.gjt.mm.mysql.Driver url: jdbc:mysql://localhost:3306/db02?characterEncoding=utf-8&amp;useUnicode=true username: root password: admineureka: client: service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ instance: instance-id: springcloud-provider-dept-8081info: app.name: lzh-springcloud company.name: com.lzh config-eureka.yml 1234567891011121314151617181920212223242526272829303132333435363738spring: profiles: active: dev---server: port: 7001spring: profiles: dev application: name: springcloud-config-eurekaeureka: instance: hostname: eureka7001.com client: register-with-eureka: false fetch-registry: false service-url: defaultZone: http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/---server: port: 7001spring: profiles: test application: name: springcloud-config-eurekaeureka: instance: hostname: eureka7001.com client: register-with-eureka: false fetch-registry: false service-url: defaultZone: http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ 上传成功 新建springcloud-config-eureka-7001模块，并将原来的springcloud-eureka-7001模块下的内容拷贝的该模块。 清空该模块的application.yml配置 1234spring: application: name: springcloud-config-eureka-7001 并新建bootstrap.yml连接远程配置 12345678spring: cloud: config: name: config-eureka # 仓库中的配置文件名称 label: main profile: dev uri: http://localhost:3344 在pom.xml中添加spring cloud config依赖 123456&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;version&gt;2.1.1.RELEASE&lt;/version&gt;&lt;/dependency&gt; 主启动类 12345678@SpringBootApplication@EnableEurekaServerpublic class EurekaServer_7001 &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServer_7001.class,args); &#125;&#125; 测试 启动 Config_Server_3344，并访问 http://localhost:3344/master/config-eureka-dev.yml 测试 启动ConfigEurekaServer_7001，访问 http://localhost:7001/ 测试 显示上图则成功 新建springcloud-config-dept-8081模块并拷贝springcloud-provider-dept-8081的内容 同理导入spring cloud config依赖、清空application.yml 、新建bootstrap.yml配置文件并配置 12345678spring: cloud: config: name: config-dept label: main profile: dev uri: http://localhost:3344 主启动类 12345678910111213141516171819//启动类@SpringBootApplication@EnableEurekaClient //在服务启动后自动注册到Eureka中@EnableDiscoveryClient //服务发现~@EnableCircuitBreaker//添加对熔断的支持public class DeptProvider_8081 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptProvider_8081.class,args); &#125; //增加一个 Servlet @Bean public ServletRegistrationBean hystrixMetricsStreamServlet()&#123; ServletRegistrationBean registrationBean = new ServletRegistrationBean(new HystrixMetricsStreamServlet()); //访问该页面就是监控页面 registrationBean.addUrlMappings(&quot;/actuator/hystrix.stream&quot;); return registrationBean; &#125;&#125; 只需更改github远程即可实现部署","categories":[],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://example.com/tags/SpringCloud/"}]},{"title":"Redis笔记","slug":"Redis笔记","date":"2021-01-17T09:52:18.000Z","updated":"2021-01-18T04:58:15.545Z","comments":true,"path":"2021/01/17/Redis笔记/","link":"","permalink":"http://example.com/2021/01/17/Redis%E7%AC%94%E8%AE%B0/","excerpt":"","text":"一、Nosql概述为什么使用Nosql 1、单机Mysql时代 90年代,一个网站的访问量一般不会太大，单个数据库完全够用。随着用户增多，网站出现以下问题 数据量增加到一定程度，单机数据库就放不下了 数据的索引（B+ Tree）,一个机器内存也存放不下 访问量变大后（读写混合），一台服务器承受不住。 2、Memcached(缓存) + Mysql + 垂直拆分（读写分离） 网站80%的情况都是在读，每次都要去查询数据库的话就十分的麻烦！所以说我们希望减轻数据库的压力，我们可以使用缓存来保证效率！ 优化过程经历了以下几个过程： 优化数据库的数据结构和索引(难度大) 文件缓存，通过IO流获取比每次都访问数据库效率略高，但是流量爆炸式增长时候，IO流也承受不了 MemCache,当时最热门的技术，通过在数据库和数据库访问层之间加上一层缓存，第一次访问时查询数据库，将结果保存到缓存，后续的查询先检查缓存，若有直接拿去使用，效率显著提升。 3、分库分表 + 水平拆分 + Mysql集群 4、如今最近的年代 如今信息量井喷式增长，各种各样的数据出现（用户定位数据，图片数据等），大数据的背景下关系型数据库（RDBMS）无法满足大量数据要求。Nosql数据库就能轻松解决这些问题。 目前一个基本的互联网项目 为什么要用NoSQL ？ 用户的个人信息，社交网络，地理位置。用户自己产生的数据，用户日志等等爆发式增长！这时候我们就需要使用NoSQL数据库的，Nosql可以很好的处理以上的情况！ 什么是NosqlNoSQL = Not Only SQL（不仅仅是SQL） Not Only Structured Query Language 关系型数据库：列+行，同一个表下数据的结构是一样的。 非关系型数据库：数据存储没有固定的格式，并且可以进行横向扩展。 NoSQL泛指非关系型数据库，随着web2.0互联网的诞生，传统的关系型数据库很难对付web2.0时代！尤其是超大规模的高并发的社区，暴露出来很多难以克服的问题，NoSQL在当今大数据环境下发展的十分迅速，Redis是发展最快的。 Nosql特点 方便扩展（数据之间没有关系，很好扩展！） 大数据量高性能（Redis一秒可以写8万次，读11万次，NoSQL的缓存记录级，是一种细粒度的缓存，性能会比较高！） 数据类型是多样型的！（不需要事先设计数据库，随取随用） 传统的 RDBMS 和 NoSQL 12345678传统的 RDBMS(关系型数据库)- 结构化组织- SQL- 数据和关系都存在单独的表中 row col- 操作，数据定义语言- 严格的一致性- 基础的事务- ... 12345678Nosql- 不仅仅是数据- 没有固定的查询语言- 键值对存储，列存储，文档存储，图形数据库（社交关系）- 最终一致性- CAP定理和BASE- 高性能，高可用，高扩展- ... 了解：3V + 3高 大数据时代的3V ：主要是描述问题的 海量Velume 多样Variety 实时Velocity 大数据时代的3高 ： 主要是对程序的要求 高并发 高可扩 高性能 真正在公司中的实践：NoSQL + RDBMS 一起使用才是最强的。 阿里巴巴演进分析推荐阅读：阿里云的这群疯子https://yq.aliyun.com/articles/653511 12345678910111213141516171819202122# 商品信息- 一般存放在关系型数据库：Mysql,阿里巴巴使用的Mysql都是经过内部改动的。# 商品描述、评论(文字居多)- 文档型数据库：MongoDB# 图片- 分布式文件系统 FastDFS- 淘宝：TFS- Google: GFS- Hadoop: HDFS- 阿里云: oss# 商品关键字 用于搜索- 搜索引擎：solr,elasticsearch- 阿里：Isearch 多隆# 商品热门的波段信息- 内存数据库：Redis，Memcache# 商品交易，外部支付接口- 第三方应用 Nosql的四大分类 KV键值对 新浪：Redis 美团：Redis + Tair 阿里、百度：Redis + Memcache 文档型数据库（bson数据格式）： MongoDB(掌握) 基于分布式文件存储的数据库。C++编写，用于处理大量文档。 MongoDB是RDBMS和NoSQL的中间产品。MongoDB是非关系型数据库中功能最丰富的，NoSQL中最像关系型数据库的数据库。 ConthDB 列存储数据库 HBase(大数据必学) 分布式文件系统 图关系数据库 用于广告推荐，社交网络 Neo4j、InfoGrid 分类 Examples举例 典型应用场景 数据模型 优点 缺点 键值对（key-value） Tokyo Cabinet/Tyrant, Redis, Voldemort, Oracle BDB 内容缓存，主要用于处理大量数据的高访问负载，也用于一些日志系统等等。 Key 指向 Value 的键值对，通常用hash table来实现 查找速度快 数据无结构化，通常只被当作字符串或者二进制数据 列存储数据库 Cassandra, HBase, Riak 分布式的文件系统 以列簇式存储，将同一列数据存在一起 查找速度快，可扩展性强，更容易进行分布式扩展 功能相对局限 文档型数据库 CouchDB, MongoDb Web应用（与Key-Value类似，Value是结构化的，不同的是数据库能够了解Value的内容） Key-Value对应的键值对，Value为结构化数据 数据结构要求不严格，表结构可变，不需要像关系型数据库一样需要预先定义表结构 查询性能不高，而且缺乏统一的查询语法。 图形(Graph)数据库 Neo4J, InfoGrid, Infinite Graph 社交网络，推荐系统等。专注于构建关系图谱 图结构 利用图结构相关算法。比如最短路径寻址，N度关系查找等 很多时候需要对整个图做计算才能得出需要的信息，而且这种结构不太好做分布式的集群 二、Redis入门概述 Redis是什么？ Redis（Remote Dictionary Server )，即远程字典服务。 是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。 与memcached一样，为了保证效率，数据都是缓存在内存中。区别的是redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave(主从)同步。 Redis能该干什么？ 内存存储、持久化，内存是断电即失的，所以需要持久化（RDB、AOF） 高效率、用于高速缓冲 发布订阅系统 地图信息分析 计时器、计数器(eg：浏览量) 。。。 特性 多样的数据类型 持久化 集群 事务 … 环境搭建官网：https://redis.io/ 推荐使用Linux服务器学习。 windows版本的Redis已经停更很久了… Windows安装https://github.com/dmajkic/redis 解压安装包 开启redis-server.exe 启动redis-cli.exe测试 Linux安装 下载安装包！redis-5.0.8.tar.gz 解压Redis的安装包！程序一般放在 /opt 目录下 基本环境安装 12345yum install gcc-c++# 然后进入redis目录下执行make# 然后执行make install redis默认安装路径 /usr/local/bin 将redis的配置文件复制到 程序安装目录 /usr/local/bin/kconfig下 redis默认不是后台启动的，需要修改配置文件！ 通过制定的配置文件启动redis服务 使用redis-cli连接指定的端口号测试，Redis的默认端口6379 查看redis进程是否开启 关闭Redis服务 shutdown 再次查看进程是否存在 后面我们会使用单机多Redis启动集群测试 测试性能redis-benchmark：Redis官方提供的性能测试工具，参数选项如下： 简单测试： 123# 测试：100个并发连接 100000请求redis-benchmark -h localhost -p 6379 -c 100 -n 10000012 基础知识 redis默认有16个数据库 默认使用的第0个; 16个数据库为：DB 0~DB 15默认使用DB 0 ，可以使用select n切换到DB n，dbsize可以查看当前数据库的大小，与key数量相关。 12345678910111213141516171819202122232425262728127.0.0.1:6379&gt; config get databases # 命令行查看数据库数量databases1) &quot;databases&quot;2) &quot;16&quot;127.0.0.1:6379&gt; select 8 # 切换数据库 DB 8OK127.0.0.1:6379[8]&gt; dbsize # 查看数据库大小(integer) 0# 不同数据库之间 数据是不能互通的，并且dbsize 是根据库中key的个数。127.0.0.1:6379&gt; set name sakura OK127.0.0.1:6379&gt; SELECT 8OK127.0.0.1:6379[8]&gt; get name # db8中并不能获取db0中的键值对。(nil)127.0.0.1:6379[8]&gt; DBSIZE(integer) 0127.0.0.1:6379[8]&gt; SELECT 0OK127.0.0.1:6379&gt; keys *1) &quot;counter:__rand_int__&quot;2) &quot;mylist&quot;3) &quot;name&quot;4) &quot;key:__rand_int__&quot;5) &quot;myset:__rand_int__&quot;127.0.0.1:6379&gt; DBSIZE # size和key个数相关(integer) 5 keys * ：查看当前数据库中所有的key。 flushdb：清空当前数据库中的键值对。 flushall：清空所有数据库的键值对。 Redis是单线程的，Redis是基于内存操作的。 所以Redis的性能瓶颈不是CPU,而是机器内存和网络带宽。 那么为什么Redis的速度如此快呢，性能这么高呢？QPS达到10W+ Redis为什么单线程还这么快？ 误区1：高性能的服务器一定是多线程的？ 误区2：多线程（CPU上下文会切换！）一定比单线程效率高！ 核心：Redis是将所有的数据放在内存中的，所以说使用单线程去操作效率就是最高的，多线程（CPU上下文会切换：耗时的操作！），对于内存系统来说，如果没有上下文切换效率就是最高的，多次读写都是在一个CPU上的，在内存存储数据情况下，单线程就是最佳的方案。 三、五大数据类型 Redis是一个开源（BSD许可），内存存储的数据结构服务器，可用作数据库，高速缓存和消息队列代理。它支持字符串、哈希表、列表、集合、有序集合，位图，hyperloglogs等数据类型。内置复制、Lua脚本、LRU收回、事务以及不同级别磁盘持久化功能，同时通过Redis Sentinel提供高可用，通过Redis Cluster提供自动分区。 Redis-key 在redis中无论什么数据类型，在数据库中都是以key-value形式保存，通过进行对Redis-key的操作，来完成对数据库中数据的操作。 下面学习的命令： exists key：判断键是否存在 del key：删除键值对 move key db：将键值对移动到指定数据库 expire key second：设置键值对的过期时间 type key：查看value的数据类型 1234567891011121314151617181920212223242526272829303132333435363738394041424344127.0.0.1:6379&gt; keys * # 查看当前数据库所有key(empty list or set)127.0.0.1:6379&gt; set name qinjiang # set keyOK127.0.0.1:6379&gt; set age 20OK127.0.0.1:6379&gt; keys *1) &quot;age&quot;2) &quot;name&quot;127.0.0.1:6379&gt; move age 1 # 将键值对移动到指定数据库(integer) 1127.0.0.1:6379&gt; EXISTS age # 判断键是否存在(integer) 0 # 不存在127.0.0.1:6379&gt; EXISTS name(integer) 1 # 存在127.0.0.1:6379&gt; SELECT 1OK127.0.0.1:6379[1]&gt; keys *1) &quot;age&quot;127.0.0.1:6379[1]&gt; del age # 删除键值对(integer) 1 # 删除个数127.0.0.1:6379&gt; set age 20OK127.0.0.1:6379&gt; EXPIRE age 15 # 设置键值对的过期时间(integer) 1 # 设置成功 开始计数127.0.0.1:6379&gt; ttl age # 查看key的过期剩余时间(integer) 13127.0.0.1:6379&gt; ttl age(integer) 11127.0.0.1:6379&gt; ttl age(integer) 9127.0.0.1:6379&gt; ttl age(integer) -2 # -2 表示key过期，-1表示key未设置过期时间127.0.0.1:6379&gt; get age # 过期的key 会被自动delete(nil)127.0.0.1:6379&gt; keys *1) &quot;name&quot;127.0.0.1:6379&gt; type name # 查看value的数据类型string 关于TTL命令 Redis的key，通过TTL命令返回key的过期时间，一般来说有3种： 当前key没有设置过期时间，所以会返回-1. 当前key有设置过期时间，而且key已经过期，所以会返回-2. 当前key有设置过期时间，且key还没有过期，故会返回key的正常剩余时间. 关于重命名RENAME和RENAMENX RENAME key newkey修改 key 的名称 RENAMENX key newkey仅当 newkey 不存在时，将 key 改名为 newkey 。 更多命令学习：https://www.redis.net.cn/order/ [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-wBVZtGVm-1597890996517)(狂神说 Redis.assets/image-20200813114228439.png)] String(字符串)普通的set、get直接略过。 命令 描述 示例 APPEND key value 向指定的key的value后追加字符串 127.0.0.1:6379&gt; set msg hello OK 127.0.0.1:6379&gt; append msg “ world” (integer) 11 127.0.0.1:6379&gt; get msg “hello world” DECR/INCR key 将指定key的value数值进行+1/-1(仅对于数字) 127.0.0.1:6379&gt; set age 20 OK 127.0.0.1:6379&gt; incr age (integer) 21 127.0.0.1:6379&gt; decr age (integer) 20 INCRBY/DECRBY key n 按指定的步长对数值进行加减 127.0.0.1:6379&gt; INCRBY age 5 (integer) 25 127.0.0.1:6379&gt; DECRBY age 10 (integer) 15 INCRBYFLOAT key n 为数值加上浮点型数值 127.0.0.1:6379&gt; INCRBYFLOAT age 5.2 “20.2” STRLEN key 获取key保存值的字符串长度 127.0.0.1:6379&gt; get msg “hello world” 127.0.0.1:6379&gt; STRLEN msg (integer) 11 GETRANGE key start end 按起止位置获取字符串（闭区间，起止位置都取） 127.0.0.1:6379&gt; get msg “hello world” 127.0.0.1:6379&gt; GETRANGE msg 3 9 “lo worl” SETRANGE key offset value 用指定的value 替换key中 offset开始的值 127.0.0.1:6379&gt; SETRANGE msg 2 hello (integer) 7 127.0.0.1:6379&gt; get msg “tehello” GETSET key value 将给定 key 的值设为 value ，并返回 key 的旧值(old value)。 127.0.0.1:6379&gt; GETSET msg test “hello world” SETNX key value 仅当key不存在时进行set 127.0.0.1:6379&gt; SETNX msg test (integer) 0 127.0.0.1:6379&gt; SETNX name sakura (integer) 1 SETEX key seconds value set 键值对并设置过期时间 127.0.0.1:6379&gt; setex name 10 root OK 127.0.0.1:6379&gt; get name (nil) MSET key1 value1 [key2 value2..] 批量set键值对 127.0.0.1:6379&gt; MSET k1 v1 k2 v2 k3 v3 OK MSETNX key1 value1 [key2 value2..] 批量设置键值对，仅当参数中所有的key都不存在时执行 127.0.0.1:6379&gt; MSETNX k1 v1 k4 v4 (integer) 0 MGET key1 [key2..] 批量获取多个key保存的值 127.0.0.1:6379&gt; MGET k1 k2 k3 1) “v1” 2) “v2” 3) “v3” PSETEX key milliseconds value 和 SETEX 命令相似，但它以毫秒为单位设置 key 的生存时间， getset key value 如果不存在值，则返回nil，如果存在值，获取原来的值，并设置新的值 String类似的使用场景：value除了是字符串还可以是数字，用途举例： 计数器 统计多单位的数量：uid:123666：follow 0 粉丝数 对象存储缓存 List(列表) Redis列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边） 一个列表最多可以包含 232 - 1 个元素 (4294967295, 每个列表超过40亿个元素)。 首先我们列表，可以经过规则定义将其变为队列、栈、双端队列等 正如图Redis中List是可以进行双端操作的，所以命令也就分为了LXXX和RLLL两类，有时候L也表示List例如LLEN 命令 描述 LPUSH/RPUSH key value1[value2..] 从左边/右边向列表中PUSH值(一个或者多个)。 LRANGE key start end 获取list 起止元素==（索引从左往右 递增）== LPUSHX/RPUSHX key value 向已存在的列名中push值（一个或者多个） `LINSERT key BEFORE AFTER pivot value` LLEN key 查看列表长度 LINDEX key index 通过索引获取列表元素 LSET key index value 通过索引为元素设值 LPOP/RPOP key 从最左边/最右边移除值 并返回 RPOPLPUSH source destination 将列表的尾部(右)最后一个值弹出，并返回，然后加到另一个列表的头部 LTRIM key start end 通过下标截取指定范围内的列表 LREM key count value List中是允许value重复的 count &gt; 0：从头部开始搜索 然后删除指定的value 至多删除count个 count &lt; 0：从尾部开始搜索… count = 0：删除列表中所有的指定value。 BLPOP/BRPOP key1[key2] timout 移出并获取列表的第一个/最后一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。 BRPOPLPUSH source destination timeout 和RPOPLPUSH功能相同，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129---------------------------LPUSH---RPUSH---LRANGE--------------------------------127.0.0.1:6379&gt; LPUSH mylist k1 # LPUSH mylist=&gt;&#123;1&#125;(integer) 1127.0.0.1:6379&gt; LPUSH mylist k2 # LPUSH mylist=&gt;&#123;2,1&#125;(integer) 2127.0.0.1:6379&gt; RPUSH mylist k3 # RPUSH mylist=&gt;&#123;2,1,3&#125;(integer) 3127.0.0.1:6379&gt; get mylist # 普通的get是无法获取list值的(error) WRONGTYPE Operation against a key holding the wrong kind of value127.0.0.1:6379&gt; LRANGE mylist 0 4 # LRANGE 获取起止位置范围内的元素1) &quot;k2&quot;2) &quot;k1&quot;3) &quot;k3&quot;127.0.0.1:6379&gt; LRANGE mylist 0 21) &quot;k2&quot;2) &quot;k1&quot;3) &quot;k3&quot;127.0.0.1:6379&gt; LRANGE mylist 0 11) &quot;k2&quot;2) &quot;k1&quot;127.0.0.1:6379&gt; LRANGE mylist 0 -1 # 获取全部元素1) &quot;k2&quot;2) &quot;k1&quot;3) &quot;k3&quot;---------------------------LPUSHX---RPUSHX-----------------------------------127.0.0.1:6379&gt; LPUSHX list v1 # list不存在 LPUSHX失败(integer) 0127.0.0.1:6379&gt; LPUSHX list v1 v2 (integer) 0127.0.0.1:6379&gt; LPUSHX mylist k4 k5 # 向mylist中 左边 PUSH k4 k5(integer) 5127.0.0.1:6379&gt; LRANGE mylist 0 -11) &quot;k5&quot;2) &quot;k4&quot;3) &quot;k2&quot;4) &quot;k1&quot;5) &quot;k3&quot;---------------------------LINSERT--LLEN--LINDEX--LSET----------------------------127.0.0.1:6379&gt; LINSERT mylist after k2 ins_key1 # 在k2元素后 插入ins_key1(integer) 6127.0.0.1:6379&gt; LRANGE mylist 0 -11) &quot;k5&quot;2) &quot;k4&quot;3) &quot;k2&quot;4) &quot;ins_key1&quot;5) &quot;k1&quot;6) &quot;k3&quot;127.0.0.1:6379&gt; LLEN mylist # 查看mylist的长度(integer) 6127.0.0.1:6379&gt; LINDEX mylist 3 # 获取下标为3的元素&quot;ins_key1&quot;127.0.0.1:6379&gt; LINDEX mylist 0&quot;k5&quot;127.0.0.1:6379&gt; LSET mylist 3 k6 # 将下标3的元素 set值为k6OK127.0.0.1:6379&gt; LRANGE mylist 0 -11) &quot;k5&quot;2) &quot;k4&quot;3) &quot;k2&quot;4) &quot;k6&quot;5) &quot;k1&quot;6) &quot;k3&quot;---------------------------LPOP--RPOP--------------------------127.0.0.1:6379&gt; LPOP mylist # 左侧(头部)弹出&quot;k5&quot;127.0.0.1:6379&gt; RPOP mylist # 右侧(尾部)弹出&quot;k3&quot;---------------------------RPOPLPUSH--------------------------127.0.0.1:6379&gt; LRANGE mylist 0 -11) &quot;k4&quot;2) &quot;k2&quot;3) &quot;k6&quot;4) &quot;k1&quot;127.0.0.1:6379&gt; RPOPLPUSH mylist newlist # 将mylist的最后一个值(k1)弹出，加入到newlist的头部&quot;k1&quot;127.0.0.1:6379&gt; LRANGE newlist 0 -11) &quot;k1&quot;127.0.0.1:6379&gt; LRANGE mylist 0 -11) &quot;k4&quot;2) &quot;k2&quot;3) &quot;k6&quot;---------------------------LTRIM--------------------------127.0.0.1:6379&gt; LTRIM mylist 0 1 # 截取mylist中的 0~1部分OK127.0.0.1:6379&gt; LRANGE mylist 0 -11) &quot;k4&quot;2) &quot;k2&quot;# 初始 mylist: k2,k2,k2,k2,k2,k2,k4,k2,k2,k2,k2---------------------------LREM--------------------------127.0.0.1:6379&gt; LREM mylist 3 k2 # 从头部开始搜索 至多删除3个 k2(integer) 3# 删除后：mylist: k2,k2,k2,k4,k2,k2,k2,k2127.0.0.1:6379&gt; LREM mylist -2 k2 #从尾部开始搜索 至多删除2个 k2(integer) 2# 删除后：mylist: k2,k2,k2,k4,k2,k2---------------------------BLPOP--BRPOP--------------------------mylist: k2,k2,k2,k4,k2,k2newlist: k1127.0.0.1:6379&gt; BLPOP newlist mylist 30 # 从newlist中弹出第一个值，mylist作为候选1) &quot;newlist&quot; # 弹出2) &quot;k1&quot;127.0.0.1:6379&gt; BLPOP newlist mylist 301) &quot;mylist&quot; # 由于newlist空了 从mylist中弹出2) &quot;k2&quot;127.0.0.1:6379&gt; BLPOP newlist 30(30.10s) # 超时了127.0.0.1:6379&gt; BLPOP newlist 30 # 我们连接另一个客户端向newlist中push了test, 阻塞被解决。1) &quot;newlist&quot;2) &quot;test&quot;(12.54s) 小结 list实际上是一个链表，before Node after , left, right 都可以插入值 如果key不存在，则创建新的链表 如果key存在，新增内容 如果移除了所有值，空链表，也代表不存在 在两边插入或者改动值，效率最高！修改中间元素，效率相对较低 应用： 消息排队！消息队列（Lpush Rpop）,栈（Lpush Lpop） Set(集合) Redis的Set是string类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据。 Redis 中 集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。 集合中最大的成员数为 232 - 1 (4294967295, 每个集合可存储40多亿个成员)。 命令 描述 SADD key member1[member2..] 向集合中无序增加一个/多个成员 SCARD key 获取集合的成员数 SMEMBERS key 返回集合中所有的成员 SISMEMBER key member 查询member元素是否是集合的成员,结果是无序的 SRANDMEMBER key [count] 随机返回集合中count个成员，count缺省值为1 SPOP key [count] 随机移除并返回集合中count个成员，count缺省值为1 SMOVE source destination member 将source集合的成员member移动到destination集合 SREM key member1[member2..] 移除集合中一个/多个成员 SDIFF key1[key2..] 返回所有集合的差集 key1- key2 - … SDIFFSTORE destination key1[key2..] 在SDIFF的基础上，将结果保存到集合中==(覆盖)==。不能保存到其他类型key噢！ SINTER key1 [key2..] 返回所有集合的交集 SINTERSTORE destination key1[key2..] 在SINTER的基础上，存储结果到集合中。覆盖 SUNION key1 [key2..] 返回所有集合的并集 SUNIONSTORE destination key1 [key2..] 在SUNION的基础上，存储结果到及和张。覆盖 SSCAN KEY [MATCH pattern] [COUNT count] 在大量数据环境下，使用此命令遍历集合中元素，每次遍历部分 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384---------------SADD--SCARD--SMEMBERS--SISMEMBER--------------------127.0.0.1:6379&gt; SADD myset m1 m2 m3 m4 # 向myset中增加成员 m1~m4(integer) 4127.0.0.1:6379&gt; SCARD myset # 获取集合的成员数目(integer) 4127.0.0.1:6379&gt; smembers myset # 获取集合中所有成员1) &quot;m4&quot;2) &quot;m3&quot;3) &quot;m2&quot;4) &quot;m1&quot;127.0.0.1:6379&gt; SISMEMBER myset m5 # 查询m5是否是myset的成员(integer) 0 # 不是，返回0127.0.0.1:6379&gt; SISMEMBER myset m2(integer) 1 # 是，返回1127.0.0.1:6379&gt; SISMEMBER myset m3(integer) 1---------------------SRANDMEMBER--SPOP----------------------------------127.0.0.1:6379&gt; SRANDMEMBER myset 3 # 随机返回3个成员1) &quot;m2&quot;2) &quot;m3&quot;3) &quot;m4&quot;127.0.0.1:6379&gt; SRANDMEMBER myset # 随机返回1个成员&quot;m3&quot;127.0.0.1:6379&gt; SPOP myset 2 # 随机移除并返回2个成员1) &quot;m1&quot;2) &quot;m4&quot;# 将set还原到&#123;m1,m2,m3,m4&#125;---------------------SMOVE--SREM----------------------------------------127.0.0.1:6379&gt; SMOVE myset newset m3 # 将myset中m3成员移动到newset集合(integer) 1127.0.0.1:6379&gt; SMEMBERS myset1) &quot;m4&quot;2) &quot;m2&quot;3) &quot;m1&quot;127.0.0.1:6379&gt; SMEMBERS newset1) &quot;m3&quot;127.0.0.1:6379&gt; SREM newset m3 # 从newset中移除m3元素(integer) 1127.0.0.1:6379&gt; SMEMBERS newset(empty list or set)# 下面开始是多集合操作,多集合操作中若只有一个参数默认和自身进行运算# setx=&gt;&#123;m1,m2,m4,m6&#125;, sety=&gt;&#123;m2,m5,m6&#125;, setz=&gt;&#123;m1,m3,m6&#125;-----------------------------SDIFF------------------------------------127.0.0.1:6379&gt; SDIFF setx sety setz # 等价于setx-sety-setz1) &quot;m4&quot;127.0.0.1:6379&gt; SDIFF setx sety # setx - sety1) &quot;m4&quot;2) &quot;m1&quot;127.0.0.1:6379&gt; SDIFF sety setx # sety - setx1) &quot;m5&quot;-------------------------SINTER---------------------------------------# 共同关注（交集）127.0.0.1:6379&gt; SINTER setx sety setz # 求 setx、sety、setx的交集1) &quot;m6&quot;127.0.0.1:6379&gt; SINTER setx sety # 求setx sety的交集1) &quot;m2&quot;2) &quot;m6&quot;-------------------------SUNION---------------------------------------127.0.0.1:6379&gt; SUNION setx sety setz # setx sety setz的并集1) &quot;m4&quot;2) &quot;m6&quot;3) &quot;m3&quot;4) &quot;m2&quot;5) &quot;m1&quot;6) &quot;m5&quot;127.0.0.1:6379&gt; SUNION setx sety # setx sety 并集1) &quot;m4&quot;2) &quot;m6&quot;3) &quot;m2&quot;4) &quot;m1&quot;5) &quot;m5&quot; Hash（哈希） Redis hash 是一个string类型的field和value的映射表，hash特别适合用于存储对象。 Set就是一种简化的Hash,只变动key,而value使用默认值填充。可以将一个Hash表作为一个对象进行存储，表中存放对象的信息。 命令 描述 HSET key field value 将哈希表 key 中的字段 field 的值设为 value 。重复设置同一个field会覆盖,返回0 HMSET key field1 value1 [field2 value2..] 同时将多个 field-value (域-值)对设置到哈希表 key 中。 HSETNX key field value 只有在字段 field 不存在时，设置哈希表字段的值。 HEXISTS key field 查看哈希表 key 中，指定的字段是否存在。 HGET key field value 获取存储在哈希表中指定字段的值 HMGET key field1 [field2..] 获取所有给定字段的值 HGETALL key 获取在哈希表key 的所有字段和值 HKEYS key 获取哈希表key中所有的字段 HLEN key 获取哈希表中字段的数量 HVALS key 获取哈希表中所有值 HDEL key field1 [field2..] 删除哈希表key中一个/多个field字段 HINCRBY key field n 为哈希表 key 中的指定字段的整数值加上增量n，并返回增量后结果 一样只适用于整数型字段 HINCRBYFLOAT key field n 为哈希表 key 中的指定字段的浮点数值加上增量 n。 HSCAN key cursor [MATCH pattern] [COUNT count] 迭代哈希表中的键值对。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071------------------------HSET--HMSET--HSETNX----------------127.0.0.1:6379&gt; HSET studentx name sakura # 将studentx哈希表作为一个对象，设置name为sakura(integer) 1127.0.0.1:6379&gt; HSET studentx name gyc # 重复设置field进行覆盖，并返回0(integer) 0127.0.0.1:6379&gt; HSET studentx age 20 # 设置studentx的age为20(integer) 1127.0.0.1:6379&gt; HMSET studentx sex 1 tel 15623667886 # 设置sex为1，tel为15623667886OK127.0.0.1:6379&gt; HSETNX studentx name gyc # HSETNX 设置已存在的field(integer) 0 # 失败127.0.0.1:6379&gt; HSETNX studentx email 12345@qq.com(integer) 1 # 成功----------------------HEXISTS--------------------------------127.0.0.1:6379&gt; HEXISTS studentx name # name字段在studentx中是否存在(integer) 1 # 存在127.0.0.1:6379&gt; HEXISTS studentx addr(integer) 0 # 不存在-------------------HGET--HMGET--HGETALL-----------127.0.0.1:6379&gt; HGET studentx name # 获取studentx中name字段的value&quot;gyc&quot;127.0.0.1:6379&gt; HMGET studentx name age tel # 获取studentx中name、age、tel字段的value1) &quot;gyc&quot;2) &quot;20&quot;3) &quot;15623667886&quot;127.0.0.1:6379&gt; HGETALL studentx # 获取studentx中所有的field及其value 1) &quot;name&quot; 2) &quot;gyc&quot; 3) &quot;age&quot; 4) &quot;20&quot; 5) &quot;sex&quot; 6) &quot;1&quot; 7) &quot;tel&quot; 8) &quot;15623667886&quot; 9) &quot;email&quot;10) &quot;12345@qq.com&quot;--------------------HKEYS--HLEN--HVALS--------------127.0.0.1:6379&gt; HKEYS studentx # 查看studentx中所有的field1) &quot;name&quot;2) &quot;age&quot;3) &quot;sex&quot;4) &quot;tel&quot;5) &quot;email&quot;127.0.0.1:6379&gt; HLEN studentx # 查看studentx中的字段数量(integer) 5127.0.0.1:6379&gt; HVALS studentx # 查看studentx中所有的value1) &quot;gyc&quot;2) &quot;20&quot;3) &quot;1&quot;4) &quot;15623667886&quot;5) &quot;12345@qq.com&quot;-------------------------HDEL--------------------------127.0.0.1:6379&gt; HDEL studentx sex tel # 删除studentx 中的sex、tel字段(integer) 2127.0.0.1:6379&gt; HKEYS studentx1) &quot;name&quot;2) &quot;age&quot;3) &quot;email&quot;-------------HINCRBY--HINCRBYFLOAT------------------------127.0.0.1:6379&gt; HINCRBY studentx age 1 # studentx的age字段数值+1(integer) 21127.0.0.1:6379&gt; HINCRBY studentx name 1 # 非整数字型字段不可用(error) ERR hash value is not an integer127.0.0.1:6379&gt; HINCRBYFLOAT studentx weight 0.6 # weight字段增加0.6&quot;90.8&quot; Hash变更的数据user name age，尤其是用户信息之类的，经常变动的信息！Hash更适合于对象的存储，Sring更加适合字符串存储！ Zset（有序集合） 不同的是每个元素都会关联一个double类型的分数（score）。redis正是通过分数来为集合中的成员进行从小到大的排序。 score相同：按字典顺序排序 有序集合的成员是唯一的,但分数(score)却可以重复。 命令 描述 ZADD key score member1 [score2 member2] 向有序集合添加一个或多个成员，或者更新已存在成员的分数 ZCARD key 获取有序集合的成员数 ZCOUNT key min max 计算在有序集合中指定区间score的成员数 ZINCRBY key n member 有序集合中对指定成员的分数加上增量 n ZSCORE key member 返回有序集中，成员的分数值 ZRANK key member 返回有序集合中指定成员的索引 ZRANGE key start end 通过索引区间返回有序集合成指定区间内的成员 ZRANGEBYLEX key min max 通过字典区间返回有序集合的成员 ZRANGEBYSCORE key min max 通过分数返回有序集合指定区间内的成员==-inf 和 +inf分别表示最小最大值，只支持开区间()== ZLEXCOUNT key min max 在有序集合中计算指定字典区间内成员数量 ZREM key member1 [member2..] 移除有序集合中一个/多个成员 ZREMRANGEBYLEX key min max 移除有序集合中给定的字典区间的所有成员 ZREMRANGEBYRANK key start stop 移除有序集合中给定的排名区间的所有成员 ZREMRANGEBYSCORE key min max 移除有序集合中给定的分数区间的所有成员 ZREVRANGE key start end 返回有序集中指定区间内的成员，通过索引，分数从高到底 ZREVRANGEBYSCORRE key max min 返回有序集中指定分数区间内的成员，分数从高到低排序 ZREVRANGEBYLEX key max min 返回有序集中指定字典区间内的成员，按字典顺序倒序 ZREVRANK key member 返回有序集合中指定成员的排名，有序集成员按分数值递减(从大到小)排序 ZINTERSTORE destination numkeys key1 [key2 ..] 计算给定的一个或多个有序集的交集并将结果集存储在新的有序集合 key 中，numkeys：表示参与运算的集合数，将score相加作为结果的score ZUNIONSTORE destination numkeys key1 [key2..] 计算给定的一个或多个有序集的交集并将结果集存储在新的有序集合 key 中 ZSCAN key cursor [MATCH pattern\\] [COUNT count] 迭代有序集合中的元素（包括元素成员和元素分值） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137-------------------ZADD--ZCARD--ZCOUNT--------------127.0.0.1:6379&gt; ZADD myzset 1 m1 2 m2 3 m3 # 向有序集合myzset中添加成员m1 score=1 以及成员m2 score=2..(integer) 2127.0.0.1:6379&gt; ZCARD myzset # 获取有序集合的成员数(integer) 2127.0.0.1:6379&gt; ZCOUNT myzset 0 1 # 获取score在 [0,1]区间的成员数量(integer) 1127.0.0.1:6379&gt; ZCOUNT myzset 0 2(integer) 2----------------ZINCRBY--ZSCORE--------------------------127.0.0.1:6379&gt; ZINCRBY myzset 5 m2 # 将成员m2的score +5&quot;7&quot;127.0.0.1:6379&gt; ZSCORE myzset m1 # 获取成员m1的score&quot;1&quot;127.0.0.1:6379&gt; ZSCORE myzset m2&quot;7&quot;--------------ZRANK--ZRANGE-----------------------------------127.0.0.1:6379&gt; ZRANK myzset m1 # 获取成员m1的索引，索引按照score排序，score相同索引值按字典顺序顺序增加(integer) 0127.0.0.1:6379&gt; ZRANK myzset m2(integer) 2127.0.0.1:6379&gt; ZRANGE myzset 0 1 # 获取索引在 0~1的成员1) &quot;m1&quot;2) &quot;m3&quot;127.0.0.1:6379&gt; ZRANGE myzset 0 -1 # 获取全部成员1) &quot;m1&quot;2) &quot;m3&quot;3) &quot;m2&quot;#testset=&gt;&#123;abc,add,amaze,apple,back,java,redis&#125; score均为0------------------ZRANGEBYLEX---------------------------------127.0.0.1:6379&gt; ZRANGEBYLEX testset - + # 返回所有成员1) &quot;abc&quot;2) &quot;add&quot;3) &quot;amaze&quot;4) &quot;apple&quot;5) &quot;back&quot;6) &quot;java&quot;7) &quot;redis&quot;127.0.0.1:6379&gt; ZRANGEBYLEX testset - + LIMIT 0 3 # 分页 按索引显示查询结果的 0,1,2条记录1) &quot;abc&quot;2) &quot;add&quot;3) &quot;amaze&quot;127.0.0.1:6379&gt; ZRANGEBYLEX testset - + LIMIT 3 3 # 显示 3,4,5条记录1) &quot;apple&quot;2) &quot;back&quot;3) &quot;java&quot;127.0.0.1:6379&gt; ZRANGEBYLEX testset (- [apple # 显示 (-,apple] 区间内的成员1) &quot;abc&quot;2) &quot;add&quot;3) &quot;amaze&quot;4) &quot;apple&quot;127.0.0.1:6379&gt; ZRANGEBYLEX testset [apple [java # 显示 [apple,java]字典区间的成员1) &quot;apple&quot;2) &quot;back&quot;3) &quot;java&quot;-----------------------ZRANGEBYSCORE---------------------127.0.0.1:6379&gt; ZRANGEBYSCORE myzset 1 10 # 返回score在 [1,10]之间的的成员1) &quot;m1&quot;2) &quot;m3&quot;3) &quot;m2&quot;127.0.0.1:6379&gt; ZRANGEBYSCORE myzset 1 51) &quot;m1&quot;2) &quot;m3&quot;--------------------ZLEXCOUNT-----------------------------127.0.0.1:6379&gt; ZLEXCOUNT testset - +(integer) 7127.0.0.1:6379&gt; ZLEXCOUNT testset [apple [java(integer) 3------------------ZREM--ZREMRANGEBYLEX--ZREMRANGBYRANK--ZREMRANGEBYSCORE--------------------------------127.0.0.1:6379&gt; ZREM testset abc # 移除成员abc(integer) 1127.0.0.1:6379&gt; ZREMRANGEBYLEX testset [apple [java # 移除字典区间[apple,java]中的所有成员(integer) 3127.0.0.1:6379&gt; ZREMRANGEBYRANK testset 0 1 # 移除排名0~1的所有成员(integer) 2127.0.0.1:6379&gt; ZREMRANGEBYSCORE myzset 0 3 # 移除score在 [0,3]的成员(integer) 2# testset=&gt; &#123;abc,add,apple,amaze,back,java,redis&#125; score均为0# myzset=&gt; &#123;(m1,1),(m2,2),(m3,3),(m4,4),(m7,7),(m9,9)&#125;----------------ZREVRANGE--ZREVRANGEBYSCORE--ZREVRANGEBYLEX-----------127.0.0.1:6379&gt; ZREVRANGE myzset 0 3 # 按score递减排序，然后按索引，返回结果的 0~31) &quot;m9&quot;2) &quot;m7&quot;3) &quot;m4&quot;4) &quot;m3&quot;127.0.0.1:6379&gt; ZREVRANGE myzset 2 4 # 返回排序结果的 索引的2~41) &quot;m4&quot;2) &quot;m3&quot;3) &quot;m2&quot;127.0.0.1:6379&gt; ZREVRANGEBYSCORE myzset 6 2 # 按score递减顺序 返回集合中分数在[2,6]之间的成员1) &quot;m4&quot;2) &quot;m3&quot;3) &quot;m2&quot;127.0.0.1:6379&gt; ZREVRANGEBYLEX testset [java (add # 按字典倒序 返回集合中(add,java]字典区间的成员1) &quot;java&quot;2) &quot;back&quot;3) &quot;apple&quot;4) &quot;amaze&quot;-------------------------ZREVRANK------------------------------127.0.0.1:6379&gt; ZREVRANK myzset m7 # 按score递减顺序，返回成员m7索引(integer) 1127.0.0.1:6379&gt; ZREVRANK myzset m2(integer) 4# mathscore=&gt;&#123;(xm,90),(xh,95),(xg,87)&#125; 小明、小红、小刚的数学成绩# enscore=&gt;&#123;(xm,70),(xh,93),(xg,90)&#125; 小明、小红、小刚的英语成绩-------------------ZINTERSTORE--ZUNIONSTORE-----------------------------------127.0.0.1:6379&gt; ZINTERSTORE sumscore 2 mathscore enscore # 将mathscore enscore进行合并 结果存放到sumscore(integer) 3127.0.0.1:6379&gt; ZRANGE sumscore 0 -1 withscores # 合并后的score是之前集合中所有score的和1) &quot;xm&quot;2) &quot;160&quot;3) &quot;xg&quot;4) &quot;177&quot;5) &quot;xh&quot;6) &quot;188&quot;127.0.0.1:6379&gt; ZUNIONSTORE lowestscore 2 mathscore enscore AGGREGATE MIN # 取两个集合的成员score最小值作为结果的(integer) 3127.0.0.1:6379&gt; ZRANGE lowestscore 0 -1 withscores1) &quot;xm&quot;2) &quot;70&quot;3) &quot;xg&quot;4) &quot;87&quot;5) &quot;xh&quot;6) &quot;93&quot; 应用案例： set排序 存储班级成绩表 工资表排序！ 普通消息，1.重要消息 2.带权重进行判断 排行榜应用实现，取Top N测试 四、三种特殊数据类型Geospatial(地理位置) 使用经纬度定位地理坐标并用一个有序集合zset保存，所以zset命令也可以使用 命令 描述 geoadd key longitud(经度) latitude(纬度) member [..] 将具体经纬度的坐标存入一个有序集合 geopos key member [member..] 获取集合中的一个/多个成员坐标 geodist key member1 member2 [unit] 返回两个给定位置之间的距离。默认以米作为单位。 `georadius key longitude latitude radius m km GEORADIUSBYMEMBER key member radius... 功能与GEORADIUS相同，只是中心位置不是具体的经纬度，而是使用结合中已有的成员作为中心点。 geohash key member1 [member2..] 返回一个或多个位置元素的Geohash表示。使用Geohash位置52点整数编码。 有效经纬度 有效的经度从-180度到180度。 有效的纬度从-85.05112878度到85.05112878度。 指定单位的参数 unit 必须是以下单位的其中一个： m 表示单位为米。 km 表示单位为千米。 mi 表示单位为英里。 ft 表示单位为英尺。 关于GEORADIUS的参数 通过georadius就可以完成 附近的人功能 withcoord:带上坐标 withdist:带上距离，单位与半径单位相同 COUNT n : 只显示前n个(按距离递增排序) 12345678910111213141516----------------georadius---------------------127.0.0.1:6379&gt; GEORADIUS china:city 120 30 500 km withcoord withdist # 查询经纬度(120,30)坐标500km半径内的成员1) 1) &quot;hangzhou&quot; 2) &quot;29.4151&quot; 3) 1) &quot;120.20000249147415&quot; 2) &quot;30.199999888333501&quot;2) 1) &quot;shanghai&quot; 2) &quot;205.3611&quot; 3) 1) &quot;121.40000134706497&quot; 2) &quot;31.400000253193539&quot; ------------geohash---------------------------127.0.0.1:6379&gt; geohash china:city yichang shanghai # 获取成员经纬坐标的geohash表示1) &quot;wmrjwbr5250&quot;2) &quot;wtw6ds0y300&quot; Hyperloglog(基数统计) Redis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。 花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数。 因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。 其底层使用string数据类型 什么是基数？ 数据集中不重复的元素的个数。 应用场景： 网页的访问量（UV）：一个用户多次访问，也只能算作一个人。 传统实现，存储用户的id,然后每次进行比较。当用户变多之后这种方式及其浪费空间，而我们的目的只是计数，Hyperloglog就能帮助我们利用最小的空间完成。 命令 描述 PFADD key element1 [elememt2..] 添加指定元素到 HyperLogLog 中 PFCOUNT key [key] 返回给定 HyperLogLog 的基数估算值。 PFMERGE destkey sourcekey [sourcekey..] 将多个 HyperLogLog 合并为一个 HyperLogLog 1234567891011121314151617----------PFADD--PFCOUNT---------------------127.0.0.1:6379&gt; PFADD myelemx a b c d e f g h i j k # 添加元素(integer) 1127.0.0.1:6379&gt; type myelemx # hyperloglog底层使用Stringstring127.0.0.1:6379&gt; PFCOUNT myelemx # 估算myelemx的基数(integer) 11127.0.0.1:6379&gt; PFADD myelemy i j k z m c b v p q s(integer) 1127.0.0.1:6379&gt; PFCOUNT myelemy(integer) 11----------------PFMERGE-----------------------127.0.0.1:6379&gt; PFMERGE myelemz myelemx myelemy # 合并myelemx和myelemy 成为myelemzOK127.0.0.1:6379&gt; PFCOUNT myelemz # 估算基数(integer) 17 如果允许容错，那么一定可以使用Hyperloglog ! 如果不允许容错，就使用set或者自己的数据类型即可 ！ BitMaps(位图) 使用位存储，信息状态只有 0 和 1 Bitmap是一串连续的2进制数字（0或1），每一位所在的位置为偏移(offset)，在bitmap上可执行AND,OR,XOR,NOT以及其它位操作。 应用场景 签到统计、状态统计 命令 描述 setbit key offset value 为指定key的offset位设置值 getbit key offset 获取offset位的值 bitcount key [start end] 统计字符串被设置为1的bit数，也可以指定统计范围按字节 bitop operration destkey key[key..] 对一个或多个保存二进制位的字符串 key 进行位元操作，并将结果保存到 destkey 上。 BITPOS key bit [start] [end] 返回字符串里面第一个被设置为1或者0的bit位。start和end只能按字节,不能按位 1234567891011121314151617181920212223------------setbit--getbit--------------127.0.0.1:6379&gt; setbit sign 0 1 # 设置sign的第0位为 1 (integer) 0127.0.0.1:6379&gt; setbit sign 2 1 # 设置sign的第2位为 1 不设置默认 是0(integer) 0127.0.0.1:6379&gt; setbit sign 3 1(integer) 0127.0.0.1:6379&gt; setbit sign 5 1(integer) 0127.0.0.1:6379&gt; type signstring127.0.0.1:6379&gt; getbit sign 2 # 获取第2位的数值(integer) 1127.0.0.1:6379&gt; getbit sign 3(integer) 1127.0.0.1:6379&gt; getbit sign 4 # 未设置默认是0(integer) 0-----------bitcount----------------------------127.0.0.1:6379&gt; BITCOUNT sign # 统计sign中为1的位数(integer) 4 bitmaps的底层 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-9PlszjhS-1597890996519)(D:\\我\\MyBlog\\狂神说 Redis.assets\\image-20200803234336175.png)] 这样设置以后你能get到的值是：\\xA2\\x80，所以bitmaps是一串从左到右的二进制串 五、事务Redis的单条命令是保证原子性的，但是redis事务不能保证原子性 Redis事务本质：一组命令的集合。 —————– 队列 set set set 执行 ——————- 事务中每条命令都会被序列化，执行过程中按顺序执行，不允许其他命令进行干扰。 一次性 顺序性 排他性 Redis事务没有隔离级别的概念 Redis单条命令是保证原子性的，但是事务不保证原子性！ Redis事务操作过程 开启事务（multi） 命令入队 执行事务（exec） 所以事务中的命令在加入时都没有被执行，直到提交时才会开始执行(Exec)一次性完成。 123456789101112131415161718192021127.0.0.1:6379&gt; multi # 开启事务OK127.0.0.1:6379&gt; set k1 v1 # 命令入队QUEUED127.0.0.1:6379&gt; set k2 v2 # ..QUEUED127.0.0.1:6379&gt; get k1QUEUED127.0.0.1:6379&gt; set k3 v3QUEUED127.0.0.1:6379&gt; keys *QUEUED127.0.0.1:6379&gt; exec # 事务执行1) OK2) OK3) &quot;v1&quot;4) OK5) 1) &quot;k3&quot; 2) &quot;k2&quot; 3) &quot;k1&quot; 取消事务(discurd) 12345678910111213127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set k1 v1QUEUED127.0.0.1:6379&gt; set k2 v2QUEUED127.0.0.1:6379&gt; DISCARD # 放弃事务OK127.0.0.1:6379&gt; EXEC (error) ERR EXEC without MULTI # 当前未开启事务127.0.0.1:6379&gt; get k1 # 被放弃事务中命令并未执行(nil) 事务错误 代码语法错误（编译时异常）所有的命令都不执行 123456789101112131415127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set k1 v1QUEUED127.0.0.1:6379&gt; set k2 v2QUEUED127.0.0.1:6379&gt; error k1 # 这是一条语法错误命令(error) ERR unknown command `error`, with args beginning with: `k1`, # 会报错但是不影响后续命令入队 127.0.0.1:6379&gt; get k2QUEUED127.0.0.1:6379&gt; EXEC(error) EXECABORT Transaction discarded because of previous errors. # 执行报错127.0.0.1:6379&gt; get k1 (nil) # 其他命令并没有被执行 代码逻辑错误 (运行时异常) **其他命令可以正常执行 ** &gt;&gt;&gt; 所以不保证事务原子性 12345678910111213141516171819127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set k1 v1QUEUED127.0.0.1:6379&gt; set k2 v2QUEUED127.0.0.1:6379&gt; INCR k1 # 这条命令逻辑错误（对字符串进行增量）QUEUED127.0.0.1:6379&gt; get k2QUEUED127.0.0.1:6379&gt; exec1) OK2) OK3) (error) ERR value is not an integer or out of range # 运行时报错4) &quot;v2&quot; # 其他命令正常执行# 虽然中间有一条命令报错了，但是后面的指令依旧正常执行成功了。# 所以说Redis单条指令保证原子性，但是Redis事务不能保证原子性。 监控悲观锁： 很悲观，认为什么时候都会出现问题，无论做什么都会加锁 乐观锁： 很乐观，认为什么时候都不会出现问题，所以不会上锁！更新数据的时候去判断一下，在此期间是否有人修改过这个数据 获取version 更新的时候比较version 使用watch key监控指定数据，相当于乐观锁加锁。 正常执行 12345678910111213141516127.0.0.1:6379&gt; set money 100 # 设置余额:100OK127.0.0.1:6379&gt; set use 0 # 支出使用:0OK127.0.0.1:6379&gt; watch money # 监视money (上锁)OK127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; DECRBY money 20QUEUED127.0.0.1:6379&gt; INCRBY use 20QUEUED127.0.0.1:6379&gt; exec # 监视值没有被中途修改，事务正常执行1) (integer) 802) (integer) 20 测试多线程修改值，使用watch可以当做redis的乐观锁操作（相当于getversion） 我们启动另外一个客户端模拟插队线程。 线程1： 12345678910127.0.0.1:6379&gt; watch money # money上锁OK127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; DECRBY money 20QUEUED127.0.0.1:6379&gt; INCRBY use 20QUEUED127.0.0.1:6379&gt; # 此时事务并没有执行 模拟线程插队，线程2： 1234127.0.0.1:6379&gt; INCRBY money 500 # 修改了线程一中监视的money(integer) 60012 回到线程1，执行事务： 1234567127.0.0.1:6379&gt; EXEC # 执行之前，另一个线程修改了我们的值，这个时候就会导致事务执行失败(nil) # 没有结果，说明事务执行失败127.0.0.1:6379&gt; get money # 线程2 修改生效&quot;600&quot;127.0.0.1:6379&gt; get use # 线程1事务执行失败，数值没有被修改&quot;0&quot; 解锁获取最新值，然后再加锁进行事务。 unwatch进行解锁。 注意：每次提交执行exec后都会自动释放锁，不管是否成功 六、Jedis使用Java来操作Redis，Jedis是Redis官方推荐使用的Java连接redis的客户端。 导入依赖 123456789101112&lt;!--导入jredis的包--&gt;&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt;&lt;/dependency&gt;&lt;!--fastjson--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.70&lt;/version&gt;&lt;/dependency&gt; 编码测试 连接数据库 修改redis的配置文件 123vim /usr/local/bin/myconfig/redis.conf1 将只绑定本地注释 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-4IRUFJ95-1597890996520)(狂神说 Redis.assets/image-20200813161921480.png)] 保护模式改为 no [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-oKjIVapw-1597890996521)(狂神说 Redis.assets/image-20200813161939847.png)] 允许后台运行 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-c2IMvpZL-1597890996522)(狂神说 Redis.assets/image-20200813161954567.png)] 开放端口6379 123firewall-cmd --zone=public --add-port=6379/tcp --permanet1 重启防火墙服务 123systemctl restart firewalld.service1 阿里云服务器控制台配置安全组 重启redis-server 123[root@AlibabaECS bin]# redis-server myconfig/redis.conf 1 操作命令 TestPing.java 12345678public class TestPing &#123; public static void main(String[] args) &#123; Jedis jedis = new Jedis(&quot;192.168.xx.xxx&quot;, 6379); String response = jedis.ping(); System.out.println(response); // PONG &#125;&#125; 断开连接 事务 12345678910111213141516171819202122232425262728public class TestTX &#123; public static void main(String[] args) &#123; Jedis jedis = new Jedis(&quot;39.99.xxx.xx&quot;, 6379); JSONObject jsonObject = new JSONObject(); jsonObject.put(&quot;hello&quot;, &quot;world&quot;); jsonObject.put(&quot;name&quot;, &quot;kuangshen&quot;); // 开启事务 Transaction multi = jedis.multi(); String result = jsonObject.toJSONString(); // jedis.watch(result) try &#123; multi.set(&quot;user1&quot;, result); multi.set(&quot;user2&quot;, result); // 执行事务 multi.exec(); &#125;catch (Exception e)&#123; // 放弃事务 multi.discard(); &#125; finally &#123; // 关闭连接 System.out.println(jedis.get(&quot;user1&quot;)); System.out.println(jedis.get(&quot;user2&quot;)); jedis.close(); &#125; &#125;&#125; 七、SpringBoot整合 导入依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; springboot 2.x后 ，原来使用的 Jedis 被 lettuce 替换。 jedis：采用的直连，多个线程操作的话，是不安全的。如果要避免不安全，使用jedis pool连接池！更像BIO模式 lettuce：采用netty，实例可以在多个线程中共享，不存在线程不安全的情况！可以减少线程数据了，更像NIO模式 我们在学习SpringBoot自动配置的原理时，整合一个组件并进行配置一定会有一个自动配置类xxxAutoConfiguration,并且在spring.factories中也一定能找到这个类的完全限定名。Redis也不例外。 那么就一定还存在一个RedisProperties类 之前我们说SpringBoot2.x后默认使用Lettuce来替换Jedis，现在我们就能来验证了。 先看Jedis: @ConditionalOnClass注解中有两个类是默认不存在的，所以Jedis是无法生效的 然后再看Lettuce： 完美生效。 现在我们回到RedisAutoConfiguratio 只有两个简单的Bean RedisTemplate StringRedisTemplate 当看到xxTemplate时可以对比RestTemplat、SqlSessionTemplate,通过使用这些Template来间接操作组件。那么这俩也不会例外。分别用于操作Redis和Redis中的String数据类型。 在RedisTemplate上也有一个条件注解，说明我们是可以对其进行定制化的 说完这些，我们需要知道如何编写配置文件然后连接Redis，就需要阅读RedisProperties 这是一些基本的配置属性。 还有一些连接池相关的配置。注意使用时一定使用Lettuce的连接池。 编写配置文件 1234# 配置redisspring.redis.host=39.99.xxx.xxspring.redis.port=6379 使用RedisTemplate 1234567891011121314151617181920212223242526@SpringBootTestclass Redis02SpringbootApplicationTests &#123; @Autowired private RedisTemplate redisTemplate; @Test void contextLoads() &#123; // redisTemplate 操作不同的数据类型，api和我们的指令是一样的 // opsForValue 操作字符串 类似String // opsForList 操作List 类似List // opsForHah // 除了基本的操作，我们常用的方法都可以直接通过redisTemplate操作，比如事务和基本的CRUD // 获取连接对象 //RedisConnection connection = redisTemplate.getConnectionFactory().getConnection(); //connection.flushDb(); //connection.flushAll(); redisTemplate.opsForValue().set(&quot;mykey&quot;,&quot;kuangshen&quot;); System.out.println(redisTemplate.opsForValue().get(&quot;mykey&quot;)); &#125;&#125; 测试结果 此时我们回到Redis查看数据时候，惊奇发现全是乱码，可是程序中可以正常输出： 这时候就关系到存储对象的序列化问题，在网络中传输的对象也是一样需要序列化，否者就全是乱码。 我们转到看那个默认的RedisTemplate内部什么样子： 在最开始就能看到几个关于序列化的参数。 默认的序列化器是采用JDK序列化器 而默认的RedisTemplate中的所有序列化器都是使用这个序列化器： 后续我们定制RedisTemplate就可以对其进行修改。 RedisSerializer提供了多种序列化方案： 直接调用RedisSerializer的静态方法来返回序列化器，然后set 自己new 相应的实现类，然后set 定制RedisTemplate的模板： 我们创建一个Bean加入容器，就会触发RedisTemplate上的条件注解使默认的RedisTemplate失效。 123456789101112131415161718192021222324@Configurationpublic class RedisConfig &#123; @Bean public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException &#123; // 将template 泛型设置为 &lt;String, Object&gt; RedisTemplate&lt;String, Object&gt; template = new RedisTemplate(); // 连接工厂，不必修改 template.setConnectionFactory(redisConnectionFactory); /* * 序列化设置 */ // key、hash的key 采用 String序列化方式 template.setKeySerializer(RedisSerializer.string()); template.setHashKeySerializer(RedisSerializer.string()); // value、hash的value 采用 Jackson 序列化方式 template.setValueSerializer(RedisSerializer.json()); template.setHashValueSerializer(RedisSerializer.json()); template.afterPropertiesSet(); return template; &#125;&#125; 这样一来，只要实体类进行了序列化，我们存什么都不会有乱码的担忧了。 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-oc8kJP08-1597890996523)(狂神说 Redis.assets/image-20200817175638086.png)] 八、自定义Redis工具类使用RedisTemplate需要频繁调用.opForxxx然后才能进行对应的操作，这样使用起来代码效率低下，工作中一般不会这样使用，而是将这些常用的公共API抽取出来封装成为一个工具类，然后直接使用工具类来间接操作Redis,不但效率高并且易用。 工具类参考博客： https://www.cnblogs.com/zeng1994/p/03303c805731afc9aa9c60dbbd32a323.html https://www.cnblogs.com/zhzhlong/p/11434284.html 九、Redis.conf 容量单位不区分大小写，G和GB有区别 可以使用 include 组合多个配置问题 网络配置 日志输出级别 日志输出文件 持久化规则 由于Redis是基于内存的数据库，需要将数据由内存持久化到文件中 持久化方式： RDB AOF RDB文件相关 主从复制 Security模块中进行密码设置 客户端连接相关 1234maxclients 10000 最大客户端数量maxmemory &lt;bytes&gt; 最大内存限制maxmemory-policy noeviction # 内存达到限制值的处理策略 redis 中的默认的过期策略是 volatile-lru 。 设置方式 123config set maxmemory-policy volatile-lru 1 maxmemory-policy 六种方式1、volatile-lru：只对设置了过期时间的key进行LRU（默认值） 2、allkeys-lru ： 删除lru算法的key 3、volatile-random：随机删除即将过期key 4、allkeys-random：随机删除 5、volatile-ttl ： 删除即将过期的 6、noeviction ： 永不过期，返回错误 AOF相关部分 十、持久化—RDBRDB：Redis Databases [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-C0mm1D4A-1597890996524)(狂神说 Redis.assets/image-20200818122236614.png)] 什么是RDB 在指定时间间隔后，将内存中的数据集快照写入数据库 ；在恢复时候，直接读取快照文件，进行数据的恢复 ； 默认情况下， Redis 将数据库快照保存在名字为 dump.rdb的二进制文件中。文件名可以在配置文件中进行自定义。 工作原理 在进行 RDB 的时候，**redis** 的主线程是不会做 io 操作的，主线程会 fork 一个子线程来完成该操作； Redis 调用forks。同时拥有父进程和子进程。 子进程将数据集写入到一个临时 RDB 文件中。 当子进程完成对新 RDB 文件的写入时，Redis 用新 RDB 文件替换原来的 RDB 文件，并删除旧的 RDB 文件。 这种工作方式使得 Redis 可以从写时复制（copy-on-write）机制中获益(因为是使用子进程进行写操作，而父进程依然可以接收来自客户端的请求。) 触发机制 save的规则满足的情况下，会自动触发rdb原则 执行flushall命令，也会触发我们的rdb原则 退出redis，也会自动产生rdb文件 save使用 save 命令，会立刻对当前内存中的数据进行持久化 ,但是会阻塞，也就是不接受其他操作了； 由于 save 命令是同步命令，会占用Redis的主进程。若Redis数据非常多时，save命令执行速度会非常慢，阻塞所有客户端的请求。 flushall命令flushall 命令也会触发持久化 ； 触发持久化规则满足配置条件中的触发条件 ； 可以通过配置文件对 Redis 进行设置， 让它在“ N 秒内数据集至少有 M 个改动”这一条件被满足时， 自动进行数据集保存操作。 bgsavebgsave 是异步进行，进行持久化的时候，redis 还可以将继续响应客户端请求 ； bgsave和save对比 命令 save bgsave IO类型 同步 异步 阻塞？ 是 是（阻塞发生在fock()，通常非常快） 复杂度 O(n) O(n) 优点 不会消耗额外的内存 不阻塞客户端命令 缺点 阻塞客户端命令 需要fock子进程，消耗内存 优缺点优点： 适合大规模的数据恢复 对数据的完整性要求不高 缺点： 需要一定的时间间隔进行操作，如果redis意外宕机了，这个最后一次修改的数据就没有了。 fork进程的时候，会占用一定的内容空间。 十一、持久化AOFAppend Only File 将我们所有的命令都记录下来，history，恢复的时候就把这个文件全部再执行一遍 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-Z8wr9lBW-1597890996525)(狂神说 Redis.assets/image-20200818123711375.png)] 以日志的形式来记录每个写的操作，将Redis执行过的所有指令记录下来（读操作不记录），只许追加文件但不可以改写文件，redis启动之初会读取该文件重新构建数据，换言之，redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。 什么是AOF 快照功能（RDB）并不是非常耐久（durable）： 如果 Redis 因为某些原因而造成故障停机， 那么服务器将丢失最近写入、以及未保存到快照中的那些数据。 从 1.1 版本开始， Redis 增加了一种完全耐久的持久化方式： AOF 持久化。 如果要使用AOF，需要修改配置文件： appendonly no yes则表示启用AOF 默认是不开启的，我们需要手动配置，然后重启redis，就可以生效了！ 如果这个aof文件有错位，这时候redis是启动不起来的，我需要修改这个aof文件 redis给我们提供了一个工具redis-check-aof --fix 优点和缺点 1234567appendonly yes # 默认是不开启aof模式的，默认是使用rdb方式持久化的，在大部分的情况下，rdb完全够用appendfilename &quot;appendonly.aof&quot;# appendfsync always # 每次修改都会sync 消耗性能appendfsync everysec # 每秒执行一次 sync 可能会丢失这一秒的数据# appendfsync no # 不执行 sync ,这时候操作系统自己同步数据，速度最快 优点 每一次修改都会同步，文件的完整性会更加好 没秒同步一次，可能会丢失一秒的数据 从不同步，效率最高 缺点 相对于数据文件来说，aof远远大于rdb，修复速度比rdb慢！ Aof运行效率也要比rdb慢，所以我们redis默认的配置就是rdb持久化 十二、RDB和AOP选择RDB 和 AOF 对比 RDB AOF 启动优先级 低 高 体积 小 大 恢复速度 快 慢 数据安全性 丢数据 根据策略决定 如何选择使用哪种持久化方式？一般来说， 如果想达到足以媲美 PostgreSQL 的数据安全性， 你应该同时使用两种持久化功能。 如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失， 那么你可以只使用 RDB 持久化。 有很多用户都只使用 AOF 持久化， 但并不推荐这种方式： 因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快。 十三、Redis发布与订阅Redis 发布订阅(pub/sub)是一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息。 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-IBT2pjCa-1597890996526)(狂神说 Redis.assets/image-20200818162849693.png)] 下图展示了频道 channel1 ， 以及订阅这个频道的三个客户端 —— client2 、 client5 和 client1 之间的关系： 当有新消息通过 PUBLISH 命令发送给频道 channel1 时， 这个消息就会被发送给订阅它的三个客户端： 命令 命令 描述 PSUBSCRIBE pattern [pattern..] 订阅一个或多个符合给定模式的频道。 PUNSUBSCRIBE pattern [pattern..] 退订一个或多个符合给定模式的频道。 PUBSUB subcommand [argument[argument]] 查看订阅与发布系统状态。 PUBLISH channel message 向指定频道发布消息 SUBSCRIBE channel [channel..] 订阅给定的一个或多个频道。 SUBSCRIBE channel [channel..] 退订一个或多个频道 示例1234567891011121314151617181920212223------------订阅端----------------------127.0.0.1:6379&gt; SUBSCRIBE sakura # 订阅sakura频道Reading messages... (press Ctrl-C to quit) # 等待接收消息1) &quot;subscribe&quot; # 订阅成功的消息2) &quot;sakura&quot;3) (integer) 11) &quot;message&quot; # 接收到来自sakura频道的消息 &quot;hello world&quot;2) &quot;sakura&quot;3) &quot;hello world&quot;1) &quot;message&quot; # 接收到来自sakura频道的消息 &quot;hello i am sakura&quot;2) &quot;sakura&quot;3) &quot;hello i am sakura&quot;--------------消息发布端-------------------127.0.0.1:6379&gt; PUBLISH sakura &quot;hello world&quot; # 发布消息到sakura频道(integer) 1127.0.0.1:6379&gt; PUBLISH sakura &quot;hello i am sakura&quot; # 发布消息(integer) 1-----------------查看活跃的频道------------127.0.0.1:6379&gt; PUBSUB channels1) &quot;sakura&quot; 原理每个 Redis 服务器进程都维持着一个表示服务器状态的 redis.h/redisServer 结构， 结构的 pubsub_channels 属性是一个字典， 这个字典就用于保存订阅频道的信息，其中，字典的键为正在被订阅的频道， 而字典的值则是一个链表， 链表中保存了所有订阅这个频道的客户端。 客户端订阅，就被链接到对应频道的链表的尾部，退订则就是将客户端节点从链表中移除。 缺点 如果一个客户端订阅了频道，但自己读取消息的速度却不够快的话，那么不断积压的消息会使redis输出缓冲区的体积变得越来越大，这可能使得redis本身的速度变慢，甚至直接崩溃。 这和数据传输可靠性有关，如果在订阅方断线，那么他将会丢失所有在短线期间发布者发布的消息。 应用 消息订阅：公众号订阅，微博关注等等（起始更多是使用消息队列来进行实现） 多人在线聊天室。 稍微复杂的场景，我们就会使用消息中间件MQ处理。 十四、Redis主从复制概念 主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点（Master/Leader）,后者称为从节点（Slave/Follower）， 数据的复制是单向的！只能由主节点复制到从节点（主节点以写为主、从节点以读为主）。 默认情况下，每台Redis服务器都是主节点，一个主节点可以有0个或者多个从节点，但每个从节点只能由一个主节点。 作用 数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余的方式。 故障恢复：当主节点故障时，从节点可以暂时替代主节点提供服务，是一种服务冗余的方式 负载均衡：在主从复制的基础上，配合读写分离，由主节点进行写操作，从节点进行读操作，分担服务器的负载；尤其是在多读少写的场景下，通过多个从节点分担负载，提高并发量。 高可用基石：主从复制还是哨兵和集群能够实施的基础。 为什么使用集群 单台服务器难以负载大量的请求 单台服务器故障率高，系统崩坏概率大 单台服务器内存容量有限。 环境配置我们在讲解配置文件的时候，注意到有一个replication模块 (见Redis.conf中第8条) 查看当前库的信息：info replication 12345678910111213127.0.0.1:6379&gt; info replication# Replicationrole:master # 角色connected_slaves:0 # 从机数量master_replid:3b54deef5b7b7b7f7dd8acefa23be48879b4fcffmaster_replid2:0000000000000000000000000000000000000000master_repl_offset:0second_repl_offset:-1repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0 既然需要启动多个服务，就需要多个配置文件。每个配置文件对应修改以下信息： 端口号 pid文件名 日志文件名 rdb文件名 启动单机多服务集群： 一主二从配置==默认情况下，每台Redis服务器都是主节点；==我们一般情况下只用配置从机就好了！ 认老大！一主（79）二从（80，81） 使用SLAVEOF host port就可以为从机配置主机了。 然后主机上也能看到从机的状态： 我们这里是使用命令搭建，是暂时的，==真实开发中应该在从机的配置文件中进行配置，==这样的话是永久的。 使用规则 从机只能读，不能写，主机可读可写但是多用于写。 12345678910 127.0.0.1:6381&gt; set name sakura # 从机6381写入失败(error) READONLY You can&#x27;t write against a read only replica.127.0.0.1:6380&gt; set name sakura # 从机6380写入失败(error) READONLY You can&#x27;t write against a read only replica.127.0.0.1:6379&gt; set name sakuraOK127.0.0.1:6379&gt; get name&quot;sakura&quot; 当主机断电宕机后，默认情况下从机的角色不会发生变化 ，集群中只是失去了写操作，当主机恢复以后，又会连接上从机恢复原状。 当从机断电宕机后，若不是使用配置文件配置的从机，再次启动后作为主机是无法获取之前主机的数据的，若此时重新配置称为从机，又可以获取到主机的所有数据。这里就要提到一个同步原理。 第二条中提到，默认情况下，主机故障后，不会出现新的主机，有两种方式可以产生新的主机： 从机手动执行命令slaveof no one,这样执行以后从机会独立出来成为一个主机 使用哨兵模式（自动选举） 如果没有老大了，这个时候能不能选择出来一个老大呢？手动！ 如果主机断开了连接，我们可以使用SLAVEOF no one让自己变成主机！其他的节点就可以手动连接到最新的主节点（手动）！如果这个时候老大修复了，那么久重新连接！ 十五、哨兵模式更多信息参考博客：https://www.jianshu.com/p/06ab9daf921d 主从切换技术的方法是：当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间内服务不可用。这不是一种推荐的方式，更多时候，我们优先考虑哨兵模式。 单机单个哨兵 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-2ENYVAPp-1597890996527)(狂神说 Redis.assets/image-20200818233231154.png)] 哨兵的作用： 通过发送命令，让Redis服务器返回监控其运行状态，包括主服务器和从服务器。 当哨兵监测到master宕机，会自动将slave切换成master，然后通过发布订阅模式通知其他的从服务器，修改配置文件，让它们切换主机。 多哨兵模式 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-Ga1RyfVc-1597890996528)(狂神说 Redis.assets/image-20200818233316478.png)] 哨兵的核心配置 12sentinel monitor mymaster 127.0.0.1 6379 1 数字1表示 ：当一个哨兵主观认为主机断开，就可以客观认为主机故障，然后开始选举新的主机。 测试 12redis-sentinel xxx&#x2F;sentinel.conf 成功启动哨兵模式 此时哨兵监视着我们的主机6379，当我们断开主机后： 哨兵模式优缺点 优点： 哨兵集群，基于主从复制模式，所有主从复制的优点，它都有 主从可以切换，故障可以转移，系统的可用性更好 哨兵模式是主从模式的升级，手动到自动，更加健壮 缺点： Redis不好在线扩容，集群容量一旦达到上限，在线扩容就十分麻烦 实现哨兵模式的配置其实是很麻烦的，里面有很多配置项 哨兵模式的全部配置 完整的哨兵模式配置文件 sentinel.conf 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970# Example sentinel.conf # 哨兵sentinel实例运行的端口 默认26379port 26379 # 哨兵sentinel的工作目录dir /tmp # 哨兵sentinel监控的redis主节点的 ip port # master-name 可以自己命名的主节点名字 只能由字母A-z、数字0-9 、这三个字符&quot;.-_&quot;组成。# quorum 当这些quorum个数sentinel哨兵认为master主节点失联 那么这时 客观上认为主节点失联了# sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt;sentinel monitor mymaster 127.0.0.1 6379 1 # 当在Redis实例中开启了requirepass foobared 授权密码 这样所有连接Redis实例的客户端都要提供密码# 设置哨兵sentinel 连接主从的密码 注意必须为主从设置一样的验证密码# sentinel auth-pass &lt;master-name&gt; &lt;password&gt;sentinel auth-pass mymaster MySUPER--secret-0123passw0rd # 指定多少毫秒之后 主节点没有应答哨兵sentinel 此时 哨兵主观上认为主节点下线 默认30秒# sentinel down-after-milliseconds &lt;master-name&gt; &lt;milliseconds&gt;sentinel down-after-milliseconds mymaster 30000 # 这个配置项指定了在发生failover主备切换时最多可以有多少个slave同时对新的master进行 同步，这个数字越小，完成failover所需的时间就越长，但是如果这个数字越大，就意味着越 多的slave因为replication而不可用。可以通过将这个值设为 1 来保证每次只有一个slave 处于不能处理命令请求的状态。# sentinel parallel-syncs &lt;master-name&gt; &lt;numslaves&gt;sentinel parallel-syncs mymaster 1 # 故障转移的超时时间 failover-timeout 可以用在以下这些方面： #1. 同一个sentinel对同一个master两次failover之间的间隔时间。#2. 当一个slave从一个错误的master那里同步数据开始计算时间。直到slave被纠正为向正确的master那里同步数据时。#3.当想要取消一个正在进行的failover所需要的时间。 #4.当进行failover时，配置所有slaves指向新的master所需的最大时间。不过，即使过了这个超时，slaves依然会被正确配置为指向master，但是就不按parallel-syncs所配置的规则来了# 默认三分钟# sentinel failover-timeout &lt;master-name&gt; &lt;milliseconds&gt;sentinel failover-timeout mymaster 180000 # SCRIPTS EXECUTION #配置当某一事件发生时所需要执行的脚本，可以通过脚本来通知管理员，例如当系统运行不正常时发邮件通知相关人员。#对于脚本的运行结果有以下规则：#若脚本执行后返回1，那么该脚本稍后将会被再次执行，重复次数目前默认为10#若脚本执行后返回2，或者比2更高的一个返回值，脚本将不会重复执行。#如果脚本在执行过程中由于收到系统中断信号被终止了，则同返回值为1时的行为相同。#一个脚本的最大执行时间为60s，如果超过这个时间，脚本将会被一个SIGKILL信号终止，之后重新执行。 #通知型脚本:当sentinel有任何警告级别的事件发生时（比如说redis实例的主观失效和客观失效等等），将会去调用这个脚本，#这时这个脚本应该通过邮件，SMS等方式去通知系统管理员关于系统不正常运行的信息。调用该脚本时，将传给脚本两个参数，#一个是事件的类型，#一个是事件的描述。#如果sentinel.conf配置文件中配置了这个脚本路径，那么必须保证这个脚本存在于这个路径，并且是可执行的，否则sentinel无法正常启动成功。#通知脚本# sentinel notification-script &lt;master-name&gt; &lt;script-path&gt; sentinel notification-script mymaster /var/redis/notify.sh # 客户端重新配置主节点参数脚本# 当一个master由于failover而发生改变时，这个脚本将会被调用，通知相关的客户端关于master地址已经发生改变的信息。# 以下参数将会在调用脚本时传给脚本:# &lt;master-name&gt; &lt;role&gt; &lt;state&gt; &lt;from-ip&gt; &lt;from-port&gt; &lt;to-ip&gt; &lt;to-port&gt;# 目前&lt;state&gt;总是“failover”,# &lt;role&gt;是“leader”或者“observer”中的一个。 # 参数 from-ip, from-port, to-ip, to-port是用来和旧的master和新的master(即旧的slave)通信的# 这个脚本应该是通用的，能被多次调用，不是针对性的。# sentinel client-reconfig-script &lt;master-name&gt; &lt;script-path&gt;sentinel client-reconfig-script mymaster /var/redis/reconfig.sh 十六、缓存穿透与雪崩缓存穿透（查不到） 概念 在默认情况下，用户请求数据时，会先在缓存(Redis)中查找，若没找到即缓存未命中，再在数据库中进行查找，数量少可能问题不大，可是一旦大量的请求数据（例如秒杀场景）缓存都没有命中的话，就会全部转移到数据库上，造成数据库极大的压力，就有可能导致数据库崩溃。网络安全中也有人恶意使用这种手段进行攻击被称为洪水攻击。 解决方案 布隆过滤器 对所有可能查询的参数以Hash的形式存储，以便快速确定是否存在这个值，在控制层先进行拦截校验，校验不通过直接打回，减轻了存储系统的压力。 缓存空对象 一次请求若在缓存和数据库中都没找到，就在缓存中方一个空对象用于处理后续这个请求。 这样做有一个缺陷：存储空对象也需要空间，大量的空对象会耗费一定的空间，存储效率并不高。解决这个缺陷的方式就是设置较短过期时间 即使对空值设置了过期时间，还是会存在缓存层和存储层的数据会有一段时间窗口的不一致，这对于需要保持一致性的业务会有影响。 缓存击穿（量太大，缓存过期） 概念 相较于缓存穿透，缓存击穿的目的性更强，一个存在的key，在缓存过期的一刻，同时有大量的请求，这些请求都会击穿到DB，造成瞬时DB请求量大、压力骤增。这就是缓存被击穿，只是针对其中某个key的缓存不可用而导致击穿，但是其他的key依然可以使用缓存响应。 比如热搜排行上，一个热点新闻被同时大量访问就可能导致缓存击穿。 解决方案 设置热点数据永不过期 这样就不会出现热点数据过期的情况，但是当Redis内存空间满的时候也会清理部分数据，而且此种方案会占用空间，一旦热点数据多了起来，就会占用部分空间。 加互斥锁(分布式锁) 在访问key之前，采用SETNX（set if not exists）来设置另一个短期key来锁住当前key的访问，访问结束再删除该短期key。保证同时刻只有一个线程访问。这样对锁的要求就十分高。 缓存雪崩 概念 大量的key设置了相同的过期时间，导致在缓存在同一时刻全部失效，造成瞬时DB请求量大、压力骤增，引起雪崩。 解决方案 redis高可用 这个思想的含义是，既然redis有可能挂掉，那我多增设几台redis，这样一台挂掉之后其他的还可以继续工作，其实就是搭建的集群 限流降级 这个解决方案的思想是，在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。 数据预热 数据加热的含义就是在正式部署之前，我先把可能的数据先预先访问一遍，这样部分可能大量访问的数据就会加载到缓存中。在即将发生大并发访问前手动触发加载缓存不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀。","categories":[],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"}]},{"title":"JAVA前端与后端交互的知识点总结","slug":"我自己的第一篇博客","date":"2021-01-17T02:39:20.000Z","updated":"2021-01-18T05:00:18.424Z","comments":true,"path":"2021/01/17/我自己的第一篇博客/","link":"","permalink":"http://example.com/2021/01/17/%E6%88%91%E8%87%AA%E5%B7%B1%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/","excerpt":"","text":"1.1. 描述Servlet调用过程？ （1）在浏览器输入地址，浏览器先去查找hosts文件，将主机名翻译为ip地址，如果找不到就再去查询dns服务器将主机名翻译成ip地址。（2）浏览器根据ip地址和端口号访问服务器，组织http请求信息发送给服务器。（3）服务器收到请求后首先根据Host请求头判断当前访问的是哪台虚拟主机。（4）服务器根据http请求头中的请求URI判断当前访问的是哪个web应用。（5）服务器根据http请求头中的请求URI判断当前访问的是web应用中的哪个web资源。（6）检查web应用的web.xml文件，如果根据路径找到具体的servlet处理类的全路径名交给该servlet处理,如果找不到就交给缺省servlet处理。（7）这个过程中浏览器只知道自己发出来http请求，不久就收到了http响应，浏览器不知道也不关心服务器内部是如何处理的。浏览器和服务器之间的关系是非常单纯的，只有HTTP协议。（8）解析请求、封装RequestResponse对象、创建Servlet、调用Service方法都是服务器自动进行的，开发人员只需要写好Servlet配置进容器中即可，无需操心具体的底层实现。 1.2. 简述Servlet生命周期？1.Servlet第一次被访问到时创建对象，创建出来后立即执行init方法执行初始化的操作。2.从此以后该对象一直驻留在内存中为后续的对这个Servlet的请求进行服务。3.直到服务器关闭或web应用移除出容器时，随着web应用的销毁Servlet对象销毁掉，在销毁之前调用destory方法执行善后工作。4.在存活期间，每次对Servlet 的调用都会导致Service方法的执行。 1.3. 什么是http协议？ HTTP协议就是一套基于tcp/ip协议的应用层协议 。简单来说，就是一个基于应用层的通信规范，双方要进行通信，大家都要遵守一个规范，这个规范就是HTTP协议。它规定了客户端（通常是浏览器）和服务器之间的通信方式。 1.4. HTTP协议工作原理？ HTTP协议基于请求响应模型。一次请求对应一次响应。首先客户端发送一个请求(request)给服务器，服务器在接收到这个请求后将生成一个响应(response)返回给客户端。 1.5. HTTP协议的特点是什么 ? （1） 它是一个无状态的协议，服务器端在处理相应请求后不会保留任何客户端的信息，每次请求都是独立的（2） 客户端与服务器端的每一次数据交互，都要经过一次请求/响应的过程。（3） 服务器端无法识别能够出发客户端请求的方法。（4） 一个典型的HTTP请求分为 一个请求行 若干请求头 一个空行 实体内容 1.6. get和post请求的区别？ 1） get请求用来从服务器上获得资源，而post是用来向服务器提交数据；（2） get将表单中数据按照name=value的形式，添加到action 所指向的URL 后面，并且两者使用”?“连接，而各个变量之间使用”&amp;“连接；post是将表单中的数据放在HTTP协议的请求头或消息体中，传递到action所指向URL；（3） get传输的数据要受到URL长度限制（1024字节）；而post可以传输大量的数据， POST数据是没有限制的，上传文件通常要使用post方式；（4） 使用get时参数会显示在地址栏上，如果这些数据不是敏感数据，那么可以使用get；对于敏感数据还是应用使用post；（5） get使用MIME类型application/x-www-form-urlencoded的URL编码（也叫百分号编码）文本的格式传递参数，保证被传送的参数由遵循规范的文本组成，例如一个空格的编码是”%20”。（6） Jsp页面中的FORM标签里的method属性为get时调用doGet()，为post时调用doPost()。 1.7. 请求乱码产生的原因？ 浏览器用什么码表来打开表单页面就用什么编码来发送数据。当前我们的注册页面指定了用utf-8来打开。这就决定了浏览器是用utf-8打开的页面，浏览器在提交表单时是用utf-8编码的。而tomcat默认情况下会使用iso8859-1来进行解码。我们知道全世界的码表都兼容iso8859-1，所以英文处理是没有问题的。但是iso8859-1中并没有中文，iso8859-1对于无法处理的字节都使用?替代，所以我们看到的都是？ 1.8. 如何来处理get请求产生的乱码? 由于客户端发送时使用的是utf-8编码而服务器用iso8859-1解码造成了乱码，虽然字符已经乱掉了，但底层的字节仍然是正确的，我们只要将乱码字符getBytes(“iso8859-1”)转换为字节，就是正确的字节，再将这些字节new String(bytes，“utf-8”)按照正确的码表编码，就可以转换回正确的字符了。从而解决了乱码。 1.9. Request生命周期 request对象的生命周期是针对一个客户端(一个浏览器应用程序)的一次请求，当请求完毕之后，request里边的内容也将被释放，一个请求开始时创建，请求结束后销毁。 1.10. 如何处理响应乱码？ 通过response.setHeader(“Content-Type”, “text/html;charset=utf-8”)方法，通知服务器发送数据时的码表；通过response.setCharacterEncoding(“utf-8”)方法，通知浏览器解析时使用的码表。两码相同就不会有乱码了。response提供了setContentType(“text/html;charset=UTF-8”)快捷方法，在它的底层，会同时做上面两件事，所以可以一行代码解决response产生的乱码问题。 1.11. 简述ServletContext生命周期？ServletContext对象代表当前web应用。当服务器启动时，服务器在启动时会依次加载web应用，每一个web应用加载完成后都会创建一个ServletContext对象唯一代表该web应用，这个对象一直存活，直到web应用移除出容器或服务器关闭时，随着应用销毁，ServletContext对象跟着销毁。 1.12. 转发与重定向的比较？ 重定向：首先服务器受到浏览器客户端请求之后，服务器发送新的链接到客户端浏览器，浏览器接收到新的链接之后又重新请求收到的链接地址，在整个过程中完成之后在客户端浏览器看来是发生了一次跳转，其实是客户端浏览器请求了两次而已，所以在浏览器的地址栏里网络地址自然就会改变成新的连接 转发：服务器接收到客户端的请求之后，服务器把控制权交到另一个JSP页面手里，新的JSP页面接收到请求之后根据情况是继续转交控制权或者显示页面由自己决定，到最后显示页面的整个过程就是一个页面跳转过程，在这个过程中，服务器可以把请求的数据在经过的页面进行传递，而不会担心数据的丢失 1.转发在服务器端完成的；重定向是在客户端完成的 2.转发的速度快；重定向速度慢 3.转发的是同一次请求；重定向是两次不同请求 4.转发不会执行转发后的代码；重定向会执行重定向之后的代码 5.转发地址栏没有变化；重定向地址栏有变化 6.转发必须是在同一台服务器下完成；重定向可以在不同的服务器下完成 1.13. Session生命周期？ 当程序第一次调用到request.getSession()代码时,服务器明确的知道了需要用到session了,此时创建session。如果session超过30分钟(可以在web.xml中配置的)没人使用,服务器认为这个session超时了,销毁session。明确的调用session.invalidate(),session立即销毁。服务器被非正常关闭或web应用被移除出容器,此时随着web应用的销毁session销毁.如果是正常关闭,session会被钝化.当下次服务器正常启动时,没有超时的session还会被活化回来。 1.14. session的原理？ session的原理：在服务器第一次调用request.getSession()方法的时候，会在内存中创建一个session对象，此对象具有一个独一无二的id值，此id值将会以cookie（JSESSIONID）的形式发送给浏览器，浏览器以后每次访问都会带着此cookie，服务器就利用此cookie区分浏览器找到对应的session空间。 1.15. cookie与session的区别 cookie数据存放在客户的浏览器上，session数据放在服务器上cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗，考虑到安全应当使用sessionsession会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能，考虑到减轻服务器性能方面，应当使用COOKIE 1.16. JSP和Servlet是什么关系？1.17. JSP的九大隐式对象是哪九个 1：request: 请求对象 在javax.servlet.ServletRequest 作用域为Request来自客服端的请求，如：FORM表单中填写的信息，常用的方法有getParameter，getParamterName 和getParamterValue通过表用获取请求对象中包含的参数值。2:response表示客服端的响应。3：pageContext对象为页面的上下文对象，代表当请运行页面的一些属性。4：session：对象代码服务器与客服端所建立的会话，比如在写购物，客服轨迹跟踪，session”是建立在cookie的基础之上的。常用方法有getId,getValues等。5：application对象负责提供应用程序在服务端运行时的一些全局信息，方法有getMimeType等。6：out：与response不同，通过out对象发送的内容是浏览器需要的显示内容，还可以直接想客服端编写一个有程序动态生成的HTML的文件。7：page：page里的变量没法从index.jsp传递到test.jsp。只要页面跳转了，就不见了。8： exception：他是一个列外的对象，当页面发生了列外，就会会创建该对象。9：config：是在servlet初始化Servlet的时候，JSP引擎向他传递信息用的，此消息包括Servlet初始化时所需要的参数。 1.19. Mysql数据库优化 (1)查询时，能不用* 就不用，尽量写全字段名。(2)索引不是越多越好，每个表控制在6个索引以内。范围where条件的情况下，索引不起作用，比如where value&lt;100(3)大部分情况连接效率远大于子查询，但是有例外。当你对连接查询的效率都感到不能接受的时候可以试试用子查询，虽然大部分情况下你会更失望，但总有碰到惊喜的时候不是么…(4)多用explain 和 profile分析查询语句(5)有时候可以1条大的SQL可以分成几个小SQL顺序执行，分了吧，速度会快很多。(6)每隔一段时间用alter table table_name engine=innodb;优化表(7)连接时注意:小表 jion 大表的原则(8)学会用explain 和 profile判断是什么原因使你的SQL慢(9)查看慢查询日志，找出执行时间长的SQL进行优化(10)尽量避免使用order by(11)因为where子句后面的条件是执行顺序是从右到左，所以尽量把能过滤掉大部分数据的条件放在最后 1.22. 什么是数据库连接池及其工作原理 对于共享资源，有一个很著名的设计模式：资源池（resource pool）。该模式正是为了解决资源的频繁分配﹑释放所造成的问题。为解决上述问题，可以采用数据库连接池技术。数据库连接池的基本思想就是为数据库连接建立一个“缓冲池”。预先在缓冲池中放入一定数量的连接，当需要建立数据库连接时，只需从“缓冲池”中取出一个，使用完毕之后再放回去。我们可以通过设定连接池最大连接数来防止系统无尽的与数据库连接。更为重要的是我们可以通过连接池的管理机制监视数据库的连接的数量﹑使用情况，为系统开发﹑测试及性能调整提供依据。 1.24. http和https的区别？ HTTP协议传输的数据都是未加密的，也就是明文的，因此使用HTTP协议传输隐私信息非常不安全，为了保证这些隐私数据能加密传输，于是网景公司设计了SSL（Secure Sockets Layer）协议用于对HTTP协议传输的数据进行加密，从而就诞生了HTTPS。简单来说，HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全。 1.28. request.getParameter()和request.getAttribute()的区别？ a、request.getParameter()获取的类型是String；request.getAttribute()获取的类型是Objectb、request.getPrameter()获取的是POST/GET传递的参数值和URL中的参数；request.getAttribute()获取的是对象容器中的数据值/对象c、request.setAttribute()和request.getAttribute()可以发送、接收对象；request.getParamter()只能接收字符串，官方不开放request.setParamter()（也就是没有这个方法）setAttribute()和getAttribute()的传参原理：setAttribute()是应用服务器把这个对象放在该页面所对应的一块内存中去，当你的页面服务器重定向到另外一个页面时，应用服务器会把这块内存拷贝到另一个页面所对应的那块内存中。这个就可以通过getAttribute()获取到相应的参数值或者对象。 1.30. 详细描述MVC 基于java的web应用系统采用MVC设计模型，即用Model（模型）、View（视图）和Controller（控制）分离设计，这是目前web应用服务系统的主流设置方向。Model：处理业务逻辑的模块。View：负责页面显示，显示Model的处理结果给用户，主要实现数据到页面的转换过程。Controller：负责每个请求的分发，把Form数据传递给Model进行处理，处理完成后，把处理结果返回给相应的View显示给用户。 1.37. 简述web.xml的作用 属于部署描述符，在整个JAVA中只要是容器都会存在部署描述符，此部署描述符可以控制整个WEB中各个组件的运行状态，也可以配置整个窗口的状态 1.44. HTML和xml的区别？ XML是可扩展标记语言，而HTML超文本标记语言。不同之处：1、语法有所不同。XML语法比较严谨而HTML语法比较松散。2、用途不同。XML主要用于数据格式化存储而HTML主要用于网页的编辑。 1.56. Spring 在ssm中起什么作用？ Spring：轻量级框架作用：Bean工厂，用来管理Bean的生命周期和框架集成。两大核心：1、IOC/DI(控制反转/依赖注入) ：把dao依赖注入到service层，service层反转给action层，Spring顶层容器为BeanFactory。2、AOP：面向切面编程 1.57. Spring的配置文件中的内容？ 开启事务注解驱动事务管理器开启注解功能，并配置扫描包配置数据库配置SQL会话工厂，别名，映射文件不用编写Dao层的实现类 1.58. Spring主要使用了什么模式？ 工厂模式：每个Bean的创建通过方法单例模式：默认的每个Bean的作用域都是单例代理模式：关于Aop的实现通过代理模式 1.60. Mybatis的好处？把Sql语句从Java中独立出来封装了底层的JDBC，API的调用，并且能够将结果集自动转换成JavaBean对象，简化了Java数据库编程的重复工作。自己编写Sql语句，更加的灵活。入参无需用对象封装（或者map封装）,使用@Param注解","categories":[],"tags":[{"name":"java后端","slug":"java后端","permalink":"http://example.com/tags/java%E5%90%8E%E7%AB%AF/"}]}],"categories":[],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://example.com/tags/SpringBoot/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://example.com/tags/SpringCloud/"},{"name":"Redis","slug":"Redis","permalink":"http://example.com/tags/Redis/"},{"name":"java后端","slug":"java后端","permalink":"http://example.com/tags/java%E5%90%8E%E7%AB%AF/"}]}