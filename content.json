{"meta":{"title":"星辰大海","subtitle":"","description":"","author":"Xingchen","url":"http://www.xc234.ltd","root":"/"},"pages":[{"title":"categories","date":"2021-01-19T08:29:18.000Z","updated":"2021-01-19T09:09:49.718Z","comments":true,"path":"categories/index.html","permalink":"http://www.xc234.ltd/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"设计模式学习笔记","slug":"设计模式学习笔记","date":"2022-07-06T14:25:27.000Z","updated":"2022-09-12T08:32:48.498Z","comments":true,"path":"2022/07/06/设计模式学习笔记/","link":"","permalink":"http://www.xc234.ltd/2022/07/06/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"设计模式1.设计模式概述1.1 软件设计模式的产生背景“设计模式”最初并不是出现在软件设计之中，而是被用在建筑领域的设计中。 1977年美国著名建筑大师、加利福尼亚大学伯克利分校环境结构中心主任克里斯托夫·亚历山大（Christopher Alexander）在他的著作《建筑模式语言：城镇、建筑、构造》中描述了一些常见的建筑设计问题，并提出了 253 种关于对城镇、邻里、住宅、花园和房间等进行设计的基本模式。 1990年软件工程界开始研讨设计模式的话题，后来召开了多次关于设计模式的研讨会。直到1995 年，艾瑞克·伽马（ErichGamma）、理査德·海尔姆（Richard Helm）、拉尔夫·约翰森（Ralph Johnson）、约翰·威利斯迪斯（John Vlissides）等 4 位作者合作出版了《设计模式：可复用面向对象软件的基础》一书，在此书中收录了 23 个设计模式，这是设计模式领域里程碑的事件，导致了软件设计模式的突破。这 4 位作者在软件开发领域里也以他们的“四人组”（Gang of Four，GoF）著称。 1.2 软件设计模式的概念软件设计模式(Software Design Pattern),又称设计模式，是一套被反复使用、多数人知晓的、经过分类编目的、代码设计经验的总结。它描述了在软件设计过程中的一些不断重复发生的问题，以及该问题的解决方案。也就是说，它是解决特定问题的一系列套路，是前辈们的代码设计经验的总结，具有一定的普遍性，可以反复使用。 1.3 学习设计模式的必要性设计模式的本质是面向对象设计原则的实际运用，是对类的封装性、继承性和多态性以及类的关联关系和组合关系的充分理解。 正确使用设计模式具有以下有点。 可以提高程序员的思维能力、编程能力和设计能力。 使程序设计更加标准化、代码编写更加工程化，使软件开发效率大大提高，从而缩短软件的开发周期。 使设计的代码可重用性高、可读性高、可靠性高、灵活性好、可维护性强。 1.4 设计模式分类 创建型模式 用于描述“怎样创建对象”，它的主要特点是“将对象的创建与使用分离”。GoF（四人组）书中提供了单例、原型、工厂方法、抽象工厂、建造者等5中创建型模式。 12常用：⼯⼚模式、抽象⼯⼚模式、单例模式、建造者模式不常用：原型模式 结构型模式 用于描述如何将类或对象按某种布局组成更大的结构，GoF（四人组）书中提供了代理、适配器、桥接、装饰、外观、享元、组合等7种结构性模式。 12常用：适配器模式、桥接模式、装饰器模式、代理模式不常用：组合模式、外观模式、享元模式、 行为型模式 用于描述类或对象之间怎样相互协作共同完成单个对象无法单独完成的任务，以及怎样分配职责。GoF（四人组）书中提供了模板方法、策略、命令、职责链、状态、观察者、中介者、迭代器、访问者、备忘录、解释器等11种行为型模式。 123常用：责任链模式、迭代器模式、观察者模式、状态模式、策略模式、模板模式不常用：备忘录模式、命令模式几乎不用：访问者模式、中介者模式、解释器模式 1.5设计模式六大原则软件设计开发原则 设计模式是站在设计原则的基础之上的，所以在学习设计模式之前，有必要对这些设计原则先做⼀下了解 软件设计开发原则 为了让的代码更好重⽤性，可读性，可靠性，可维护性 诞⽣出了很多软件设计的原则，这6⼤设计原则是我们要掌握的 将六⼤原则的英⽂⾸字⺟拼在⼀起就是SOLID（稳定的），所以也称之为SOLID原则 单一职责原则 一个类只负责一个功能领域中的相应职责，就一个类而言，应该只有一个引起它变化的原因 是实现高内聚、低耦合的指导方针 解释： 高内聚： 尽可能类的每个成员只完成一件事（最大限度的聚合） 模块内的代码，相互之间的联系越强，内聚就越高，模块的独立性就越好 低耦合：减少类内部，一个成员方法调用另一个成员方法，不要牵一发动全身 开闭原则 对拓展开发，对修改关闭，在程序需要进行拓展的时候，不能去修改原有的代码，实现一个热拔插的效果 里氏替换原则LSPLSP（Liskov Substitution principle） 任何基类可以出现的地方，子类一定可以出现 在程序中尽量使用基类类型来对对象进行定义，而在运行时再确定其子类类型 ，用子类对象来替换父类对象 controller-&gt;service-&gt;dao 接口隔离原则 客户端不应该依赖哪些它不需要的接口 使用多个隔离的接口，比使用单个接口要好，降低类之间的耦合度 迪米特法则 最少知道原则，一个实体类应当尽量少地与其他实体之间发生相互作用，使得系统功能模块相对独立 类之间的耦合度越低，就越有利于复用，一个处在松耦合中的类一旦被修改，不会对关联的类造成太大波及 通过引入一个合理的第三者来降低现有对象之间的耦合度 2.工创建型设计模式-单例设计模式单例设计模式介绍 这个是最简单的设计模式，但事实并不是 单例意思只包含一个对象被称为单例的特殊类 通过单例设计模式可以保证系统中，应用该模式的类只有一个对象实例 使用场景 业务系统全局只需要一个对象实例，比如发号器、redis连接对象等 Spring IOC容器中的bean默认就是单例 Spring boot 中的controller、service、dao层通过@autowire的依赖注入对象默认都是单例的 分类 懒汉：就是所谓的懒加载，延迟创建对象 饿汉：与懒汉相比，提前创建对象 实现步骤 私有化构造函数 提供获取单例的方法 懒汉代码实现**+双重检查锁定+**内存模型123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120/** * @author xingchen * @description 单例设计模式 - 懒汉实现方式 * @create 2022-08-16 21:49 */public class SingletonLazy &#123; private static SingletonLazy instance; /** * 构造函数私有化 */ private SingletonLazy() &#123; &#125; /** * 单例对象的方法 */ public void process() &#123; System.out.println(&quot;方法调用成功&quot;); &#125; /** * 第一种方式 * 对外暴露一个方法获取类的对象 * 线程不安全，多线程下存在安全问题 * * @return */ public static SingletonLazy getInstance() &#123; if (instance == null) &#123; instance = new SingletonLazy(); &#125; return instance; &#125; /** * 第二种方式 * 通过加锁 synchronized 保证单例 * 采用synchronized 对方法加锁有很大的性能开销 * 解决办法：锁粒度不要这么大 * * @return */ public static synchronized SingletonLazy getInstanceSafe() &#123; if (instance == null) &#123; instance = new SingletonLazy(); &#125; return instance; &#125; /** * 第三种方式 * 也存在线程安全问题 * * @return */ public static SingletonLazy getInstanceSafe2() &#123; if (instance == null) &#123; //A、B线程 多线程下 存在非空判断的问题 A创建完对象后释放锁，B线程也紧跟着进来创建了对象 synchronized (SingletonLazy.class) &#123; instance = new SingletonLazy(); &#125; &#125; return instance; &#125; /** * 第四种方式 * DCL 双重检查锁定 (Double-Checked-Locking),在多线程情况下保持高性能 * 这是否安全，instance = new SingletonLazy(); 并不是原子性操作 * 1、分配空间给对象 * 2、在空间内创建对象 * 3、将对象复制给引用instance * 假如线程是 1-》3-》2顺序，在执行第3步的时候会把值写回主内存，其他线程就会读取到instance最新的值，但是这个是不完全的对象 * （指令重拍） * * @return */ public static SingletonLazy getInstanceSafe3() &#123; if (instance == null) &#123; synchronized (SingletonLazy.class) &#123; if (instance == null) &#123; instance = new SingletonLazy(); &#125; &#125; &#125; return instance; &#125; /** * 第五种方式 * volatile 是java提供的关键词，它具有可⻅性和有序性，可以禁止指令重排 * 指令重排序是JVM对语句执⾏的优化，只要语句间没有依赖，那JVM就有权对语句进⾏优化 * * @return */ private static volatile SingletonLazy instanceVol; public static SingletonLazy getInstanceSafe4() &#123; //第一重检查 if (instanceVol == null) &#123; //A、B 等多线程 锁定 synchronized (SingletonLazy.class) &#123; //第二重检查 if (instanceVol == null) &#123; instanceVol = new SingletonLazy(); &#125; &#125; &#125; return instanceVol; &#125;&#125; 单例设计模式中的饿汉实现和选择问题 饿汉方式：提前创建好对象 优点：实现简单，没有多线程同步问题 缺点：不管有没使用，instance对象一直占着这段内存 如何选择 如果对象不大，且创建不负责，直接用饿汉的方式即可 其他情况则采用懒汉实现方式 123456789101112131415161718192021222324252627/** * @author xingchen * @description 单例设计模式 - 饿汉实现方式 * @create 2022-08-16 22:27 */public class SingletonHungry &#123; /** * 类加载的时候就实例化了 */ private static SingletonHungry instance = new SingletonHungry(); private SingletonHungry() &#123; &#125; public static SingletonHungry getInstance()&#123; return instance; &#125; /** * 单例对象的方法 */ public void process() &#123; System.out.println(&quot;方法调用成功&quot;); &#125;&#125; JDK源码里面的设计模式 JDK中Runtime类 饿汉方式 JDK中Desktop类懒汉方式 3.创建型设计模式-工厂设计模式常见的工厂设计模式 工厂模式介绍： 它提供了一种创建对象的最佳方式，我们在创建对象时不会对客户端暴露创建逻辑，并且是通过使用一个共同的接口来指新创建的对象 例子： 需要购买一辆车，不用管车辆如何组装密，且可以购买不同类型的比如轿车、SUV、跑车，直接去4s店购买就行（4s店就是工厂） 工厂生产手机，除了iPhone、还可以生产小米、华为、oppo等品牌手机 业务开发中，支付很常见，里面有统一下单和支付接口，具体的支付实现可以微信、支付宝、银联等 工厂模式有3种不同的实现方式 简单工厂模式：通过传入相关的类型来返回相应的类，这种方式比较单一，可拓展性相对较差 工厂方法模式：通过实现类实现相应的方法来决定相应的返回结果，这种方式的可拓展性比较强 抽象工厂模式：基于上述两种模式的拓展，且支持细化产品 应用场景： 解耦：分离职责，把负责对象的创建和使用的过程分开 复用代码 降级维护成本 如果对象创建复杂且多处需用到，如果每处都进行编写，则很多重复代码，如果业务逻辑发生了改变，需用四处修改； 使用工厂模式统一创建，则只要修改工厂类即可，降低成本 简单工厂模式 又称静态工厂方法，可以根据参数的不同返回不同类的实例，专门定义一个类来负责创建其他类的实例，被创建的实例通常都具有共同的父类 由于工厂方法是静态方法，可通过类名直接调用，而且只需要传入简单的参数即可 核心组成 Factory：工厂类，简单工厂模式的核心，它负责实现创建所有实列的内部逻辑 IProduct：抽象产品类，简单工厂模式所创建的所有对象的父类，描述所有实例所共有的公共接口 Product：具体产品类，是简单工厂模式的创建目标 实现步骤 创建抽象产品类，里面有产品的抽象方法，由具体的产品类去实现 创建具体产品类，继承了他们的父类，并实现具体方法 创建工厂类，提供了一个静态方法createXXX用来生产产品，只需要传入你想产品名称 优点将对象的创建和对象本身业务处理分离可以降低系统的耦合度，使得两者修改起来都相对容易 缺点 工厂类的职责相对过重，增加新的产品需要修改工厂类的判断逻辑，这一点与开闭原则是相违背 即开闭原则（Open Close Principle）对拓展开放，对修改关闭，程序需要进行拓展的时候，不能去修改原有的代码，实现一个热拔插的效果 将会增加系统中类的个数，在一定程度上增加了系统的复杂度和理解难度，不利于系统的拓展和维护，创建简单对象就不用模式 工厂方法模式 又称工厂模式，是对简单工厂模式的进一步抽象化，其好处是可以使系统在不修改原来代码的情况下引进新的产品，即满足开闭原则 通过工厂父类定义负责创建产品的公共接口，通过子类来确定所需要创建的类型 相比简单工厂而言，此种方法具有更多的可拓展性和复用性，同时也增强了代码的可读性 将类的实例化（具体产品的创建）延迟到工厂类的子类（具体工厂）中完成，即由子类来决定应该实例化哪一个类 核心组成 IProduct：抽象产品类，描述所有实例所共有的公共接口 Product：具体产品类，实现抽象品类的接口，工厂类创建对象，如果有多个需要定义多个 IFactory：抽象工厂类，描述具体工厂的公共接口 Factory：具体工厂类，实现创建产品类对象，实现抽象工厂类的接口，如果有多个需要定义多个 编码实践123456789101112131415161718192021222324252627282930313233343536373839/** * 抽象⼯⼚⽅法 */public interface PayFactory &#123; Pay getPay();&#125;/** * 具体产品⼯⼚ */public class AliPayFactory implements PayFactory &#123; @Override public Pay getPay() &#123; return new AliPay(); &#125;&#125;/** * 抽象产品 */public interface Pay &#123; /** * 统⼀下单 */ void unifiedorder();&#125;/** * 具体产品 */public class AliPay implements Pay &#123; @Override public void unifiedOrder() &#123; //具体逻辑代码省略 System.out.println(&quot;支付宝支付 统一下单接口&quot;); &#125;&#125; 优点： 符合开闭原则，增加一个产品类，只需要实现其他具体的产品类和具体的工厂类 符合单一职责原则，每个工厂只负责生产对应的产品 使用者只需要知道产品的抽象类，无需关心其他实现类，满足迪米特法则、依赖倒置原则和里氏替换原则 迪米特法则：最少知道原则，实体应当尽量少地与其他实体之间发生相互作用 依赖倒置原则：针对接口编程，依赖于抽象而不依赖于具体 里氏替换原则：俗称LSP，任何基类可以出现的地方，子类一定可以出现，对实现抽象化的具体步骤的规范 缺点： 增加一个产品，需要实现对应的具体工厂类和具体产品类 每个产品需要有对应的具体工厂和具体产品类 抽象工厂模式 工厂模式有3种不同的实现方式 简单工厂模式：通过传入相关的类型来返回相应的类，这种方式比较单一，可拓展性相对较差 工厂方法模式：通过实现类实现相应的方法来决定相应的返回结果，这种方式的可拓展性比较强 抽象工厂模式：基于上述两种模式的拓展，是工厂方法模式的升级版，当需要创建的产品有多个产品线时使用抽象工厂模式是比较好的选择 抽象工厂模式在Spring中应用得最为广泛的一种设计模式 背景 工厂方法模式引入工厂等级结构，解决了简单工厂模式中工厂类职责过重的问题 但工厂方法模式中每个工厂只创建一类具体类的对象，但后续发展可能会导致工厂类过多，因此将一些相关的具体类组成一个”具体类族“，由同一个工厂来统一生产，强调的是一系列相关的产品对象！！！ 实现步骤12345671、定义两个接口 Pay、Refund2、创建具体的Pay产品、创建具体的Refund产品3、创建抽象工厂 OrderFactory 接口 里面两个方法 createPay&#x2F;createRefund4、创建支付宝产品族AliOderFactory，实现OrderFactory抽象⼯⼚5、创建微信⽀付产品族WechatOderFactory，实现OrderFactory抽象⼯⼚6、定义一个超级工厂创造器，通过传递参数获取对应的工厂 编码实践123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/** * 超级工厂，定义同个产品族的其他相关子工厂 */public interface OrderFactory &#123; PayFactory createPay(); RefundFactory createRefund();&#125;/** * 产品族工厂的产品，可以不叫Factory，看公司团队规范，⽐如类名叫 IPay 也可以的 */public interface PayFactory &#123; /** * 统一下单 */ void unifiedOrder();&#125;//产品族工厂public class AliOrderFactory implements OrderFactory &#123; @Override public PayFactory createPay() &#123; return new AliPay(); &#125; @Override public RefundFactory createRefund() &#123; return new AliRefund(); &#125;&#125;//具体产品public class AliPay implements PayFactory &#123; @Override public void unifiedOrder() &#123; //具体逻辑代码省略 System.out.println(&quot;支付宝支付 统一下单接口&quot;); &#125;&#125;//超级工厂⽣产器，传参生产对应的子工厂public class FactoryProducer &#123; public static OrderFactory getFactory(String type) &#123; if (type.equalsIgnoreCase(&quot;WECHAT&quot;)) &#123; return new WechatOrderFactory(); &#125; else if (type.equalsIgnoreCase(&quot;ALI&quot;)) &#123; return new AliOrderFactory(); &#125; return null; &#125;&#125; 工厂方法模式和抽象工厂方法模式 当抽象工厂模式中每一个具体工厂类只创建一个产品对象，抽象工厂模式退化成工厂方法模式 优点 当一个产品族中的多个对象被设计称一起工作时，它能保证使用方法始终只使用同一个产品族中的对象 产品等级结构拓展容易，如果需要增加多一个产品等级，只需要增加新的工厂类和产品类即可，比如增加银联支付、退款 缺点 产品族拓展困难，要增加一系列的某一产品，既要在抽象的工厂和抽象产品里修改代码，不是很符合开闭原则 增加了系统的抽象性和理解难度 源码 4.创建型设计模式-原型模式 是一种对象创建型模式，使用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象，主要用于创建重复的对象，同时又能保证性能 工作原理是将一个原型对象传给那个要发动创建的对象，这个要发动创建的对象通过请求原型拷贝自己来实现创建过程 应该是最简单的设计模式了，实现一个接口，重写一个方法即完成了原型模式 核心组成 Prototype:声明克隆方法的接口，是所有具体原型类的公共父类，Cloneable接口 ConcretePrototype：具体原型类 Client:让一个原型对象克隆自身从而创建一个新的对象 应用场景 创建新对象成本比较大，新的对象可以通过原型设计模式对已有对象进行复制来获得 如果系统要保存对象的状态，做备份使用 遗留问题 通过对一个类进行实例化来构造新对象不同的是，原型模式是通过拷贝一个现有对象生成新对象的 浅拷贝实现Cloneable，深拷贝是通过实现Serializable读取二进制流 拓展 浅拷贝 1234如果原型对象的成员变量是基本数据类型(int、double、byte、boolean、char等)，将复制一份给克隆对象；如果原型对象的成员变量是引用类型，则将引用对象的地址复制一份给克隆对象，也就是说原型对象和克隆对象的成员变量指向相同的内存地址通过覆盖Object类的clone()方法可以实现浅拷贝 深拷贝 1无论原型对象的成员变量是基本类型还是引用类型，都将复制一份给克隆对象，如果需要实现深克隆，可以通过序列号(Serializable)等方式来是实现 优点 当创建新的对象实例较为复杂时，使用原型模式可以简化对象的创建过程，可以提高新实例的创建效率 可辅助实现撤销操作，使用深克隆的方法来保存对象的状态，使用原型模式将对象复制一份并将其状态保存起来，以便在需要的时候使用恢复到历史状态 缺点 需要为每一个类配备一个克隆方法，对已有的类进行改造时，需要修改源代码，违背了“开闭原则” 在实现深克隆时需要编写较为复杂的代码，且当对象之间存在多重的嵌套使用时，需要对每一层对象对应的类必须支持深克隆 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class Person implements Cloneable, Serializable &#123; private String name; private int age; private List&lt;String&gt; list = new ArrayList&lt;&gt;(); public Person() &#123; System.out.println(&quot;构造函数调用&quot;); &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public List&lt;String&gt; getList() &#123; return list; &#125; public void setList(List&lt;String&gt; list) &#123; this.list = list; &#125; @Override protected Person clone() throws CloneNotSupportedException &#123; return (Person) super.clone(); &#125; /** * 深拷贝 * * @return */ public Object deepClone() &#123; try &#123; //输出 序列号 ByteArrayOutputStream baos = new ByteArrayOutputStream(); //对象输出流 ObjectOutputStream oos = new ObjectOutputStream(baos); oos.writeObject(this); //输入 反序列化 ByteArrayInputStream bais = new ByteArrayInputStream(baos.toByteArray()); //对象输入流 ObjectInputStream ois = new ObjectInputStream(bais); Person copy = (Person) ois.readObject(); return copy; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; 源码案例5.创建型设计模式-建造者模式 使用多个简单的对象一步一步构建称一个复杂的对象，将一个复杂对象的构建与它的表示分离，使得同样的构建过程可以创建不同的表示 允许用户只通过指定复杂对象的类型和内容就可以构建它们，不需要知道具体的内部构建细节 场景举例 KFC创建套餐：套餐是一个复杂对象，它一般包含主食如汉堡、烤翅等和饮料 如果汁、可乐等组成部分，不同的套餐有不同的的组合，而KFC的服务员可以根据顾客的要求，一步一步装配这些组成部分，构造一份完整的套餐 电脑有低配、高配，组装需要CPU、内存、电源、硬盘、主板等 核心组成 Builder:抽象建造者，定义多个通用方法和构建方法 ConcreteBuilder：具体建造者，可以有多个 Diretor：指挥者，控制整个组合过程，将需求交给建造者，由建造者去创建对象 Product：产品角色 优点 客户端不必知道产品内部组成的细节，将产品本身与产品的创建过程解耦 每一个具体建造者都相对独立，而与其他的具体建造者无关，更加精细的控制产品的创建过程 增加新的具体建造者无需修改原有类库的代码，符合开闭原则 建造者模式结合链式编程来使用，代码上更加美观 缺点 建造者模式所创建的产品一般具体较多的共同点，如果产品差异大则不建议使用 JDK里面的应用 tcp传输协议protobuf生成的api、java中的StringBuilder(不完全一样，思想一样) 建造者模式与抽象工厂模式的比较 建造者模式返回一个组装好的完整产品，抽象工厂模式返回一系列相关的产品，这些产品位于不同的产品等级结构，构成了一个产品族 源码案例6.结构型设计模式-适配器模式 见名知其意，是作为两个不兼容的接口之间的桥梁，属于结构型模式 适配器模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作 常见的几类适配器 类的适配器 想将一个类转换称满足另一个新接口的类时，可以使用类的适配器模式，创建一个新类，继承原有的类，实现新的接口即可 对象的适配器模式 想将一个对象转化称满足另一个新街口的对象时，可以创建一个类适配器类，持有原有类的一个实例，在适配器类的方法中，调用实例的方法就行 接口的适配器模式 不想实现一个接口中所有的方法时，可以创建一个Adapter，实现所有方法，在写别的类的时候，继承Adapter类即可 应用场景 电脑需要读取内存卡的数据，读卡器就是适配器 日上使用的转换头，如电源转换头，电压转换头 系统需要使用现有的类，而这些类的接口不符合系统的需要 JDK中InputStreamReader就是适配器 JDBC就是我们用的最多的适配器模式 1JDBC给出一个客户端通用的抽象接口,每一个具体数据库厂商如 SQL Server、Oracle、MySQL等，就会开发JDBC驱动，就说一个介于JDBC接口和数据库引擎接口之间的适配器软件 接口适配器1有些接口中有多个抽象方法，当我们写该接口的实现类时，必须实现该接口的所有方法时，这明显有时比较浪费，因为并不是所有的方法都是我们需要的，有时只需要实现部分接口就可以了 类的适配器模式 想将一个类转化成满足另一个新接口的类时，可以使用类的适配器模式，创建一个新类，继承原有的类，实现新的接口即可 编码实战需求背景12345678910111213公司里有个电商支付项目，里面有个登录功能，已经线上运行了客户端A 调用生产环境的登录接口B，且线上稳定运行了好几年。某天，公司接到收购了别的公司的项目，需要把这套系统部署起来，且收购的项目也有对于的客户端C，但是两个客户端和服务器的协议不一样需求：收购的项目客户端C，需要做公司原来的项目用户数据打通，连接公司的服务端登录接口B，你能想到几个解决方法？1、修改旧项目B的登录接口，兼容C客户端协议（可能影响线上接口，不稳定）2、新增全新的登录接口F，采用C客户端协议（和旧的业务逻辑会重复）3、新增一个转换协议接口，客户端C调用旧的B接口之前，使用转换接口转换下协议 源码案例7.结构型设计模式-桥接设计模式 和适配器模式相似，包括以后经常遇到意思接近一样的设计模式，因为大神往往就是多个模式混用，且根据不同的场景进行搭配 将抽象部分与实现部分分离，使它们都可以独立的变化 通俗来说，是通过组合来桥接其他的行为/维度 应用场景 系统需要在构件的抽象化角色和具体化角色之间增加更多的灵活性 不想使用继承导致系统类的个数急剧增加的系统 有时候一个类，可能会拥有多个变化维度，比如啤酒，有不同的容量和品牌，可以使用继承组合方式进行开发，假如维度很多，就容易出现类的膨胀，使用桥接模式就可以解决这个问题，且解耦 业务场景12345我们需要构建一个手机类，我们知道手机有很多品牌，苹果、华为等，从另外一个颜色维度，又有多种颜色，红、黄、蓝等，那如果描述这些类的话，传统方式就直接通过继承，就需要特别多的类，品牌2，颜色3，就是6个类了，如果后继再增加品牌就更多了，类数目将会激增，即所谓的类爆炸使用桥接模式就可以解决这个问题，且灵活度大大提高 优点 抽象和实现的分离 优秀的拓展能力，符合开闭原则 缺点 增加系统的理解与设计难度 使用聚合关联关系建立在抽象层，要求开发者针对抽象进行设计与编程，比如抽象类汽车，里面聚合了颜色类，有点像对象适配器 总结和对比 按GOF的说法，桥接模式和适配器模式用于设计的不同阶段 桥接模式用于设计的前期，精细化的设计，让系统更加灵活 适配器模式用于设计完成之后，发现类、接口之间无法一起工作，需要进行填坑 适配器模式经常用在第三方API协同工作的场合，在功能集成需求越来越多的今天，这种模式的使用频度越来越高，外观设计模式的某些场景和适配器模式一样 源码案例8.组合设计模式 又叫部分整体模式，将对象组合成树形结构以表示”部分-整体“的层次结构，可以更好的实现管理操作 组合模式使得用户可以使用一致的方法操作单个对象和组合对象 部分-整体对象的基本操作多数是一样的，但是应该还会有不一样的地方 核心：组合模式可以使用一棵树来表示 应用场景 银行总行，总行有前台、后勤、网络等部门等，辖区下还有地方分行，也有前台、后勤、网络部门，最小的分行就没有子分行了 公司也是。总公司下有子公司，每个公司大部分的部门都类似 文件夹和文件，都有增加、删除等api，也有层级管理关系 当想表达的对象的部分-整体的层次结构 当我们的要处理的对象可以生成一颗树形结构，我们要对树上的节点和叶子进行操作时，它能够提供一致的方式，而不用考虑它是节点还是叶子 角色 组合部件（Component）：它是一个抽象接口，表示树根，例子：总行 合成部件（Composite）：和组合部件类似，也有自己的子节点，例子：总行下的分行 叶子（Leaf）：在组合中表示子节点对象，注意是没有子节点，例子：最小地方的分行 缺点 客户端需要花更多时间清理类之间的层次关系 优点 客户端只需要面对一致的对象而不用考虑整体部分或者节点叶子的问题 方便创建出复杂的层次结构 源码案例9.装饰器模式","categories":[],"tags":[]},{"title":"并发编程学习笔记","slug":"并发编程学习笔记","date":"2022-06-22T14:07:40.000Z","updated":"2022-08-18T15:34:23.818Z","comments":true,"path":"2022/06/22/并发编程学习笔记/","link":"","permalink":"http://www.xc234.ltd/2022/06/22/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"Java并发编程笔记一、基本概念1、进程与线程进程 进程是由指令和程序组成，但这些指令要运行，数据要读写，就必须将指令加载至CPU,数据加载至内存。在指令运行过程中还需要用到磁盘、网络等设备。进程是用来加载指令、管理内存、管理IO的。 当一个程序被运行，从磁盘加载这个程序的代码至内存，这时就开启了一个进程。 进程就可以视为程序的一个实例。大部分程序可以同时运行多个实例进程（例如记事本、画图、浏览器 等），也有的程序只能启动一个实例进程（例如网易云音乐、360安全卫士等） 线程 一个进程之内可以分为一到多个线程。 一个线程就是一个指令流，将指令流中的一条条指令以一定的顺序交给CPU执行。 Java中，线程作为最小调度单位，进程作为资源分配的最小单位。在Windows中进程是不活动的，只是作为线程的容器。 二者对比 进程基本上是相互独立的，而线程存于进程内，是进程的一个子集 进程拥有共享的资源，如内存空间等，供其内部的线程共享 进程间通信较为复杂 同一台计算机的进程通信称为IPC（Inter-process communication） 不同计算机之间的进程通信，需要通过网络，并遵守共同的协议，例如HTTP 线程通信相对简单，因为它们共享进程内的内存，一个例子是多个线程可以访问同一个共享变量 线程更轻量，线程上下文切换成本一般上要比进程上下文切换低 2、并发与并行并发就是一个CPU在不同的时间去不同线程中执行指令 并行就是多个CPU同时处理不同的线程 引用 Rob Pike 的一段描述： 并发（concurrent）是同一时间应对（dealing with）多件事情的能力 并行（parallel）是同一时间动手做（doing）多件事情的能力 例子: 家庭主妇做饭、打扫卫生、照顾孩子，她一个人轮流交替做这多件事，这时就是并发 家庭主妇雇佣了一个保姆，她们一起做这些事情，这时既有并发，也有并行（这时会产生竞争，例如只有一口锅，一个人用锅时，另一个人就得等待） 雇了3个保姆，一个专门做饭、一个专门打扫卫生、一个专门照顾孩子，互不干扰，这时是并行 3、应用应用之异步调用 以调用方角度来讲，如果 需要等待结果返回，才能继续运行就是同步 不需要等待结果返回，就能继续运行就是异步","categories":[],"tags":[]},{"title":"2022-2023","slug":"2022-2023","date":"2022-06-14T14:27:24.000Z","updated":"2022-06-14T14:28:04.815Z","comments":true,"path":"2022/06/14/2022-2023/","link":"","permalink":"http://www.xc234.ltd/2022/06/14/2022-2023/","excerpt":"","text":"时间安排准备2022 六月JVM​ 剩下的视频尽快看完，不能再拖了，请务必在6.17日前完成，并做好笔记，复习回顾，即刻进行下一阶段并发相关的学习 资料 JUC并发编程​ 6.18 6.19这两天初步学习，由于视频长度几乎是JVM的两倍，按照空闲时间以及自制力影响推断，六月基本不可能完成，延期到七月份 资料 2022 七月JUC并发编程 资料​ 预计7.15日前完成，并完成笔记整理，知识回顾。 JDK8-15新特性JDK8 9 10资料 JDK 13资料 JDK 14资料 JDK 15资料 看完前面JUC休息看会JDK新版的新特性，熟悉JDK发展路线及各个版本的新功能。预计7.25日前完成，并完成笔记梳理，知识回顾。 2022 八月设计模式 资料为了能更好的设计出’优雅’的代码，更好的理解很多技术的底层源码(方便之后进行框架的源码学习)，就要学习设计模式。预计8.10日前完成，并完成笔记梳理，知识回顾。 网络编程强化 NettyNetty是 Java 领域网络编程的王者，如果需要开发高性能的服务器程序、高性能的客户端程序，还真得掌握Netty，推上学习进程 ,预计九月份前完成，并完成笔记梳理，知识回顾。 资料 2022 九月 十月框架源码篇章以下暂时无先后顺序之分，根据易学程度串起来，所需学习时间暂时未知 MyBatis 源码剖析 MyBtis整体架构 配置文件解析 动态代理 核心调度执行器 MyBatis封装的JDBC MyBatis源码 MyBatis缓存陷阱 插件机制原理探究 Spring 源码深度剖析 Spring源码环境搭建， IOC容器初始化， XML解析引擎和对象生成原理 生命周期，多播器和读取器 Spring后处理器，Bean工厂、Environment环境， 循环依赖，依赖注入DI原理， AOP源码剖析、调用源头剖析， AOP代理对象与动态代理，责任链模式与反射调用， MVC执行流程、MVC与IOC容器关系 SpringBoot 源码剖析 main函数的作用 SpringBoot的Bean是如何初始化的 自动装配，工厂加载机制与SPI、万能启动器starter Tomcat源码剖析 Tomcat Servlet容器 引导类BootStrap 类加载器、管道，钩子线程 JDK 源码剖析 JDK源码环境搭建 Object源码剖析 HashCode源码剖析 动态数组ArrayList LinkedList底层实现原理前驱后继， 哈希映射HashMap，HashMap扰动函数、扩容，哈希运算寻址 HotSpot源码探索Synchronized锁， ConcurrentHashMap线程安全 2022 十一月 or 2022 十一、十二月具体内容暂时还未罗列好，可能会有以下这些（具体看到时候安排） 分布式篇章（情况1） 分布式架构设计&amp;微服务深入剖析 大型分布式存储系统架构进阶 大型分布式系统缓存架构进阶 分布式消息服务中间件进阶 分布式篇章（情况2） RPC 通信原理实战 RPC的设计架构与思想，RPC架构完整调用流程，自定义RPC相应因素详情等 Netty 通信技术进阶 Netty三大组件，ByteBuffer 之工作原理、应用模式、分配与释放机制、源码剖析等 纯手写 RPC RPC工程设计与整体结构，完成RPC服务注册与发现功能 注册中心 Zookeeper 源码深度剖析 ZK核心组件剖析，ZK工作流程剖析，网络通信组件、会话接收器、并发处理器等 Dubbo 核心源码剖析 Dubbo源码结构、整体设计及层次结构与作用，SPI机制，Dubbo服务注册发现剖析，Dubbo服务高可用，Dubbo服务治理之调用过程、服务降级与限流剖析，网络通信协议详解 或者是微服务篇 高级应用、原理、源码 核心组件注册中心Consul、服务网关Gateway、服务调用OpenFeign，负载均衡组件Ribbon、消息驱动Stream等，组件源码剖析 链路追踪 Skywalking 真实演练 Skywalking架构讲解、原理剖析、存储优化、探针等，追踪信息获取、 MySQL调用监控，RPC调用监控，线上问题排查定位等 Alibaba 主流微服务前沿技术栈 Sentinel架构学习、调用链路分析、流控方案、降级方案、熔断方案等，系统自我保护实现。Nacos架构分析、服务发现与DataId配置、Group分组方案等，Nacos权重管理，元数据管理，服务优雅上下线，一键回滚，推送轨迹，灰度发布执行流程源码剖析。Seata工作原理剖析，性能调优，集群，DataSourceProxy源码剖析等 Alibaba功能概述、多环境配置发布(热/灰度发布)等，Alibaba版本管理，权限管理、发布审核、操作审计，监控等 携程 Apollo 应用发布实战 服务网格 ServiceMesh 学习与实战 Service Mesh基础，Istio架构，核心特性，平台支持，搭建Istio环境，部署Bookinfo，可视化网络 2022 十二月 or 2023 一月消息中间件篇RabbitMQ 深度剖析 AMQP，消息可靠性投递、消息持久化 、死信队列、延迟队列等、排队人数管理-Redis Zset，打车呼叫超时系统技术方案，海量打车记录零数据丢失打车结果确认机制 RocketMQ 深度剖析 RocketMQ设计理念，可靠消息发送，消费进度保存机制，18个等级的延时消息分析，死信队列，消息存储机制，高可用集群搭建，RocketMQ保障数据安全性，日活6千万订单亚秒级处理方案 Kafka 深度剖析 Kafka系统架构及组件，Kafka消息传递 ，主题与分区-Kafka多通道设计，同步发送异步，消息消费偏移量，顺序消费，存储架构与零拷贝，Kafka海量订单数据的传输与分析，Kafka企业级监控利器Eagle OpenResty、Kong Nginx反向代理，负载均衡，高可用实战，单点故障，Lua脚本，OpenResty剖析，多级缓存架构，Kong网关，动态负载均衡，实时监控链路和性能指标，可扩展插件 2023 二月 三月面试篇","categories":[],"tags":[]},{"title":"","slug":"B站后端开发笔记","date":"2022-04-04T06:10:44.109Z","updated":"2022-06-14T14:28:04.826Z","comments":true,"path":"2022/04/04/B站后端开发笔记/","link":"","permalink":"http://www.xc234.ltd/2022/04/04/B%E7%AB%99%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/","excerpt":"","text":"B站后端开发笔记架构","categories":[],"tags":[]},{"title":"JVM学习笔记","slug":"JVM学习笔记","date":"2022-03-26T13:15:29.000Z","updated":"2022-06-16T13:44:54.757Z","comments":true,"path":"2022/03/26/JVM学习笔记/","link":"","permalink":"http://www.xc234.ltd/2022/03/26/JVM%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"JVM学习一、什么是JVM定义Java Virtual Machine，JAVA程序的运行环境（JAVA二进制字节码的运行环境） 好处 一次编写，到处运行 自动内存管理，垃圾回收机制 数组下标越界检查 比较JVM JRE JDK的区别 二、内存结构整体架构 1、程序计数器作用用于保存JVM中下一条所要执行的指令的地址 特点 线程私有 CPU会为每个线程分配时间片，当当前线程的时间片使用完以后，CPU就会去执行另一个线程中的代码 程序计数器是每个线程所私有的，当另一个线程的时间片用完，又返回来执行当前线程的代码时，通过程序计数器可以知道应该执行哪一句指令 不会存在内存溢出 2、虚拟机栈定义 每个线程运行需要的内存空间，称为虚拟机栈 每个栈由多个栈帧组成，对应着每次调用方法时所占用的内存 每个线程只能有一个活动栈帧，对应着当前正在执行的方法 演示代码 1234567891011121314public class Main &#123; public static void main(String[] args) &#123; method1(); &#125; private static void method1() &#123; method2(1, 2); &#125; private static int method2(int a, int b) &#123; int c = a + b; return c; &#125;&#125; 在控制台中可以看到，主类中的方法在进入虚拟机栈的时候，符合栈的特点 问题辨析 垃圾回收是否涉及栈内存 不需要。因为虚拟机栈中是由一个个栈帧组成的，在方法执行完毕后，对应的栈帧就会被弹出栈。所以无需通过垃圾回收机制去回收内存。 栈内存的分配越大越好吗？ 不是。因为物理内存是一定的，栈内存越大，可以支持更多的递归调用，但是可执行的线程数就会越少。（假如一个线程用了1m内存，总共的内存假设有500m，理论上可以有500个线程同时运行。 如果为每个线程的栈内存设置了2m内存，那么理论上只能同时最多运行256个线程） 方法内的局部变量是否是线程安全的？ 如果方法内局部变量没有逃离方法的作用范围，则是线程安全的 如果如果局部变量引用了对象，并逃离了方法的作用范围，则需要考虑线程安全问题 内存溢出Java.lang.stackOverflowError 栈内存溢出 发生原因 虚拟机栈中，栈帧过多（无限递归） 每个栈帧所占用过大 线程运行诊断CPU占用过高 Linux环境下运行某些程序的时候，可能导致CPU的占用过高，这时需要定位占用CPU过高的线程 top命令，查看是哪个进程占用CPU过高 ps H -eo pid, tid（线程id）, %cpu | grep 刚才通过top查到的进程号 通过ps命令进一步查看是哪个线程占用CPU过高（ps表示可以查看线程对cpu的占用情况 H表示可以打印进程的线程数，把进程的所有信息展示出来 -eo表示规定要输出那些 可以用grep来筛选 已知的进程编号） jstack 进程id 通过查看进程中的线程的nid，刚才通过ps命令看到的tid来对比定位，注意jstack查找出的线程id是16进制的，需要转换 此处进程id换算成16进制是7F99 此时可以发现问题在thread1这个线程，以下显示了具体的代码类的代码行数 3、本地方法栈一些带有native关键字的方法就是需要JAVA去调用本地的C或者C++方法，因为JAVA有时候没法直接和操作系统底层交互，所以需要用到本地方法。本地方法栈的作用就是为（本地）Native方法的调用提供内存空间 4、堆定义通过new关键字，创建对象都会使用堆内存 特点 所有线程共享，堆内存中的对象都需要考虑线程安全问题 有垃圾回收机制 堆内存溢出java.lang.OutofMemoryError ：java heap space 堆内存溢出 堆内存诊断jps 查看当前系统中有哪些Java进程 jmap 查看堆内存占用情况 jconsole 图形界面的，多功能的检测工具，可以连续监测 jvirsalvm 5、方法区结构 内存溢出 1.8以前会导致永久代内存溢出 1.8以后会导致元空间内存溢出 演示元空间内存溢出 常量池二进制字节码的组成：类的基本信息、常量池、类的方法定义（包含了虚拟机指令） 通过反编译来查看类的信息 获得对应类的.class文件 先编译所需要的类 打开IDEA的Terminal控制台 找到编译后的类的绝对路径 在控制台切换路径 1cd E:\\Study_Code\\jvm\\out\\production\\jvm\\cn\\itcast\\jvm\\t5 输入完成后，对应的目录下就会出现类的.class文件 在控制台输入 javap -v 类名 1javap -v HelloWorld.class 然后能在控制台看到反编译以后类的信息了 类的基本信息 常量池 虚拟机中执行编译的方法（框内的是真正编译执行的内容，**#号的内容需要在常量池中查找**） 运行时常量池 常量池 就是一张表（如上图中的constant pool），虚拟机指令根据这张常量表找到要执行的类名、方法名、参数类型、字面量信息 运行时常量池 常量池是*.class文件中的，当该类被加载以后，它的常量池信息就会放入运行时常量池，并把里面的符号地址变为真实地址 常量池与串池的关系串池StringTable特征 常量池中的字符串仅是符号，只有被用到时候才会转换为对象 利用串池的机制，来避免重复创建字符串对象 字符串变量拼接的原理是StringBuilder 字符串常量拼接的原理是编译器优化 可以用intern方法，主动将串池中还没有的字符串对象放入串池中 注意：无论是串池还是堆里面的字符串，都是对象 用来放字符串对象且里面的元素不重复 1234567public class StringTableStudy &#123; public static void main(String[] args) &#123; String a = &quot;a&quot;; String b = &quot;b&quot;; String ab = &quot;ab&quot;; &#125;&#125; 常量池中的信息，都会被加载到运行时常量池中，但这是a b ab 仅是常量池中的符号，还没有成为java字符串 12345670: ldc #2 &#x2F;&#x2F; String a2: astore_13: ldc #3 &#x2F;&#x2F; String b5: astore_26: ldc #4 &#x2F;&#x2F; String ab8: astore_39: return 当执行到 ldc #2时，会把 a 符号变为 “a” 字符串对象，这时会先在串池中查找，没找到然后把生成的字符串对象放入串池 StringTable [ “a” ] 当执行到 ldc #3 时，会把符号 b 变为 “b” 字符串对象，并放入串池中 StringTable [ “a”, “b” ] 当执行到 ldc #4 时，会把符号 ab 变为 “ab” 字符串对象，并放入串池中 StringTable [ “a”, “b” ,”ab” ] 最终StringTable [“a”, “b”, “ab”] 注意：字符串对象的创建都是懒惰的，只有当运行到那一行字符串且在串池中不存在的时候（如 ldc #2）时，该字符串才会被创建并放入串池中。 使用拼接字符串变量对象创建字符串的过程 123456789public class StringTableStudy &#123; public static void main(String[] args) &#123; String s1 = &quot;a&quot;; // 懒惰的 只有执行到所在代码行，即用到的时候才会放在串池中 String s2 = &quot;b&quot;; String s3 = &quot;ab&quot;; //拼接字符串对象来创建新的字符串 String s4 = s1 + s2; &#125;&#125; 反编译后的结果 123456789101112131415161718Code: stack=2, locals=5, args_size=1 0: ldc #2 // String a 2: astore_1 3: ldc #3 // String b 5: astore_2 6: ldc #4 // String ab 8: astore_3 9: new #5 // class java/lang/StringBuilder 12: dup 13: invokespecial #6 // Method java/lang/StringBuilder.&quot;&lt;init&gt;&quot;:()V 16: aload_1 17: invokevirtual #7 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 20: aload_2 21: invokevirtual #7 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 24: invokevirtual #8 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 27: astore 4 29: return 通过拼接的方式来创建字符串的过程是：StringBuilder().append(“a”).append(“b”).toString() 最后的toString方法的返回值是一个新的字符串，但字符串的值和拼接的字符串一致，但是两个不同的字符串，一个存在于串池之中，一个存在于堆内存之中 1234String s3 = &quot;ab&quot;;String s4 = a+b;//结果为false,因为s3是存在于串池之中，s4是由StringBuilder的toString方法所返回的一个对象，存在于堆内存之中System.out.println(s3 == s4); 使用拼接字符串常量对象的方法创建字符串 12345678910public class StringTableStudy &#123; public static void main(String[] args) &#123; String s1 = &quot;a&quot;; // 懒惰的 只有执行到所在代码行，即用到的时候才会放在串池中 String s2 = &quot;b&quot;; String s3 = &quot;ab&quot;; String s4 = s1 + s2; //使用拼接字符串的方法创建字符串 String s5 = &quot;a&quot; + &quot;b&quot;; &#125;&#125; 反编译后的结果 1234567891011121314151617181920Code: stack&#x3D;2, locals&#x3D;6, args_size&#x3D;1 0: ldc #2 &#x2F;&#x2F; String a 2: astore_1 3: ldc #3 &#x2F;&#x2F; String b 5: astore_2 6: ldc #4 &#x2F;&#x2F; String ab 8: astore_3 9: new #5 &#x2F;&#x2F; class java&#x2F;lang&#x2F;StringBuilder 12: dup 13: invokespecial #6 &#x2F;&#x2F; Method java&#x2F;lang&#x2F;StringBuilder.&quot;&lt;init&gt;&quot;:()V 16: aload_1 17: invokevirtual #7 &#x2F;&#x2F; Method java&#x2F;lang&#x2F;StringBuilder.append:(Ljava&#x2F;lang&#x2F;String;)Ljava&#x2F;lang&#x2F;StringBuilder; 20: aload_2 21: invokevirtual #7 &#x2F;&#x2F; Method java&#x2F;lang&#x2F;StringBuilder.append:(Ljava&#x2F;lang&#x2F;String;)Ljava&#x2F;lang&#x2F;StringBuilder; 24: invokevirtual #8 &#x2F;&#x2F; Method java&#x2F;lang&#x2F;StringBuilder.toString:()Ljava&#x2F;lang&#x2F;String; 27: astore 4 29: ldc #4 &#x2F;&#x2F; String ab 31: astore 5 33: return 使用拼接字符串常量的方法来创建新的字符串时，因为内存是常量，javac在编译期会进行优化，结果已在编译器确定为ab,而创建ab的时候已经在串池中放入了“ab”，所以s5直接从串池中获取值，所以进行的操作和 s3 = “ab”一致。 使用拼接字符串变量的方法来创建新的字符串时，因为内容是变量，只能在运行期确定它的值，所以需要使用StringBuilder来创建 intern方法 1.8(JDK1.8)调用字符串对象的intern方法，会将该字符串对象尝试放入到串池中 如果串池中没有该字符串对象，则放入成功 如果有该字符串对象，则放入失败 无论放入是否成功，都会返回串池中的字符串对象 注意：此时如果调用intern方法成功，堆内存与串池中的字符串对象是同一个对象；如果失败，则不是同一个对象 例1 12345678910111213public class Main &#123; public static void main(String[] args) &#123; //&quot;a&quot; &quot;b&quot; 被放入串池中，str则存在于堆内存之中 String str = new String(&quot;a&quot;) + new String(&quot;b&quot;); //调用str的intern方法，这时串池中没有&quot;ab&quot;，则会将该字符串对象放入到串池中，此时堆内存与串池中的&quot;ab&quot;是同一个对象 String st2 = str.intern(); //给str3赋值，因为此时串池中已有&quot;ab&quot;，则直接将串池中的内容返回 String str3 = &quot;ab&quot;; //因为堆内存与串池中的&quot;ab&quot;是同一个对象，所以以下两条语句打印的都为true System.out.println(str == st2); System.out.println(str == str3); &#125;&#125; 例2 12345678910111213141516public class Main &#123; public static void main(String[] args) &#123; //此处创建字符串对象&quot;ab&quot;，因为串池中还没有&quot;ab&quot;，所以将其放入串池中 String str3 = &quot;ab&quot;; //&quot;a&quot; &quot;b&quot; 被放入串池中，str则存在于堆内存之中 String str = new String(&quot;a&quot;) + new String(&quot;b&quot;); //此时因为在创建str3时，&quot;ab&quot;已存在与串池中，所以放入失败，但是会返回串池中的&quot;ab&quot; String str2 = str.intern(); //false System.out.println(str == str2); //false System.out.println(str == str3); //true System.out.println(str2 == str3); &#125;&#125; intern方法 1.6(JDK1.6)调用字符串对象的intern方法，会将该字符串对象尝试放入到串池中 如果串池中没有该字符串对象，会将该字符串对象复制一份，再放入到串池中 如果有该字符串对象，则放入失败 无论放入是否成功，都会返回串池中的字符串对象 注意：此时无论调用intern方法成功与否，串池中的字符串对象和堆内存中的字符串对象都不是同一个对象 StringTable 垃圾回收StringTable在内存紧张时，会发生垃圾回收 StringTable调优 因为StringTable是由HashTable实现的，所以可以适当增加HashTable桶的个数，来减少字符串放入串池所需要的时间 1-XX:StringTableSize&#x3D;xxxxCopy 考虑是否需要将字符串对象入池 可以通过intern方法减少重复入池 6、直接内存 属于操作系统，常见于NIO操作时，用于数据缓冲区 分配回收成本较高，但读写性能高 不受JVM内存回收管理 文件读写流程 使用了DirectBuffer 直接内存(direct memory)是操作系统和Java代码都可以访问的一块区域，无需将代码从系统内存复制到Java堆内存，从而提高了效率 释放原理直接内存的回收不是通过JVM的垃圾回收来释放的，而是通过unsafe.freeMemory来手动释放 通过 12//通过ByteBuffer申请1M的直接内存ByteBuffer byteBuffer = ByteBuffer.allocateDirect(_1M); 申请直接内存，但JVM并不能回收直接内存中的内容，它是如何实现回收的呢？ allocateDirect的实现 123public static ByteBuffer allocateDirect(int capacity) &#123; return new DirectByteBuffer(capacity);&#125; DirectByteBuffer类 12345678910111213141516171819202122232425DirectByteBuffer(int cap) &#123; // package-private super(-1, 0, cap, cap); boolean pa = VM.isDirectMemoryPageAligned(); int ps = Bits.pageSize(); long size = Math.max(1L, (long)cap + (pa ? ps : 0)); Bits.reserveMemory(size, cap); long base = 0; try &#123; base = unsafe.allocateMemory(size); //申请内存 &#125; catch (OutOfMemoryError x) &#123; Bits.unreserveMemory(size, cap); throw x; &#125; unsafe.setMemory(base, size, (byte) 0); if (pa &amp;&amp; (base % ps != 0)) &#123; // Round up to page boundary address = base + ps - (base &amp; (ps - 1)); &#125; else &#123; address = base; &#125; cleaner = Cleaner.create(this, new Deallocator(base, size, cap)); //通过虚引用，来实现直接内存的释放，this为虚引用的实际对象 att = null;&#125; 这里调用了一个Cleaner的create方法，且后台线程还会对虚引用的对象监测，如果虚引用的实际对象（这里是DirectByteBuffer）被回收以后，就会调用Cleaner的clean方法，来清除直接内存中占用的内存空间 12345678910111213141516public void clean() &#123; if (remove(this)) &#123; try &#123; this.thunk.run(); //调用run方法 &#125; catch (final Throwable var2) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; if (System.err != null) &#123; (new Error(&quot;Cleaner terminated abnormally&quot;, var2)).printStackTrace(); &#125; System.exit(1); return null; &#125; &#125;); &#125; 对应对象的run方法 123456789public void run() &#123; if (address == 0) &#123; // Paranoia return; &#125; unsafe.freeMemory(address); //释放直接内存中占用的内存 address = 0; Bits.unreserveMemory(size, capacity);&#125; 直接内存的回收机制总结 使用了Unsafe类来完成直接内存的分配回收，回收需要主动调用freeMemory方法 ByteBuffer的实现内部使用了Cleaner（虚引用）来检测ByteBuffer。一旦ByteBuffer被垃圾回收，那么会由ReferenceHandler来调用Cleaner的clean方法调用freeMemory来释放内存 三、垃圾回收1、如何判断对象可以回收什么是内存泄漏在Java中，内存泄漏就是存在一些被分配的对象，这些对象有下面两个特点，首先，这些对象是可达的，即在有向图中，存在通路可以与其相连；其次，这些对象是无用的，即程序以后不会再使用这些对象。如果对象满足这两个条件，这些对象就可以判定为Java中的内存泄漏，这些对象不会被GC所回收，然而它却占用内存。 引用计数法弊端：循环引用时，两个对象的计数都为1，导致两个对象都无法被释放 可达性分析算法 JVM中的垃圾回收器通过可达性分析来探索所有存活的对象 扫描堆中的对象，看能否沿着GC Root对象为起点的引用链找到该对象，如果找不到，则表示可以回收 可以作为GC Root的对象 虚拟机栈（栈帧中的本地变量表）中引用的对象。 方法区中类静态属性引用的对象 方法区中常量引用的对象 本地方法栈中JNI（即一般说的Native方法）引用的对象 五种引用 强引用（上图实线代表强引用）只有GC Root都不引用该对象时，才会回收强引用对象 如上图B、C对象都不引用A1对象时，A1对象才会被回收 软引用当GC Root指向软引用对象时，在内存不足时，会回收软引用所引用的对象 如上图如果B对象不再引用A2对象且内存不足时，软引用所引用的A2对象就会被回收 软引用的使用 12345678public class Soft_Demo &#123; public static void main(String[] args) &#123; final int _4M = 4*1024*1024; //使用软引用对象 list和SoftReference是强引用，而SoftReference和byte数组则是软引用 List&lt;SoftReference&lt;byte[]&gt;&gt; list = new ArrayList&lt;&gt;(); SoftReference&lt;byte[]&gt; ref= new SoftReference&lt;&gt;(new byte[_4M]); &#125;&#125; 如果在垃圾回收时发现内存不足，在回收软引用所指向的对象时，软引用本身不会被清理 如果想要清理软引用，需要使用引用队列 1234567891011121314151617181920212223242526public class Soft_Demo &#123; public static void main(String[] args) &#123; final int _4M = 4 * 1024 * 1024; //使用软引用对象 list和SoftReference是强引用，而SoftReference和byte数组则是软引用 List&lt;SoftReference&lt;byte[]&gt;&gt; list = new ArrayList&lt;&gt;(); //使用引用队列，用于移除引用为空的软引用对象 ReferenceQueue&lt;byte[]&gt; queue = new ReferenceQueue&lt;&gt;(); for (int i = 0; i &lt; 5; i++) &#123; // 关联了引用队列， 当软引用所关联的 byte[]被回收时，软引用自己会加入到 queue 中去 SoftReference&lt;byte[]&gt; ref = new SoftReference&lt;&gt;(new byte[_4M], queue); System.out.println(ref.get()); list.add(ref); System.out.println(list.size()); &#125; //遍历引用队列 从队列中获取无用的 软引用对象，并移除 Reference&lt;? extends byte[]&gt; poll = queue.poll(); while (poll != null) &#123; //引用队列不为空，则从集合中移除该元素 list.remove(poll); //移动到引用队列中的下一个元素 poll = queue.poll(); &#125; &#125;&#125; 大概思路为：查看引用队列中有无软引用，如果有，则将该软引用从存放它的集合中移除（这里为一个list集合） 弱引用只有弱引用引用该对象时，在垃圾回收时，无论内存是否充足，都会回收弱引用所引用的对象 弱引用的使用和软引用类似，只是将 SoftReference 换为了 WeakReference 虚引用当虚引用对象所引用的对象被回收以后，虚引用对象就会被放入引用队列中，调用虚引用的方法 虚引用的一个体现是释放直接内存所分配的内存，当引用的对象ByteBuffer被垃圾回收以后，虚引用对象Cleaner就会被放入引用队列中，然后调用Cleaner的clean方法来释放直接内存 如上图，B对象不再引用ByteBuffer对象，ByteBuffer就会被回收。但是直接内存中的内存还未被回收。这时需要将虚引用对象Cleaner放入引用队列中，然后调用它的clean方法来释放直接内存 终结器引用所有的类都继承自Object类，Object类有一个finalize方法。当某个对象不再被其他的对象所引用时，会先将终结器引用对象放入引用队列中，然后根据终结器引用对象找到它所引用的对象，然后调用该对象的finalize方法。调用以后，该对象就可以被垃圾回收了 如上图，B对象不再引用A4对象。这时终结器对象就会被放入引用队列中，引用队列会根据它，找到它所引用的对象。然后调用被引用对象的finalize方法。调用以后，该对象就可以被垃圾回收了 引用队列 软引用和弱引用可以配合引用队列 在弱引用和虚引用所引用的对象被回收以后，会将这些引用放入引用队列中，方便一起回收这些软/弱引用对象 虚引用和终结器引用必须配合引用队列 虚引用和终结器引用在使用时会关联一个引用队列 2、垃圾回收算法标记-清除 定义：标记清除算法顾名思义，是指在虚拟机执行垃圾回收的过程中，先采用标记算法确定可回收对象，然后垃圾收集器根据标识清除相应的内容，给堆内存腾出相应的空间 这里腾出内存空间并不是将内存空间的字节清0，而是记录下这段内存的起始结束地址，下次分配内存的时候，会直接覆盖这段内存 缺点：容易产生大量的内存碎片，可能无法满足大对象的内存分配，一旦导致无法分配对象，那就会导致jvm启动gc，一旦启动gc，我们的应用程序就会暂停，这就导致应用的响应速度变慢 标记-整理 标记-整理 会将不被GC Root引用的对象回收，清除其占用的内存空间。然后将整理剩余的对象，可以有效避免因内存碎片而导致的问题，但是因为整体需要消耗一定的时间，所以效率较低 复制 将内存大小分为等大小的两个区域，FROM和TO（TO中为空）。先将被GC Root引用的对象从FROM放入TO中，再回收不被GC Root引用的对象。然后交换FROM和TO。这样可以避免内存碎片的问题，但是会占用双倍的内存空间。 3、分代回收 回收流程新创建的对象都被放在了新生代的伊甸园中 当伊甸园中的内存不足时，就会进行一次垃圾回收，这时的回收叫做Minor GC Minor GC 会将伊甸园和幸存区FROM存活的对象先复制到 幸存区 TO中， 并让其寿命加1，再交换两个幸存区 再次创建对象，若新生代的伊甸园又满了，则会再次触发 Minor GC（会触发 stop the world， 暂停其他用户线程，只让垃圾回收线程工作），这时不仅会回收伊甸园中的垃圾，还会回收幸存区中的垃圾，再将活跃对象复制到幸存区TO中。回收以后会交换两个幸存区，并让幸存区中的对象寿命加1 如果幸存区中的对象的寿命超过某个阈值（最大为15，4bit），就会被放入老年代中 如果新生代老年代中的内存都满了，就会先触发Minor GC，再触发Full GC，扫描新生代和老年代中所有不再使用的对象并回收 GC 分析大对象处理策略当遇到一个较大的对象时，就算新生代的伊甸园为空，也无法容纳该对象时，会将该对象直接晋升为老年代 线程内存溢出某个线程的内存溢出了而抛异常（out of memory），不会让其他的线程结束运行 这是因为当一个线程抛出OOM异常后，它所占据的内存资源会全部被释放掉，从而不会影响其他线程的运行，进程依然正常 4、垃圾回收器相关概念并行收集：指多条垃圾收集线程并行工作，但此时用户线程仍处于等待状态。 并发收集：指用户线程与垃圾收集线程同时工作（不一定是并行的可能会交替执行）。用户程序在继续运行，而垃圾收集程序运行在另一个CPU上 吞吐量：即CPU用于运行用户代码的时间与CPU总消耗时间的比值（吞吐量 = 运行用户代码时间 / ( 运行用户代码时间 + 垃圾收集时间 )），也就是。例如：虚拟机共运行100分钟，垃圾收集器花掉1分钟，那么吞吐量就是99% 串行 单线程 内存较小，个人电脑（CPU核数较少） 安全点：让其他线程都在这个点停下来，以免垃圾回收时移动对象地址，使得其他线程找不到被移动的对象 因为是串行的，所以只有一个垃圾回收线程。且在该线程执行回收工作时，其他线程进入阻塞状态 Serial 收集器Serial收集器是最基本的、发展历史最悠久的收集器 特点：单线程、简单高效（与其他收集器的单线程相比），采用复制算法。对于限定单个CPU的环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程手机效率。收集器进行垃圾回收时，必须暂停其他所有的工作线程，直到它结束（Stop The World） ParNew 收集器ParNew收集器其实就是Serial收集器的多线程版本 特点：多线程、ParNew收集器默认开启的收集线程数与CPU的数量相同，在CPU非常多的环境中，可以使用-XX:ParallelGCThreads参数来限制垃圾收集的线程数。和Serial收集器一样存在Stop The World问题 Serial Old 收集器Serial Old是Serial收集器的老年代版本 特点：同样是单线程收集器，采用标记-整理算法 吞吐量优先 多线程 堆内存较大，多核CPU 单位时间内，STW（stop the world，停掉其他所有工作线程）时间最短 JDK1.8默认使用的垃圾回收器 Parallel Scavenge 收集器与吞吐量关系密切，故也称为吞吐量优先收集器 特点：属于新生代收集器也是采用复制算法的收集器（用到了新生代的幸存区），又是并行的多线程收集器（与ParNew收集器类似） 该收集器的目标是达到一个可控制的吞吐量。还有一个值得关注的点是：GC自适应调节策略（与ParNew收集器最重要的一个区别） GC自适应调节策略：Parallel Scavenge收集器可设置-XX:+UseAdptiveSizePolicy参数。当开关打开时不需要手动指定新生代的大小（-Xmn）、Eden与Survivor区的比例（-XX:SurvivorRation）、晋升老年代的对象年龄（-XX:PretenureSizeThreshold）等，虚拟机会根据系统的运行状况收集性能监控信息，动态设置这些参数以提供最优的停顿时间和最高的吞吐量，这种调节方式称为GC的自适应调节策略。 Parallel Scavenge收集器使用两个参数控制吞吐量： XX:MaxGCPauseMillis 控制最大的垃圾收集停顿时间 XX:GCRatio 直接设置吞吐量的大小 Parallel Old 收集器是Parallel Scavenge收集器的老年代版本 特点：多线程，采用标记-整理算法（老年代没有幸存区） 响应时间优先 多线程 堆内存较大，多核CPU 尽可能让单次STW时间变短（尽量不影响其他线程运行） CMS 收集器Concurrent Mark Sweep，一种以获取最短回收停顿时间为目标的老年代收集器 特点：基于标记-清除算法实现。并发收集、低停顿，但是会产生内存碎片 应用场景：适用于注重服务的响应速度，希望系统停顿时间最短，给用户带来更好的体验等场景下。如web程序、b/s服务 CMS收集器的运行过程分为下列4步： 初始标记：标记GC Roots能直接到的对象。速度很快但是仍存在Stop The World问题 并发标记：进行GC Roots Tracing 的过程，找出存活对象且用户线程可并发执行 重新标记：为了修正并发标记期间因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录。仍然存在Stop The World问题 并发清除：对标记的对象进行清除回收 CMS收集器的内存回收过程是与用户线程一起并发执行的 G1定义：Garbage First JDK 9以后默认使用，而且替代了CMS 收集器 适用场景 同时注重吞吐量和低延迟（响应时间） 超大堆内存（内存大的），会将堆内存划分为多个大小相等的区域 整体上是标记-整理算法，两个区域之间是复制算法 相关参数：JDK8 并不是默认开启的，所需要参数开启 G1垃圾回收阶段 新生代伊甸园垃圾回收—–&gt;内存不足，新生代回收+并发标记—–&gt;回收新生代伊甸园、幸存区、老年代内存——&gt;新生代伊甸园垃圾回收(重新开始) Young Collection分区算法region 分代是按对象的生命周期划分，分区则是将堆空间划分连续几个不同小区间，每一个小区间独立回收，可以控制一次回收多少个小区间，方便控制 GC 产生的停顿时间 E：伊甸园 S：幸存区 O：老年代 会STW Young Collection + CMCM：并发标记 在 Young GC 时会对 GC Root 进行初始标记 在老年代占用堆内存的比例达到阈值时，对进行并发标记（不会STW），阈值可以根据用户来进行设定 [ Mixed Collection会对E S O 进行全面的回收 最终标记 拷贝存活 -XX:MaxGCPauseMills:xxx 用于指定最长的停顿时间 问：为什么有的老年代被拷贝了，有的没拷贝？ 因为指定了最大停顿时间，如果对所有老年代都进行回收，耗时可能过高。为了保证时间不超过设定的停顿时间，会回收最有价值的老年代（回收后，能够得到更多内存） [ Full GCG1在老年代内存不足时（老年代所占内存超过阈值） 如果垃圾产生速度慢于垃圾回收速度，不会触发Full GC，还是并发地进行清理 如果垃圾产生速度快于垃圾回收速度，便会触发Full GC Young Collection 跨代引用 新生代回收的跨代引用（老年代引用新生代）问题 卡表与Remembered Set Remembered Set 存在于E中，用于保存新生代对象对应的脏卡 脏卡：O被划分为多个区域（一个区域512K），如果该区域引用了新生代对象，则该区域被称为脏卡 在引用变更时通过post-write barried + dirty card queue concurrent refinement threads 更新 Remembered Set Remark重新标记阶段 在垃圾回收时，收集器处理对象的过程中 黑色：已被处理，需要保留的 灰色：正在处理中的 白色：还未处理的 但是在并发标记过程中，有可能A被处理了以后未引用C，但该处理过程还未结束，在处理过程结束之前A引用了C，这时就会用到remark 过程如下 之前C未被引用，这时A引用了C，就会给C加一个写屏障，写屏障的指令会被执行，将C放入一个队列当中，并将C变为 处理中 状态 在并发标记阶段结束以后，重新标记阶段会STW，然后将放在该队列中的对象重新处理，发现有强引用引用它，就会处理它 JDK 8u20 字符串去重过程 将所有新分配的字符串（底层是char[]）放入一个队列 当新生代回收时，G1并发检查是否有重复的字符串 如果字符串的值一样，就让他们引用同一个字符串对象 注意，其与String.intern的区别 intern关注的是字符串对象 字符串去重关注的是char[] 在JVM内部，使用了不同的字符串标 优点与缺点 节省了大量内存 新生代回收时间略微增加，导致略微多占用CPU JDK 8u40 并发标记类卸载在并发标记阶段结束以后，就能知道哪些类不再被使用。如果一个类加载器的所有类都不在使用，则卸载它所加载的所有类 JDK 8u60 回收巨型对象 一个对象大于region的一半时，就称为巨型对象 G1不会对巨型对象进行拷贝 回收时被优先考虑 G1会跟踪老年代所有incoming引用，如果老年代incoming引用为0的巨型对象就可以在新生代垃圾回收时处理掉 5、GC 调优查看虚拟机参数命令 1&quot;F:\\JAVA\\JDK8.0\\bin\\java&quot; -XX:+PrintFlagsFinal -version | findstr &quot;GC&quot;Copy 可以根据参数去查询具体的信息 调优领域 内存 锁竞争 CPU占用 IO GC 确定目标低延迟/高吞吐量？ 选择合适的GC CMS G1 ZGC ParallelGC Zing 最快的GC是不发生GC首先排除减少因为自身编写的代码而引发的内存问题 查看Full GC前后的内存占用，考虑以下几个问题 数据是不是太多？ 数据表示是否太臃肿 对象图 对象大小 是否存在内存泄漏 新生代调优 新生代的特点 所有的new操作分配内存都是非常廉价的 TLAB 死亡对象回收零代价 大部分对象用过即死（朝生夕死） MInor GC 所用时间远小于Full GC 新生代内存越大越好么？ 不是 新生代内存太小：频繁触发Minor GC，会STW，会使得吞吐量下降 新生代内存太大：老年代内存占比有所降低，会更频繁地触发Full GC。而且触发Minor GC时，清理新生代所花费的时间会更长 新生代内存设置为内容纳[并发量*(请求-响应)]的数据为宜 幸存区调优 幸存区需要能够保存 当前活跃对象+需要晋升的对象 晋升阈值配置得当，让长时间存活的对象尽快晋升 老年代调优四、类加载与字节码技术 1、类文件结构首先获得.class字节码文件 方法： 在文本文档里写入java代码（文件名与类名一致），将文件类型改为.java java终端中，执行javac X:…\\XXX.java 以下是字节码文件 12345678910111213141516171819202122232425262728293031323334353637380000000 ca fe ba be 00 00 00 34 00 23 0a 00 06 00 15 09 0000020 00 16 00 17 08 00 18 0a 00 19 00 1a 07 00 1b 07 0000040 00 1c 01 00 06 3c 69 6e 69 74 3e 01 00 03 28 29 0000060 56 01 00 04 43 6f 64 65 01 00 0f 4c 69 6e 65 4e 0000100 75 6d 62 65 72 54 61 62 6c 65 01 00 12 4c 6f 63 0000120 61 6c 56 61 72 69 61 62 6c 65 54 61 62 6c 65 01 0000140 00 04 74 68 69 73 01 00 1d 4c 63 6e 2f 69 74 63 0000160 61 73 74 2f 6a 76 6d 2f 74 35 2f 48 65 6c 6c 6f 0000200 57 6f 72 6c 64 3b 01 00 04 6d 61 69 6e 01 00 16 0000220 28 5b 4c 6a 61 76 61 2f 6c 61 6e 67 2f 53 74 72 0000240 69 6e 67 3b 29 56 01 00 04 61 72 67 73 01 00 13 0000260 5b 4c 6a 61 76 61 2f 6c 61 6e 67 2f 53 74 72 69 0000300 6e 67 3b 01 00 10 4d 65 74 68 6f 64 50 61 72 61 0000320 6d 65 74 65 72 73 01 00 0a 53 6f 75 72 63 65 46 0000340 69 6c 65 01 00 0f 48 65 6c 6c 6f 57 6f 72 6c 640000360 2e 6a 61 76 61 0c 00 07 00 08 07 00 1d 0c 00 1e 0000400 00 1f 01 00 0b 68 65 6c 6c 6f 20 77 6f 72 6c 64 0000420 07 00 20 0c 00 21 00 22 01 00 1b 63 6e 2f 69 74 0000440 63 61 73 74 2f 6a 76 6d 2f 74 35 2f 48 65 6c 6c 0000460 6f 57 6f 72 6c 64 01 00 10 6a 61 76 61 2f 6c 61 0000500 6e 67 2f 4f 62 6a 65 63 74 01 00 10 6a 61 76 61 0000520 2f 6c 61 6e 67 2f 53 79 73 74 65 6d 01 00 03 6f 0000540 75 74 01 00 15 4c 6a 61 76 61 2f 69 6f 2f 50 72 0000560 69 6e 74 53 74 72 65 61 6d 3b 01 00 13 6a 61 76 0000600 61 2f 69 6f 2f 50 72 69 6e 74 53 74 72 65 61 6d 0000620 01 00 07 70 72 69 6e 74 6c 6e 01 00 15 28 4c 6a 0000640 61 76 61 2f 6c 61 6e 67 2f 53 74 72 69 6e 67 3b 0000660 29 56 00 21 00 05 00 06 00 00 00 00 00 02 00 01 0000700 00 07 00 08 00 01 00 09 00 00 00 2f 00 01 00 01 0000720 00 00 00 05 2a b7 00 01 b1 00 00 00 02 00 0a 00 0000740 00 00 06 00 01 00 00 00 04 00 0b 00 00 00 0c 00 0000760 01 00 00 00 05 00 0c 00 0d 00 00 00 09 00 0e 00 0001000 0f 00 02 00 09 00 00 00 37 00 02 00 01 00 00 00 0001020 09 b2 00 02 12 03 b6 00 04 b1 00 00 00 02 00 0a 0001040 00 00 00 0a 00 02 00 00 00 06 00 08 00 07 00 0b 0001060 00 00 00 0c 00 01 00 00 00 09 00 10 00 11 00 00 0001100 00 12 00 00 00 05 01 00 10 00 00 00 01 00 13 00 0001120 00 00 02 00 14Copy 根据 JVM 规范，类文件结构如下 12345678910111213141516u4 magicu2 minor_version; u2 major_version; u2 constant_pool_count; cp_info constant_pool[constant_pool_count-1]; u2 access_flags; u2 this_class; u2 super_class; u2 interfaces_count; u2 interfaces[interfaces_count]; u2 fields_count; field_info fields[fields_count]; u2 methods_count; method_info methods[methods_count]; u2 attributes_count; attribute_info attributes[attributes_count];Copy 魔数u4 magic 对应字节码文件的0~3个字节 0000000 ca fe ba be 00 00 00 34 00 23 0a 00 06 00 15 09 版本u2 minor_version; u2 major_version; 0000000 ca fe ba be 00 00 00 34 00 23 0a 00 06 00 15 09 34H = 52，代表JDK8 常量池见资料文件 …略 2、字节码指令可参考 https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-6.html#jvms-6.5 javap工具Oracle 提供了 javap 工具来反编译 class 文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465javap -v F:\\Thread_study\\src\\com\\nyima\\JVM\\day01\\Main.classCopyF:\\Thread_study&gt;javap -v F:\\Thread_study\\src\\com\\nyima\\JVM\\day5\\Demo1.classClassfile &#x2F;F:&#x2F;Thread_study&#x2F;src&#x2F;com&#x2F;nyima&#x2F;JVM&#x2F;day5&#x2F;Demo1.class Last modified 2020-6-6; size 434 bytes MD5 checksum df1dce65bf6fb0b4c1de318051f4a67e Compiled from &quot;Demo1.java&quot;public class com.nyima.JVM.day5.Demo1 minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPERConstant pool: #1 &#x3D; Methodref #6.#15 &#x2F;&#x2F; java&#x2F;lang&#x2F;Object.&quot;&lt;init&gt;&quot;:()V #2 &#x3D; Fieldref #16.#17 &#x2F;&#x2F; java&#x2F;lang&#x2F;System.out:Ljava&#x2F;io&#x2F;PrintStream; #3 &#x3D; String #18 &#x2F;&#x2F; hello world #4 &#x3D; Methodref #19.#20 &#x2F;&#x2F; java&#x2F;io&#x2F;PrintStream.println:(Ljava&#x2F;lang&#x2F;String;)V #5 &#x3D; Class #21 &#x2F;&#x2F; com&#x2F;nyima&#x2F;JVM&#x2F;day5&#x2F;Demo1 #6 &#x3D; Class #22 &#x2F;&#x2F; java&#x2F;lang&#x2F;Object #7 &#x3D; Utf8 &lt;init&gt; #8 &#x3D; Utf8 ()V #9 &#x3D; Utf8 Code #10 &#x3D; Utf8 LineNumberTable #11 &#x3D; Utf8 main #12 &#x3D; Utf8 ([Ljava&#x2F;lang&#x2F;String;)V #13 &#x3D; Utf8 SourceFile #14 &#x3D; Utf8 Demo1.java #15 &#x3D; NameAndType #7:#8 &#x2F;&#x2F; &quot;&lt;init&gt;&quot;:()V #16 &#x3D; Class #23 &#x2F;&#x2F; java&#x2F;lang&#x2F;System #17 &#x3D; NameAndType #24:#25 &#x2F;&#x2F; out:Ljava&#x2F;io&#x2F;PrintStream; #18 &#x3D; Utf8 hello world #19 &#x3D; Class #26 &#x2F;&#x2F; java&#x2F;io&#x2F;PrintStream #20 &#x3D; NameAndType #27:#28 &#x2F;&#x2F; println:(Ljava&#x2F;lang&#x2F;String;)V #21 &#x3D; Utf8 com&#x2F;nyima&#x2F;JVM&#x2F;day5&#x2F;Demo1 #22 &#x3D; Utf8 java&#x2F;lang&#x2F;Object #23 &#x3D; Utf8 java&#x2F;lang&#x2F;System #24 &#x3D; Utf8 out #25 &#x3D; Utf8 Ljava&#x2F;io&#x2F;PrintStream; #26 &#x3D; Utf8 java&#x2F;io&#x2F;PrintStream #27 &#x3D; Utf8 println #28 &#x3D; Utf8 (Ljava&#x2F;lang&#x2F;String;)V&#123; public com.nyima.JVM.day5.Demo1(); descriptor: ()V flags: ACC_PUBLIC Code: stack&#x3D;1, locals&#x3D;1, args_size&#x3D;1 0: aload_0 1: invokespecial #1 &#x2F;&#x2F; Method java&#x2F;lang&#x2F;Object.&quot;&lt;init&gt;&quot;:()V 4: return LineNumberTable: line 7: 0 public static void main(java.lang.String[]); descriptor: ([Ljava&#x2F;lang&#x2F;String;)V flags: ACC_PUBLIC, ACC_STATIC Code: stack&#x3D;2, locals&#x3D;1, args_size&#x3D;1 0: getstatic #2 &#x2F;&#x2F; Field java&#x2F;lang&#x2F;System.out:Ljava&#x2F;io&#x2F;PrintStream; 3: ldc #3 &#x2F;&#x2F; String hello world 5: invokevirtual #4 &#x2F;&#x2F; Method java&#x2F;io&#x2F;PrintStream.println:(Ljava&#x2F;lang&#x2F;String;)V 8: return LineNumberTable: line 9: 0 line 10: 8&#125;Copy 图解方法执行流程代码 12345678public class Demo3_1 &#123; public static void main(String[] args) &#123; int a &#x3D; 10; int b &#x3D; Short.MAX_VALUE + 1; int c &#x3D; a + b; System.out.println(c); &#125; &#125;Copy 常量池载入运行时常量池 常量池也属于方法区，只不过这里单独提出来了 方法字节码载入方法区 （stack=2，locals=4） 对应操作数栈有2个空间（每个空间4个字节），局部变量表中有4个槽位 执行引擎开始执行字节码 bipush 10 将一个 byte 压入操作数栈 （其长度会补齐 4 个字节），类似的指令还有 sipush 将一个 short 压入操作数栈（其长度会补齐 4 个字节） ldc 将一个 int 压入操作数栈 ldc2_w 将一个 long 压入操作数栈（分两次压入，因为 long 是 8 个字节） 这里小的数字都是和字节码指令存在一起，超过 short 范围的数字存入了常量池 istore 1 将操作数栈栈顶元素弹出，放入局部变量表的slot 1中 对应代码中的 1a &#x3D; 10Copy ldc #3 读取运行时常量池中#3，即32768(超过short最大值范围的数会被放到运行时常量池中)，将其加载到操作数栈中 注意 Short.MAX_VALUE 是 32767，所以 32768 = Short.MAX_VALUE + 1 实际是在编译期间计算好的 istore 2 将操作数栈中的元素弹出，放到局部变量表的2号位置 iload1 iload2 将局部变量表中1号位置和2号位置的元素放入操作数栈中 因为只能在操作数栈中执行运算操作 iadd 将操作数栈中的两个元素弹出栈并相加，结果在压入操作数栈中 istore 3 将操作数栈中的元素弹出，放入局部变量表的3号位置 getstatic #4 在运行时常量池中找到#4，发现是一个对象 在堆内存中找到该对象，并将其引用放入操作数栈中 iload 3 将局部变量表中3号位置的元素压入操作数栈中 invokevirtual 5 找到常量池 #5 项，定位到方法区 java/io/PrintStream.println:(I)V 方法 生成新的栈帧（分配 locals、stack等） 传递参数，执行新栈帧中的字节码 执行完毕，弹出栈帧 清除 main 操作数栈内容 return完成 main 方法调用，弹出 main 栈帧，程序结束 通过字节码指令来分析问题代码 1234567891011public class Demo2 &#123; public static void main(String[] args) &#123; int i&#x3D;0; int x&#x3D;0; while(i&lt;10) &#123; x &#x3D; x++; i++; &#125; System.out.println(x); &#x2F;&#x2F;接过为0 &#125;&#125;Copy 为什么最终的x结果为0呢？ 通过分析字节码指令即可知晓 123456789101112131415161718Code: stack&#x3D;2, locals&#x3D;3, args_size&#x3D;1 &#x2F;&#x2F;操作数栈分配2个空间，局部变量表分配3个空间 0: iconst_0 &#x2F;&#x2F;准备一个常数0 1: istore_1 &#x2F;&#x2F;将常数0放入局部变量表的1号槽位 i&#x3D;0 2: iconst_0 &#x2F;&#x2F;准备一个常数0 3: istore_2 &#x2F;&#x2F;将常数0放入局部变量的2号槽位 x&#x3D;0 4: iload_1 &#x2F;&#x2F;将局部变量表1号槽位的数放入操作数栈中 5: bipush 10 &#x2F;&#x2F;将数字10放入操作数栈中，此时操作数栈中有2个数 7: if_icmpge 21 &#x2F;&#x2F;比较操作数栈中的两个数，如果下面的数大于上面的数，就跳转到21。这里的比较是将两个数做减法。因为涉及运算操作，所以会将两个数弹出操作数栈来进行运算。运算结束后操作数栈为空 10: iload_2 &#x2F;&#x2F;将局部变量2号槽位的数放入操作数栈中，放入的值是0 11: iinc 2, 1 &#x2F;&#x2F;将局部变量2号槽位的数加1，自增后，槽位中的值为1 14: istore_2 &#x2F;&#x2F;将操作数栈中的数放入到局部变量表的2号槽位，2号槽位的值又变为了0 15: iinc 1, 1 &#x2F;&#x2F;1号槽位的值自增1 18: goto 4 &#x2F;&#x2F;跳转到第4条指令 21: getstatic #2 &#x2F;&#x2F; Field java&#x2F;lang&#x2F;System.out:Ljava&#x2F;io&#x2F;PrintStream; 24: iload_2 25: invokevirtual #3 &#x2F;&#x2F; Method java&#x2F;io&#x2F;PrintStream.println:(I)V 28: returnCopy 构造方法cinit()V123456789101112131415public class Demo3 &#123; static int i &#x3D; 10; static &#123; i &#x3D; 20; &#125; static &#123; i &#x3D; 30; &#125; public static void main(String[] args) &#123; System.out.println(i); &#x2F;&#x2F;结果为30 &#125;&#125;Copy 编译器会按从上至下的顺序，收集所有 static 静态代码块和静态成员赋值的代码，合并为一个特殊的方法 cinit()V ： 12345678stack&#x3D;1, locals&#x3D;0, args_size&#x3D;0 0: bipush 10 2: putstatic #3 &#x2F;&#x2F; Field i:I 5: bipush 20 7: putstatic #3 &#x2F;&#x2F; Field i:I 10: bipush 30 12: putstatic #3 &#x2F;&#x2F; Field i:I 15: returnCopy init()V123456789101112131415161718192021222324public class Demo4 &#123; private String a &#x3D; &quot;s1&quot;; &#123; b &#x3D; 20; &#125; private int b &#x3D; 10; &#123; a &#x3D; &quot;s2&quot;; &#125; public Demo4(String a, int b) &#123; this.a &#x3D; a; this.b &#x3D; b; &#125; public static void main(String[] args) &#123; Demo4 d &#x3D; new Demo4(&quot;s3&quot;, 30); System.out.println(d.a); System.out.println(d.b); &#125;&#125;Copy 编译器会按从上至下的顺序，收集所有 {} 代码块和成员变量赋值的代码，形成新的构造方法，但原始构造方法内的代码总是在后 123456789101112131415161718192021222324Code: stack&#x3D;2, locals&#x3D;3, args_size&#x3D;3 0: aload_0 1: invokespecial #1 &#x2F;&#x2F; Method java&#x2F;lang&#x2F;Object.&quot;&lt;init&gt;&quot;:()V 4: aload_0 5: ldc #2 &#x2F;&#x2F; String s1 7: putfield #3 &#x2F;&#x2F; Field a:Ljava&#x2F;lang&#x2F;String; 10: aload_0 11: bipush 20 13: putfield #4 &#x2F;&#x2F; Field b:I 16: aload_0 17: bipush 10 19: putfield #4 &#x2F;&#x2F; Field b:I 22: aload_0 23: ldc #5 &#x2F;&#x2F; String s2 25: putfield #3 &#x2F;&#x2F; Field a:Ljava&#x2F;lang&#x2F;String; &#x2F;&#x2F;原始构造方法在最后执行 28: aload_0 29: aload_1 30: putfield #3 &#x2F;&#x2F; Field a:Ljava&#x2F;lang&#x2F;String; 33: aload_0 34: iload_2 35: putfield #4 &#x2F;&#x2F; Field b:I 38: returnCopy 方法调用1234567891011121314151617181920212223242526272829public class Demo5 &#123; public Demo5() &#123; &#125; private void test1() &#123; &#125; private final void test2() &#123; &#125; public void test3() &#123; &#125; public static void test4() &#123; &#125; public static void main(String[] args) &#123; Demo5 demo5 &#x3D; new Demo5(); demo5.test1(); demo5.test2(); demo5.test3(); Demo5.test4(); &#125;&#125;Copy 不同方法在调用时，对应的虚拟机指令有所区别 私有、构造、被final修饰的方法，在调用时都使用invokespecial指令 普通成员方法在调用时，使用invokespecial指令。因为编译期间无法确定该方法的内容，只有在运行期间才能确定 静态方法在调用时使用invokestatic指令 1234567891011121314Code: stack&#x3D;2, locals&#x3D;2, args_size&#x3D;1 0: new #2 &#x2F;&#x2F; class com&#x2F;nyima&#x2F;JVM&#x2F;day5&#x2F;Demo5 3: dup 4: invokespecial #3 &#x2F;&#x2F; Method &quot;&lt;init&gt;&quot;:()V 7: astore_1 8: aload_1 9: invokespecial #4 &#x2F;&#x2F; Method test1:()V 12: aload_1 13: invokespecial #5 &#x2F;&#x2F; Method test2:()V 16: aload_1 17: invokevirtual #6 &#x2F;&#x2F; Method test3:()V 20: invokestatic #7 &#x2F;&#x2F; Method test4:()V 23: returnCopy new 是创建【对象】，给对象分配堆内存，执行成功会将【对象引用】压入操作数栈 dup 是赋值操作数栈栈顶的内容，本例即为【对象引用】，为什么需要两份引用呢，一个是要配合 invokespecial 调用该对象的构造方法 “init”:()V （会消耗掉栈顶一个引用），另一个要 配合 astore_1 赋值给局部变量 终方法（ﬁnal），私有方法（private），构造方法都是由 invokespecial 指令来调用，属于静态绑定 普通成员方法是由 invokevirtual 调用，属于动态绑定，即支持多态 成员方法与静态方法调用的另一个区别是，执行方法前是否需要【对象引用】 多态原理因为普通成员方法需要在运行时才能确定具体的内容，所以虚拟机需要调用invokevirtual指令 在执行invokevirtual指令时，经历了以下几个步骤 先通过栈帧中对象的引用找到对象 分析对象头，找到对象实际的Class Class结构中有vtable 查询vtable找到方法的具体地址 执行方法的字节码 异常处理try-catch12345678910public class Demo1 &#123; public static void main(String[] args) &#123; int i &#x3D; 0; try &#123; i &#x3D; 10; &#125;catch (Exception e) &#123; i &#x3D; 20; &#125; &#125;&#125;Copy 对应字节码指令 123456789101112131415Code: stack&#x3D;1, locals&#x3D;3, args_size&#x3D;1 0: iconst_0 1: istore_1 2: bipush 10 4: istore_1 5: goto 12 8: astore_2 9: bipush 20 11: istore_1 12: return &#x2F;&#x2F;多出来一个异常表 Exception table: from to target type 2 5 8 Class java&#x2F;lang&#x2F;ExceptionCopy 可以看到多出来一个 Exception table 的结构，[from, to) 是前闭后开（也就是检测2~4行）的检测范围，一旦这个范围内的字节码执行出现异常，则通过 type 匹配异常类型，如果一致，进入 target 所指示行号 8行的字节码指令 astore_2 是将异常对象引用存入局部变量表的2号位置（为e） 多个single-catch123456789101112public class Demo1 &#123; public static void main(String[] args) &#123; int i &#x3D; 0; try &#123; i &#x3D; 10; &#125;catch (ArithmeticException e) &#123; i &#x3D; 20; &#125;catch (Exception e) &#123; i &#x3D; 30; &#125; &#125;&#125;Copy 对应的字节码 12345678910111213141516171819Code: stack&#x3D;1, locals&#x3D;3, args_size&#x3D;1 0: iconst_0 1: istore_1 2: bipush 10 4: istore_1 5: goto 19 8: astore_2 9: bipush 20 11: istore_1 12: goto 19 15: astore_2 16: bipush 30 18: istore_1 19: return Exception table: from to target type 2 5 8 Class java&#x2F;lang&#x2F;ArithmeticException 2 5 15 Class java&#x2F;lang&#x2F;ExceptionCopy 因为异常出现时，只能进入 Exception table 中一个分支，所以局部变量表 slot 2 位置被共用 finally123456789101112public class Demo2 &#123; public static void main(String[] args) &#123; int i &#x3D; 0; try &#123; i &#x3D; 10; &#125; catch (Exception e) &#123; i &#x3D; 20; &#125; finally &#123; i &#x3D; 30; &#125; &#125;&#125;Copy 对应字节码 12345678910111213141516171819202122232425262728293031Code: stack&#x3D;1, locals&#x3D;4, args_size&#x3D;1 0: iconst_0 1: istore_1 &#x2F;&#x2F;try块 2: bipush 10 4: istore_1 &#x2F;&#x2F;try块执行完后，会执行finally 5: bipush 30 7: istore_1 8: goto 27 &#x2F;&#x2F;catch块 11: astore_2 &#x2F;&#x2F;异常信息放入局部变量表的2号槽位 12: bipush 20 14: istore_1 &#x2F;&#x2F;catch块执行完后，会执行finally 15: bipush 30 17: istore_1 18: goto 27 &#x2F;&#x2F;出现异常，但未被Exception捕获，会抛出其他异常，这时也需要执行finally块中的代码 21: astore_3 22: bipush 30 24: istore_1 25: aload_3 26: athrow &#x2F;&#x2F;抛出异常 27: return Exception table: from to target type 2 5 11 Class java&#x2F;lang&#x2F;Exception 2 5 21 any 11 15 21 anyCopy 可以看到 ﬁnally 中的代码被复制了 3 份，分别放入 try 流程，catch 流程以及 catch剩余的异常类型流程 注意：虽然从字节码指令看来，每个块中都有finally块，但是finally块中的代码只会被执行一次 finally中的return123456789101112131415161718public class Demo3 &#123; public static void main(String[] args) &#123; int i &#x3D; Demo3.test(); &#x2F;&#x2F;结果为20 System.out.println(i); &#125; public static int test() &#123; int i; try &#123; i &#x3D; 10; return i; &#125; finally &#123; i &#x3D; 20; return i; &#125; &#125;&#125;Copy 对应字节码 12345678910111213141516171819Code: stack&#x3D;1, locals&#x3D;3, args_size&#x3D;0 0: bipush 10 2: istore_0 3: iload_0 4: istore_1 &#x2F;&#x2F;暂存返回值 5: bipush 20 7: istore_0 8: iload_0 9: ireturn &#x2F;&#x2F;ireturn会返回操作数栈顶的整型值20 &#x2F;&#x2F;如果出现异常，还是会执行finally块中的内容，没有抛出异常 10: astore_2 11: bipush 20 13: istore_0 14: iload_0 15: ireturn &#x2F;&#x2F;这里没有athrow了，也就是如果在finally块中如果有返回操作的话，且try块中出现异常，会吞掉异常！ Exception table: from to target type 0 5 10 anyCopy 由于 ﬁnally 中的 ireturn 被插入了所有可能的流程，因此返回结果肯定以ﬁnally的为准 至于字节码中第 2 行，似乎没啥用，且留个伏笔，看下个例子 跟上例中的 ﬁnally 相比，发现没有 athrow 了，这告诉我们：如果在 ﬁnally 中出现了 return，会吞掉异常 所以不要在finally中进行返回操作 被吞掉的异常1234567891011121314151617181920public class Demo3 &#123; public static void main(String[] args) &#123; int i &#x3D; Demo3.test(); &#x2F;&#x2F;最终结果为20 System.out.println(i); &#125; public static int test() &#123; int i; try &#123; i &#x3D; 10; &#x2F;&#x2F;这里应该会抛出异常 i &#x3D; i&#x2F;0; return i; &#125; finally &#123; i &#x3D; 20; return i; &#125; &#125;&#125;Copy 会发现打印结果为20，并未抛出异常 finally不带return123456789101112131415public class Demo4 &#123; public static void main(String[] args) &#123; int i &#x3D; Demo4.test(); System.out.println(i); &#125; public static int test() &#123; int i &#x3D; 10; try &#123; return i; &#125; finally &#123; i &#x3D; 20; &#125; &#125;&#125;Copy 对应字节码 123456789101112131415161718Code: stack&#x3D;1, locals&#x3D;3, args_size&#x3D;0 0: bipush 10 2: istore_0 &#x2F;&#x2F;赋值给i 10 3: iload_0 &#x2F;&#x2F;加载到操作数栈顶 4: istore_1 &#x2F;&#x2F;加载到局部变量表的1号位置 5: bipush 20 7: istore_0 &#x2F;&#x2F;赋值给i 20 8: iload_1 &#x2F;&#x2F;加载局部变量表1号位置的数10到操作数栈 9: ireturn &#x2F;&#x2F;返回操作数栈顶元素 10 10: astore_2 11: bipush 20 13: istore_0 14: aload_2 &#x2F;&#x2F;加载异常 15: athrow &#x2F;&#x2F;抛出异常 Exception table: from to target type 3 5 10 anyCopy Synchronized1234567891011public class Demo5 &#123; public static void main(String[] args) &#123; int i &#x3D; 10; Lock lock &#x3D; new Lock(); synchronized (lock) &#123; System.out.println(i); &#125; &#125;&#125;class Lock&#123;&#125;Copy 对应字节码 1234567891011121314151617181920212223242526272829303132Code: stack&#x3D;2, locals&#x3D;5, args_size&#x3D;1 0: bipush 10 2: istore_1 3: new #2 &#x2F;&#x2F; class com&#x2F;nyima&#x2F;JVM&#x2F;day06&#x2F;Lock 6: dup &#x2F;&#x2F;复制一份，放到操作数栈顶，用于构造函数消耗 7: invokespecial #3 &#x2F;&#x2F; Method com&#x2F;nyima&#x2F;JVM&#x2F;day06&#x2F;Lock.&quot;&lt;init&gt;&quot;:()V 10: astore_2 &#x2F;&#x2F;剩下的一份放到局部变量表的2号位置 11: aload_2 &#x2F;&#x2F;加载到操作数栈 12: dup &#x2F;&#x2F;复制一份，放到操作数栈，用于加锁时消耗 13: astore_3 &#x2F;&#x2F;将操作数栈顶元素弹出，暂存到局部变量表的三号槽位。这时操作数栈中有一份对象的引用 14: monitorenter &#x2F;&#x2F;加锁 &#x2F;&#x2F;锁住后代码块中的操作 15: getstatic #4 &#x2F;&#x2F; Field java&#x2F;lang&#x2F;System.out:Ljava&#x2F;io&#x2F;PrintStream; 18: iload_1 19: invokevirtual #5 &#x2F;&#x2F; Method java&#x2F;io&#x2F;PrintStream.println:(I)V &#x2F;&#x2F;加载局部变量表中三号槽位对象的引用，用于解锁 22: aload_3 23: monitorexit &#x2F;&#x2F;解锁 24: goto 34 &#x2F;&#x2F;异常操作 27: astore 4 29: aload_3 30: monitorexit &#x2F;&#x2F;解锁 31: aload 4 33: athrow 34: return &#x2F;&#x2F;可以看出，无论何时出现异常，都会跳转到27行，将异常放入局部变量中，并进行解锁操作，然后加载异常并抛出异常。 Exception table: from to target type 15 24 27 any 27 31 27 anyCopy 3、编译期处理所谓的 语法糖 ，其实就是指 java 编译器把 .java 源码编译为 \\.class 字节码的过程中，自动生成和转换的一些代码，主要是为了减轻程序员的负担，算是 java 编译器给我们的一个额外福利 注意，以下代码的分析，借助了 javap 工具，idea 的反编译功能，idea 插件 jclasslib 等工具。另外， 编译器转换的结果直接就是 class 字节码，只是为了便于阅读，给出了 几乎等价 的 java 源码方式，并不是编译器还会转换出中间的 java 源码，切记。 默认构造函数123public class Candy1 &#123;&#125;Copy 经过编译期优化后 1234567public class Candy1 &#123; &#x2F;&#x2F;这个无参构造器是java编译器帮我们加上的 public Candy1() &#123; &#x2F;&#x2F;即调用父类 Object 的无参构造方法，即调用 java&#x2F;lang&#x2F;Object.&quot; &lt;init&gt;&quot;:()V super(); &#125;&#125;Copy 自动拆装箱基本类型和其包装类型的相互转换过程，称为拆装箱 在JDK 5以后，它们的转换可以在编译期自动完成 123456public class Demo2 &#123; public static void main(String[] args) &#123; Integer x &#x3D; 1; int y &#x3D; x; &#125;&#125;Copy 转换过程如下 12345678public class Demo2 &#123; public static void main(String[] args) &#123; &#x2F;&#x2F;基本类型赋值给包装类型，称为装箱 Integer x &#x3D; Integer.valueOf(1); &#x2F;&#x2F;包装类型赋值给基本类型，称谓拆箱 int y &#x3D; x.intValue(); &#125;&#125;Copy 泛型集合取值泛型也是在 JDK 5 开始加入的特性，但 java 在编译泛型代码后会执行 泛型擦除 的动作，即泛型信息在编译为字节码之后就丢失了，实际的类型都当做了 Object 类型来处理： 1234567public class Demo3 &#123; public static void main(String[] args) &#123; List&lt;Integer&gt; list &#x3D; new ArrayList&lt;&gt;(); list.add(10); Integer x &#x3D; list.get(0); &#125;&#125;Copy 对应字节码 123456789101112131415161718192021Code: stack&#x3D;2, locals&#x3D;3, args_size&#x3D;1 0: new #2 &#x2F;&#x2F; class java&#x2F;util&#x2F;ArrayList 3: dup 4: invokespecial #3 &#x2F;&#x2F; Method java&#x2F;util&#x2F;ArrayList.&quot;&lt;init&gt;&quot;:()V 7: astore_1 8: aload_1 9: bipush 10 11: invokestatic #4 &#x2F;&#x2F; Method java&#x2F;lang&#x2F;Integer.valueOf:(I)Ljava&#x2F;lang&#x2F;Integer; &#x2F;&#x2F;这里进行了泛型擦除，实际调用的是add(Objcet o) 14: invokeinterface #5, 2 &#x2F;&#x2F; InterfaceMethod java&#x2F;util&#x2F;List.add:(Ljava&#x2F;lang&#x2F;Object;)Z 19: pop 20: aload_1 21: iconst_0 &#x2F;&#x2F;这里也进行了泛型擦除，实际调用的是get(Object o) 22: invokeinterface #6, 2 &#x2F;&#x2F; InterfaceMethod java&#x2F;util&#x2F;List.get:(I)Ljava&#x2F;lang&#x2F;Object;&#x2F;&#x2F;这里进行了类型转换，将Object转换成了Integer 27: checkcast #7 &#x2F;&#x2F; class java&#x2F;lang&#x2F;Integer 30: astore_2 31: returnCopy 所以调用get函数取值时，有一个类型转换的操作 1Integer x &#x3D; (Integer) list.get(0);Copy 如果要将返回结果赋值给一个int类型的变量，则还有自动拆箱的操作 1int x &#x3D; (Integer) list.get(0).intValue();Copy 可变参数1234567891011public class Demo4 &#123; public static void foo(String... args) &#123; &#x2F;&#x2F;将args赋值给arr，可以看出String...实际就是String[] String[] arr &#x3D; args; System.out.println(arr.length); &#125; public static void main(String[] args) &#123; foo(&quot;hello&quot;, &quot;world&quot;); &#125;&#125;Copy 可变参数 String… args 其实是一个 String[] args ，从代码中的赋值语句中就可以看出来。 同 样 java 编译器会在编译期间将上述代码变换为： 12345678910111213public class Demo4 &#123; public Demo4 &#123;&#125; public static void foo(String[] args) &#123; String[] arr &#x3D; args; System.out.println(arr.length); &#125; public static void main(String[] args) &#123; foo(new String[]&#123;&quot;hello&quot;, &quot;world&quot;&#125;); &#125;&#125;Copy 注意，如果调用的是foo()，即未传递参数时，等价代码为foo(new String[]{})，创建了一个空数组，而不是直接传递的null foreach123456789public class Demo5 &#123; public static void main(String[] args) &#123; &#x2F;&#x2F;数组赋初值的简化写法也是一种语法糖。 int[] arr &#x3D; &#123;1, 2, 3, 4, 5&#125;; for(int x : arr) &#123; System.out.println(x); &#125; &#125;&#125;Copy 编译器会帮我们转换为 1234567891011public class Demo5 &#123; public Demo5 &#123;&#125; public static void main(String[] args) &#123; int[] arr &#x3D; new int[]&#123;1, 2, 3, 4, 5&#125;; for(int i&#x3D;0; i&lt;arr.length; ++i) &#123; int x &#x3D; arr[i]; System.out.println(x); &#125; &#125;&#125;Copy 如果是集合使用foreach 12345678public class Demo5 &#123; public static void main(String[] args) &#123; List&lt;Integer&gt; list &#x3D; Arrays.asList(1, 2, 3, 4, 5); for (Integer x : list) &#123; System.out.println(x); &#125; &#125;&#125;Copy 集合要使用foreach，需要该集合类实现了Iterable接口，因为集合的遍历需要用到迭代器Iterator 12345678910111213public class Demo5 &#123; public Demo5 &#123;&#125; public static void main(String[] args) &#123; List&lt;Integer&gt; list &#x3D; Arrays.asList(1, 2, 3, 4, 5); &#x2F;&#x2F;获得该集合的迭代器 Iterator&lt;Integer&gt; iterator &#x3D; list.iterator(); while(iterator.hasNext()) &#123; Integer x &#x3D; iterator.next(); System.out.println(x); &#125; &#125;&#125;Copy switch字符串123456789101112131415public class Demo6 &#123; public static void main(String[] args) &#123; String str &#x3D; &quot;hello&quot;; switch (str) &#123; case &quot;hello&quot; : System.out.println(&quot;h&quot;); break; case &quot;world&quot; : System.out.println(&quot;w&quot;); break; default: break; &#125; &#125;&#125;Copy 在编译器中执行的操作 123456789101112131415161718192021222324252627282930313233343536373839public class Demo6 &#123; public Demo6() &#123; &#125; public static void main(String[] args) &#123; String str &#x3D; &quot;hello&quot;; int x &#x3D; -1; &#x2F;&#x2F;通过字符串的hashCode+value来判断是否匹配 switch (str.hashCode()) &#123; &#x2F;&#x2F;hello的hashCode case 99162322 : &#x2F;&#x2F;再次比较，因为字符串的hashCode有可能相等 if(str.equals(&quot;hello&quot;)) &#123; x &#x3D; 0; &#125; break; &#x2F;&#x2F;world的hashCode case 11331880 : if(str.equals(&quot;world&quot;)) &#123; x &#x3D; 1; &#125; break; default: break; &#125; &#x2F;&#x2F;用第二个switch在进行输出判断 switch (x) &#123; case 0: System.out.println(&quot;h&quot;); break; case 1: System.out.println(&quot;w&quot;); break; default: break; &#125; &#125;&#125;Copy 过程说明： 在编译期间，单个的switch被分为了两个 第一个用来匹配字符串，并给x赋值 字符串的匹配用到了字符串的hashCode，还用到了equals方法 使用hashCode是为了提高比较效率，使用equals是防止有hashCode冲突（如BM和C.） 第二个用来根据x的值来决定输出语句 switch枚举12345678910111213141516171819public class Demo7 &#123; public static void main(String[] args) &#123; SEX sex &#x3D; SEX.MALE; switch (sex) &#123; case MALE: System.out.println(&quot;man&quot;); break; case FEMALE: System.out.println(&quot;woman&quot;); break; default: break; &#125; &#125;&#125;enum SEX &#123; MALE, FEMALE;&#125;Copy 编译器中执行的代码如下 12345678910111213141516171819202122232425262728293031323334353637public class Demo7 &#123; &#x2F;** * 定义一个合成类（仅 jvm 使用，对我们不可见） * 用来映射枚举的 ordinal 与数组元素的关系 * 枚举的 ordinal 表示枚举对象的序号，从 0 开始 * 即 MALE 的 ordinal()&#x3D;0，FEMALE 的 ordinal()&#x3D;1 *&#x2F; static class $MAP &#123; &#x2F;&#x2F;数组大小即为枚举元素个数，里面存放了case用于比较的数字 static int[] map &#x3D; new int[2]; static &#123; &#x2F;&#x2F;ordinal即枚举元素对应所在的位置，MALE为0，FEMALE为1 map[SEX.MALE.ordinal()] &#x3D; 1; map[SEX.FEMALE.ordinal()] &#x3D; 2; &#125; &#125; public static void main(String[] args) &#123; SEX sex &#x3D; SEX.MALE; &#x2F;&#x2F;将对应位置枚举元素的值赋给x，用于case操作 int x &#x3D; $MAP.map[sex.ordinal()]; switch (x) &#123; case 1: System.out.println(&quot;man&quot;); break; case 2: System.out.println(&quot;woman&quot;); break; default: break; &#125; &#125;&#125;enum SEX &#123; MALE, FEMALE;&#125;Copy 枚举类123enum SEX &#123; MALE, FEMALE;&#125;Copy 转换后的代码 1234567891011121314151617181920212223242526public final class Sex extends Enum&lt;Sex&gt; &#123; &#x2F;&#x2F;对应枚举类中的元素 public static final Sex MALE; public static final Sex FEMALE; private static final Sex[] $VALUES; static &#123; &#x2F;&#x2F;调用构造函数，传入枚举元素的值及ordinal MALE &#x3D; new Sex(&quot;MALE&quot;, 0); FEMALE &#x3D; new Sex(&quot;FEMALE&quot;, 1); $VALUES &#x3D; new Sex[]&#123;MALE, FEMALE&#125;; &#125; &#x2F;&#x2F;调用父类中的方法 private Sex(String name, int ordinal) &#123; super(name, ordinal); &#125; public static Sex[] values() &#123; return $VALUES.clone(); &#125; public static Sex valueOf(String name) &#123; return Enum.valueOf(Sex.class, name); &#125; &#125;Copy 匿名内部类12345678910public class Demo8 &#123; public static void main(String[] args) &#123; Runnable runnable &#x3D; new Runnable() &#123; @Override public void run() &#123; System.out.println(&quot;running...&quot;); &#125; &#125;; &#125;&#125;Copy 转换后的代码 12345678910111213141516public class Demo8 &#123; public static void main(String[] args) &#123; &#x2F;&#x2F;用额外创建的类来创建匿名内部类对象 Runnable runnable &#x3D; new Demo8$1(); &#125;&#125;&#x2F;&#x2F;创建了一个额外的类，实现了Runnable接口final class Demo8$1 implements Runnable &#123; public Demo8$1() &#123;&#125; @Override public void run() &#123; System.out.println(&quot;running...&quot;); &#125;&#125;Copy 如果匿名内部类中引用了局部变量 1234567891011public class Demo8 &#123; public static void main(String[] args) &#123; int x &#x3D; 1; Runnable runnable &#x3D; new Runnable() &#123; @Override public void run() &#123; System.out.println(x); &#125; &#125;; &#125;&#125;Copy 转化后代码 12345678910111213141516171819202122232425public class Demo8 &#123; public static void main(String[] args) &#123; int x &#x3D; 1; Runnable runnable &#x3D; new Runnable() &#123; @Override public void run() &#123; System.out.println(x); &#125; &#125;; &#125;&#125;final class Demo8$1 implements Runnable &#123; &#x2F;&#x2F;多创建了一个变量 int val$x; &#x2F;&#x2F;变为了有参构造器 public Demo8$1(int x) &#123; this.val$x &#x3D; x; &#125; @Override public void run() &#123; System.out.println(val$x); &#125;&#125;Copy 4、类加载阶段加载 将类的字节码载入 方法区 （1.8后为元空间，在本地内存中）中，内部采用 C++ 的 instanceKlass 描述 java 类，它的重要 ﬁeld 有： _java_mirror 即 java 的类镜像，例如对 String 来说，它的镜像类就是 String.class，作用是把 klass 暴露给 java 使用 _super 即父类 _ﬁelds 即成员变量 _methods 即方法 _constants 即常量池 _class_loader 即类加载器 _vtable 虚方法表 _itable 接口方法 如果这个类还有父类没有加载，先加载父类 加载和链接可能是交替运行的 instanceKlass保存在方法区。JDK 8以后，方法区位于元空间中，而元空间又位于本地内存中 _java_mirror则是保存在堆内存中 InstanceKlass和*.class(JAVA镜像类)互相保存了对方的地址 类的对象在对象头中保存了*.class的地址。让对象可以通过其找到方法区中的instanceKlass，从而获取类的各种信息 链接验证验证类是否符合 JVM规范，安全性检查 准备为 static 变量分配空间，设置默认值 static变量在JDK 7以前是存储与instanceKlass末尾。但在JDK 7以后就存储在_java_mirror末尾了 static变量在分配空间和赋值是在两个阶段完成的。分配空间在准备阶段完成，赋值在初始化阶段完成 如果 static 变量是 ﬁnal 的基本类型，以及字符串常量，那么编译阶段值就确定了，赋值在准备阶段完成 如果 static 变量是 ﬁnal 的，但属于引用类型，那么赋值也会在初始化阶段完成 解析HSDB的使用 先获得要查看的进程ID 1jpsCopy 打开HSDB 1java -cp F:\\JAVA\\JDK8.0\\lib\\sa-jdi.jar sun.jvm.hotspot.HSDBCopy 运行时可能会报错，是因为缺少一个.dll的文件，我们在JDK的安装目录中找到该文件，复制到缺失的文件下即可 定位需要的进程 解析的含义 将常量池中的符号引用解析为直接引用 未解析时，常量池中的看到的对象仅是符号，未真正的存在于内存中 1234567891011121314151617public class Demo1 &#123; public static void main(String[] args) throws IOException, ClassNotFoundException &#123; ClassLoader loader &#x3D; Demo1.class.getClassLoader(); &#x2F;&#x2F;只加载不解析 Class&lt;?&gt; c &#x3D; loader.loadClass(&quot;com.nyima.JVM.day8.C&quot;); &#x2F;&#x2F;用于阻塞主线程 System.in.read(); &#125;&#125;class C &#123; D d &#x3D; new D();&#125;class D &#123;&#125;Copy 打开HSDB 可以看到此时只加载了类C 查看类C的常量池，可以看到类D未被解析，只是存在于常量池中的符号 解析以后，会将常量池中的符号引用解析为直接引用 可以看到，此时已加载并解析了类C和类D 初始化初始化阶段就是执行类构造器clinit()方法的过程，虚拟机会保证这个类的『构造方法』的线程安全 clinit()方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块（static{}块）中的语句合并产生的 注意 编译器收集的顺序是由语句在源文件中出现的顺序决定的，静态语句块中只能访问到定义在静态语句块之前的变量，定义在它之后的变量，在前面的静态语句块可以赋值，但是不能访问，如 发生时机类的初始化的懒惰的，以下情况会初始化 main 方法所在的类，总会被首先初始化 首次访问这个类的静态变量或静态方法时 子类初始化，如果父类还没初始化，会引发 子类访问父类的静态变量，只会触发父类的初始化 Class.forName new 会导致初始化 以下情况不会初始化 访问类的 static ﬁnal 静态常量（基本类型和字符串） 类对象.class 不会触发初始化 创建该类对象的数组 类加载器的.loadClass方法 Class.forNamed的参数2为false时 验证类是否被初始化，可以看改类的静态代码块是否被执行 5、类加载器Java虚拟机设计团队有意把类加载阶段中的“通过一个类的全限定名来获取描述该类的二进制字节流”这个动作放到Java虚拟机外部去实现，以便让应用程序自己决定如何去获取所需的类。实现这个动作的代码被称为“类加载器”（ClassLoader） 类与类加载器类加载器虽然只用于实现类的加载动作，但它在Java程序中起到的作用却远超类加载阶段 对于任意一个类，都必须由加载它的类加载器和这个类本身一起共同确立其在Java虚拟机中的唯一性，每一个类加载器，都拥有一个独立的类名称空间。这句话可以表达得更通俗一些：比较两个类是否“相等”，只有在这两个类是由同一个类加载器加载的前提下才有意义，否则，即使这两个类来源于同一个Class文件，被同一个Java虚拟机加载，只要加载它们的类加载器不同，那这两个类就必定不相等 以JDK 8为例 名称 加载的类 说明 Bootstrap ClassLoader（启动类加载器） JAVA_HOME/jre/lib 无法直接访问 Extension ClassLoader(拓展类加载器) JAVA_HOME/jre/lib/ext 上级为Bootstrap，显示为null Application ClassLoader(应用程序类加载器) classpath 上级为Extension 自定义类加载器 自定义 上级为Application 启动类加载器可通过在控制台输入指令，使得类被启动类加器加载 拓展类加载器如果classpath和JAVA_HOME/jre/lib/ext 下有同名类，加载时会使用拓展类加载器加载。当应用程序类加载器发现拓展类加载器已将该同名类加载过了，则不会再次加载 双亲委派模式双亲委派模式，即调用类加载器ClassLoader 的 loadClass 方法时，查找类的规则 loadClass源码 1234567891011121314151617181920212223242526272829303132333435363738394041protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException&#123; synchronized (getClassLoadingLock(name)) &#123; &#x2F;&#x2F; 首先查找该类是否已经被该类加载器加载过了 Class&lt;?&gt; c &#x3D; findLoadedClass(name); &#x2F;&#x2F;如果没有被加载过 if (c &#x3D;&#x3D; null) &#123; long t0 &#x3D; System.nanoTime(); try &#123; &#x2F;&#x2F;看是否被它的上级加载器加载过了 Extension的上级是Bootstarp，但它显示为null if (parent !&#x3D; null) &#123; c &#x3D; parent.loadClass(name, false); &#125; else &#123; &#x2F;&#x2F;看是否被启动类加载器加载过 c &#x3D; findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; &#x2F;&#x2F; ClassNotFoundException thrown if class not found &#x2F;&#x2F; from the non-null parent class loader &#x2F;&#x2F;捕获异常，但不做任何处理 &#125; if (c &#x3D;&#x3D; null) &#123; &#x2F;&#x2F;如果还是没有找到，先让拓展类加载器调用findClass方法去找到该类，如果还是没找到，就抛出异常 &#x2F;&#x2F;然后让应用类加载器去找classpath下找该类 long t1 &#x3D; System.nanoTime(); c &#x3D; findClass(name); &#x2F;&#x2F; 记录时间 sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125;&#125;Copy 自定义类加载器使用场景 想加载非 classpath 随意路径中的类文件 通过接口来使用实现，希望解耦时，常用在框架设计 这些类希望予以隔离，不同应用的同名类都可以加载，不冲突，常见于 tomcat 容器 步骤 继承ClassLoader父类 要遵从双亲委派机制，重写 ﬁndClass 方法 不是重写loadClass方法，否则不会走双亲委派机制 读取类文件的字节码 调用父类的 deﬁneClass 方法来加载类 使用者调用该类加载器的 loadClass 方法 破坏双亲委派模式 双亲委派模型的第一次“被破坏”其实发生在双亲委派模型出现之前——即JDK1.2面世以前的“远古”时代 建议用户重写findClass()方法，在类加载器中的loadClass()方法中也会调用该方法 双亲委派模型的第二次“被破坏”是由这个模型自身的缺陷导致的 如果有基础类型又要调用回用户的代码，此时也会破坏双亲委派模式 双亲委派模型的第三次“被破坏”是由于用户对程序动态性的追求而导致的 这里所说的“动态性”指的是一些非常“热”门的名词：代码热替换（Hot Swap）、模块热部署（Hot Deployment）等 6、运行期优化分层编译JVM 将执行状态分成了 5 个层次： 0层：解释执行，用解释器将字节码翻译为机器码 1层：使用 C1 即时编译器编译执行（不带 proﬁling） 2层：使用 C1 即时编译器编译执行（带基本的profiling） 3层：使用 C1 即时编译器编译执行（带完全的profiling） 4层：使用 C2 即时编译器编译执行 proﬁling 是指在运行过程中收集一些程序执行状态的数据，例如【方法的调用次数】，【循环的 回边次数】等 即时编译器（JIT）与解释器的区别 解释器 将字节码解释为机器码，下次即使遇到相同的字节码，仍会执行重复的解释 是将字节码解释为针对所有平台都通用的机器码 即时编译器 将一些字节码编译为机器码，并存入 Code Cache，下次遇到相同的代码，直接执行，无需再编译 根据平台类型，生成平台特定的机器码 对于大部分的不常用的代码，我们无需耗费时间将其编译成机器码，而是采取解释执行的方式运行；另一方面，对于仅占据小部分的热点代码，我们则可以将其编译成机器码，以达到理想的运行速度。 执行效率上简单比较一下 Interpreter &lt; C1 &lt; C2，总的目标是发现热点代码（hotspot名称的由 来），并优化这些热点代码 逃逸分析逃逸分析（Escape Analysis）简单来讲就是，Java Hotspot 虚拟机可以分析新创建对象的使用范围，并决定是否在 Java 堆上分配内存的一项技术 逃逸分析的 JVM 参数如下： 开启逃逸分析：-XX:+DoEscapeAnalysis 关闭逃逸分析：-XX:-DoEscapeAnalysis 显示分析结果：-XX:+PrintEscapeAnalysis 逃逸分析技术在 Java SE 6u23+ 开始支持，并默认设置为启用状态，可以不用额外加这个参数 对象逃逸状态 全局逃逸（GlobalEscape） 即一个对象的作用范围逃出了当前方法或者当前线程，有以下几种场景： 对象是一个静态变量 对象是一个已经发生逃逸的对象 对象作为当前方法的返回值 参数逃逸（ArgEscape） 即一个对象被作为方法参数传递或者被参数引用，但在调用过程中不会发生全局逃逸，这个状态是通过被调方法的字节码确定的 没有逃逸 即方法中的对象没有发生逃逸 逃逸分析优化 针对上面第三点，当一个对象没有逃逸时，可以得到以下几个虚拟机的优化 锁消除 我们知道线程同步锁是非常牺牲性能的，当编译器确定当前对象只有当前线程使用，那么就会移除该对象的同步锁 例如，StringBuffer 和 Vector 都是用 synchronized 修饰线程安全的，但大部分情况下，它们都只是在当前线程中用到，这样编译器就会优化移除掉这些锁操作 锁消除的 JVM 参数如下： 开启锁消除：-XX:+EliminateLocks 关闭锁消除：-XX:-EliminateLocks 锁消除在 JDK8 中都是默认开启的，并且锁消除都要建立在逃逸分析的基础上 标量替换 首先要明白标量和聚合量，基础类型和对象的引用可以理解为标量，它们不能被进一步分解。而能被进一步分解的量就是聚合量，比如：对象 对象是聚合量，它又可以被进一步分解成标量，将其成员变量分解为分散的变量，这就叫做标量替换。 这样，如果一个对象没有发生逃逸，那压根就不用创建它，只会在栈或者寄存器上创建它用到的成员标量，节省了内存空间，也提升了应用程序性能 标量替换的 JVM 参数如下： 开启标量替换：-XX:+EliminateAllocations 关闭标量替换：-XX:-EliminateAllocations 显示标量替换详情：-XX:+PrintEliminateAllocations 标量替换同样在 JDK8 中都是默认开启的，并且都要建立在逃逸分析的基础上 栈上分配 当对象没有发生逃逸时，该对象就可以通过标量替换分解成成员标量分配在栈内存中，和方法的生命周期一致，随着栈帧出栈时销毁，减少了 GC 压力，提高了应用程序性能 方法内联内联函数内联函数就是在程序编译时，编译器将程序中出现的内联函数的调用表达式用内联函数的函数体来直接进行替换 JVM内联函数C++是否为内联函数由自己决定，Java由编译器决定。Java不支持直接声明为内联函数的，如果想让他内联，你只能够向编译器提出请求: 关键字final修饰 用来指明那个函数是希望被JVM内联的，如 123public final void doSomething() &#123; &#x2F;&#x2F; to do something &#125;Copy 总的来说，一般的函数都不会被当做内联函数，只有声明了final后，编译器才会考虑是不是要把你的函数变成内联函数 JVM内建有许多运行时优化。首先短方法更利于JVM推断。流程更明显，作用域更短，副作用也更明显。如果是长方法JVM可能直接就跪了。 第二个原因则更重要：方法内联 如果JVM监测到一些小方法被频繁的执行，它会把方法的调用替换成方法体本身，如： 12345678private int add4(int x1, int x2, int x3, int x4) &#123; &#x2F;&#x2F;这里调用了add2方法 return add2(x1, x2) + add2(x3, x4); &#125; private int add2(int x1, int x2) &#123; return x1 + x2; &#125;Copy 方法调用被替换后 1234private int add4(int x1, int x2, int x3, int x4) &#123; &#x2F;&#x2F;被替换为了方法本身 return x1 + x2 + x3 + x4; &#125;Copy 反射优化123456789101112public class Reflect1 &#123; public static void foo() &#123; System.out.println(&quot;foo...&quot;); &#125; public static void main(String[] args) throws NoSuchMethodException, InvocationTargetException, IllegalAccessException &#123; Method foo &#x3D; Demo3.class.getMethod(&quot;foo&quot;); for(int i &#x3D; 0; i&lt;&#x3D;16; i++) &#123; foo.invoke(null); &#125; &#125;&#125;Copy foo.invoke 前面 0 ~ 15 次调用使用的是 MethodAccessor 的 NativeMethodAccessorImpl 实现 invoke方法源码 123456789101112131415161718@CallerSensitivepublic Object invoke(Object obj, Object... args) throws IllegalAccessException, IllegalArgumentException, InvocationTargetException&#123; if (!override) &#123; if (!Reflection.quickCheckMemberAccess(clazz, modifiers)) &#123; Class&lt;?&gt; caller &#x3D; Reflection.getCallerClass(); checkAccess(caller, clazz, obj, modifiers); &#125; &#125; &#x2F;&#x2F;MethodAccessor是一个接口，有3个实现类，其中有一个是抽象类 MethodAccessor ma &#x3D; methodAccessor; &#x2F;&#x2F; read volatile if (ma &#x3D;&#x3D; null) &#123; ma &#x3D; acquireMethodAccessor(); &#125; return ma.invoke(obj, args);&#125;Copy 会由DelegatingMehodAccessorImpl去调用NativeMethodAccessorImpl NativeMethodAccessorImpl源码 12345678910111213141516171819202122232425262728class NativeMethodAccessorImpl extends MethodAccessorImpl &#123; private final Method method; private DelegatingMethodAccessorImpl parent; private int numInvocations; NativeMethodAccessorImpl(Method var1) &#123; this.method &#x3D; var1; &#125; &#x2F;&#x2F;每次进行反射调用，会让numInvocation与ReflectionFactory.inflationThreshold的值（15）进行比较，并使使得numInvocation的值加一 &#x2F;&#x2F;如果numInvocation&gt;ReflectionFactory.inflationThreshold，则会调用本地方法invoke0方法 public Object invoke(Object var1, Object[] var2) throws IllegalArgumentException, InvocationTargetException &#123; if (++this.numInvocations &gt; ReflectionFactory.inflationThreshold() &amp;&amp; !ReflectUtil.isVMAnonymousClass(this.method.getDeclaringClass())) &#123; MethodAccessorImpl var3 &#x3D; (MethodAccessorImpl)(new MethodAccessorGenerator()).generateMethod(this.method.getDeclaringClass(), this.method.getName(), this.method.getParameterTypes(), this.method.getReturnType(), this.method.getExceptionTypes(), this.method.getModifiers()); this.parent.setDelegate(var3); &#125; return invoke0(this.method, var1, var2); &#125; void setParent(DelegatingMethodAccessorImpl var1) &#123; this.parent &#x3D; var1; &#125; private static native Object invoke0(Method var0, Object var1, Object[] var2);&#125;Copy&#x2F;&#x2F;ReflectionFactory.inflationThreshold()方法的返回值private static int inflationThreshold &#x3D; 15;Copy 一开始if条件不满足，就会调用本地方法invoke0 随着numInvocation的增大，当它大于ReflectionFactory.inflationThreshold的值16时，就会本地方法访问器替换为一个运行时动态生成的访问器，来提高效率 这时会从反射调用变为正常调用，即直接调用 Reflect1.foo() 因为static块和static变量的初始化会在cinit方法中整合，而类的初始化就是执行cinity方法的过程 从下往上是为了避免重复加载（JVM 区分不同类的方式不仅仅根据类名，相同的类文件被不同的类加载器加载产生的是两个不同的类）","categories":[],"tags":[]},{"title":"Docker与微服务实战2022","slug":"Docker与微服务实战2022","date":"2022-01-09T07:32:57.000Z","updated":"2022-01-09T14:17:45.178Z","comments":true,"path":"2022/01/09/Docker与微服务实战2022/","link":"","permalink":"http://www.xc234.ltd/2022/01/09/Docker%E4%B8%8E%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%AE%9E%E6%88%982022/","excerpt":"","text":"Docker与微服务实战2022基础篇1.Docker简介1.1Docker是什么1.1.1问题：为什么会有docker出现假定您在开发一个尚硅谷的谷粒商城，您使用的是一台笔记本电脑而且您的开发环境具有特定的配置。其他开发人员身处的环境配置也各有不同。您正在开发的应用依赖于您当前的配置且还要依赖于某些配置文件。此外，您的企业还拥有标准化的测试和生产环境，且具有自身的配置和一系列支持文件。您希望尽可能多在本地模拟这些环境而不产生重新创建服务器环境的开销。请问？您要如何确保应用能够在这些环境中运行和通过质量检测？并且在部署过程中不出现令人头疼的版本、配置问题，也无需重新编写代码和进行故障修复？ 答案就是使用容器。Docker之所以发展如此迅速，也是因为它对此给出了一个标准化的解决方案—–系统平滑移植，容器虚拟化技术。 环境配置相当麻烦，换一台机器，就要重来一次，费力费时。很多人想到，能不能从根本上解决问题，软件可以带环境安装？也就是说，安装的时候，把原始环境一模一样地复制过来。开发人员利用 Docker 可以消除协作编码时“在我的机器上可正常工作”的问题。 之前在服务器配置一个应用的运行环境，要安装各种软件，就拿尚硅谷电商项目的环境来说，Java/RabbitMQ/MySQL/JDBC驱动包等。安装和配置这些东西有多麻烦就不说了，它还不能跨平台。假如我们是在 Windows 上安装的这些环境，到了 Linux 又得重新装。况且就算不跨操作系统，换另一台同样操作系统的服务器，要移植应用也是非常麻烦的。传统上认为，软件编码开发/测试结束后，所产出的成果即是程序或是能够编译执行的二进制字节码等(java为例)。而为了让这些程序可以顺利执行，开发团队也得准备完整的部署文件，让维运团队得以部署应用程式，开发需要清楚的告诉运维部署团队，用的全部配置文件+所有软件环境。不过，即便如此，仍然常常发生部署失败的状况。Docker的出现使得Docker得以打破过去「程序即应用」的观念。透过镜像(images)将作业系统核心除外，运作应用程式所需要的系统环境，由下而上打包，达到应用程式跨平台间的无缝接轨运作。 1.1.2Docker理念Docker是基于Go语言实现的云开源项目。Docker的主要目标是“Build，Ship and Run Any App,Anywhere”，也就是通过对应用组件的封装、分发、部署、运行等生命周期的管理，使用户的APP（可以是一个WEB应用或数据库应用等等）及其运行环境能够做到“一次镜像，处处运行”。 Linux容器技术的出现就解决了这样一个问题，而 Docker 就是在它的基础上发展过来的。将应用打成镜像，通过镜像成为运行在Docker容器上面的实例，而 Docker容器在任何操作系统上都是一致的，这就实现了跨平台、跨服务器。只需要一次配置好环境，换到别的机子上就可以一键部署好，大大简化了操作。 1.1.3一句话解决了运行环境和配置问题的软件容器，方便做持续集成并有助于整体发布的容器虚拟化技术 1.2Docker能干嘛更快速的应用交付和部署 更便捷的升级和扩缩容 更简单的系统运维 更高效的计算资源利用 1.3Docker去哪下官网： docker官网：http://www.docker.com 仓库： Docker Hub官网: https://hub.docker.com/ 2.Docker安装2.1前提说明CentOS Docker 安装 前提条件目前，CentOS 仅发行版本中的内核支持 Docker。Docker 运行在CentOS 7 (64-bit)上，要求系统为64位、Linux系统内核版本为 3.8以上，这里选用Centos7.x 2.2Docker的基本组成2.2.1镜像(image)Docker 镜像（Image）就是一个只读的模板。镜像可以用来创建 Docker 容器，一个镜像可以创建很多容器。 它也相当于是一个root文件系统。比如官方镜像 centos:7 就包含了完整的一套 centos:7 最小系统的 root 文件系统。 docker镜像文件类似于Java的类模板，而docker容器实例类似于java中new出来的实例对象。 2.2.2容器(container) 1 从面向对象角度 Docker利用容器（Container）独立运行的一个或一组应用，应用程序或服务运行在容器里面，容器就类似于一个虚拟化的运行环境，容器是用镜像创建的运行实例。就像是Java中的类和实例对象一样，镜像是静态的定义，容器是镜像运行时的实体。容器为镜像提供了一个标准的和隔离的运行环境，它可以被启动、开始、停止、删除。每个容器都是相互隔离的、保证安全的平台 2 从镜像容器角度 可以把容器看做是一个简易版的 Linux 环境（包括root用户权限、进程空间、用户空间和网络空间等）和运行在其中的应用程序 2.2.3仓库(respository)仓库（Repository）是集中存放镜像文件的场所 类似于Maven仓库，存放各种jar包的地方；github仓库，存放各种git项目的地方；Docker公司提供的官方registry被称为Docker Hub，存放各种镜像模板的地方。 仓库分为公开仓库（Public）和私有仓库（Private）两种形式。最大的公开仓库是 Docker Hub，存放了数量庞大的镜像供用户下载。国内的公开仓库包括阿里云 、网易云等 2.2.4小总结需要正确的理解仓库/镜像/容器这几个概念: Docker 本身是一个容器运行载体或称之为管理引擎。我们把应用程序和配置依赖打包好形成一个可交付的运行环境，这个打包好的运行环境就是image镜像文件。只有通过这个镜像文件才能生成Docker容器实例(类似Java中new出来一个对象)。 image文件可以看作是容器的模板。Docker 根据 image 文件生成容器的实例。同一个 image 文件，可以生成多个同时运行的容器实例。 镜像文件 image 文件生成的容器实例，本身也是一个文件，称为镜像文件。 容器实例 一个容器运行一种服务，当我们需要的时候，就可以通过docker客户端创建一个对应的运行实例，也就是我们的容器 仓库 就是放一堆镜像的地方，我们可以把镜像发布到仓库中，需要的时候再从仓库中拉下来就可以了。 2.3Docker平台架构图解(入门版)​ 2.3.1Docker工作原理Docker是一个Client-Server结构的系统，Docker守护进程运行在主机上， 然后通过Socket连接从客户端访问，守护进程从客户端接受命令并管理运行在主机上的容器。 容器，是一个运行时环境，就是我们前面说到的集装箱。可以对比mysql演示对比讲解 2.4安装步骤2.4.1CentOS7安装Docker官方安装文档 CentOS7安装步骤 确定你是CentOS7及以上版本 1cat /etc/redhat-release 卸载旧版本(参照官方文档) 12345678sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine yum安装gcc相关CentOS7能上外网 12yum -y install gccyum -y install gcc-c++ 安装需要的软件包 执行命令 1yum install -y yum-utils 设置stable镜像仓库 1yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 更新yum软件包索引 1yum makecache fast 安装DOCKER CE 1yum -y install docker-ce docker-ce-cli containerd.io 启动docker 1systemctl start docker 测试 1docker version 1docker run hello-world 卸载 1yum remove docker-ce docker-ce-cli containerd.iorm -rf &#x2F;var&#x2F;lib&#x2F;dockerrm -rf &#x2F;var&#x2F;lib&#x2F;containerd 2.5国内镜像云加速修改docker镜像仓库 1vim /etc/docker/daemon.json#改为下面内容，然后重启docker&#123;&quot;debug&quot;:true,&quot;experimental&quot;:true,&quot;registry-mirrors&quot;:[&quot;https://pb5bklzr.mirror.aliyuncs.com&quot;,&quot;https://hub-mirror.c.163.com&quot;,&quot;https://docker.mirrors.ustc.edu.cn&quot;]&#125;#大括号不用复制#查看信息docker info 然后重新启动docker(systemctl restart docker)，查看信息(docker info) 2.6底层原理为什么Docker会比VM虚拟机快 docker有着比虚拟机更少的抽象层由于docker不需要Hypervisor(虚拟机)实现硬件资源虚拟化,运行在docker容器上的程序直接使用的都是实际物理机的硬件资源。因此在CPU、内存利用率上docker将会在效率上有明显优势。 docker利用的是宿主机的内核,而不需要加载操作系统OS内核当新建一个容器时,docker不需要和虚拟机一样重新加载一个操作系统内核。进而避免引寻、加载操作系统内核返回等比较费时费资源的过程,当新建一个虚拟机时,虚拟机软件需要加载OS,返回新建过程是分钟级别的。而docker由于直接利用宿主机的操作系统,则省略了返回过程,因此新建一个docker容器只需要几秒钟 3.Docker常用命令3.1帮助启动类命令3.1.1启动docker1systemctl start docker 3.1.2停止docker1systemctl stop docker 3.1.3重启docker1systemctl restart docker 3.1.4查看docker状态1systemctl status docker 3.1.5开机启动1systemctl enable docker 3.1.6查看docker概要信息1docker info 3.1.7查看docker总体帮助文档1docker --help 3.1.8查看docker命令帮助文档1docker 具体命令 --help 3.2镜像命令3.2.1列出本地主机上的镜像1docker images 3.2.2搜索镜像1docker search 某个XXX镜像名字 3.2.3拉取镜像1docker pull 某个XXX镜像名字 3.2.4查看镜像/容器/数据卷所占的空间1docker system df 3.2.5删除镜像1docker rmi 某个XXX镜像名字/ID 删除单个 1docker rmi -f 镜像ID 删除多个 1docker rmi -f 镜像名1:TAG 镜像名2:TAG *删除全部** 1docker rmi -f $(docker images -qa) 3.2.6谈谈docker虚悬镜像是什么?仓库名、标签都是的镜像，俗称虚悬镜像dangling image 3.3容器命令3.3.1新建+启动容器1docker run [OPTIONS] IMAGE [COMMAND] [ARG...] OPTIONS说明（常用）：有些是一个减号，有些是两个减号 –name=”容器新名字” 为容器指定一个名称；-d: 后台运行容器并返回容器ID，也即启动守护式容器(后台运行)； -i：以交互模式运行容器，通常与 -t 同时使用；-t：为容器重新分配一个伪输入终端，通常与 -i 同时使用；也即启动交互式容器(前台有伪终端，等待交互)； -P: 随机端口映射，大写P-p: 指定端口映射，小写p 3.3.2列出当前所有正在运行的容器1docker ps [OPTIONS] 3.3.3退出容器两种退出方式 1exit !!!run进去容器，exit退出，容器停止 快捷键 1ctrl+p+q run进去容器，ctrl+p+q退出，容器不停止 3.3.4启动已停止运行的容器1docker start 容器ID或者容器名 3.3.5重启容器1docker restart 容器ID或者容器名 3.3.6停止容器1docker stop 容器ID或者容器名 3.3.7强制停止容器1docker kill 容器ID或容器名 3.3.8删除已停止的容器1docker rm 容器ID 一次性删除多个容器实例 123docker rm -f $(docker ps -a -q)#或者docker ps -a -q | xargs docker rm 3.4重要的容器命令有镜像才能创建容器，这是根本前提(下载一个Redis6.0.8镜像演示) 3.4.1启动守护式容器(后台服务器)在大部分的场景下，我们希望 docker 的服务是在后台运行的，我们可以过 -d 指定容器的后台运行模式。 1docker run -d 容器名 12345678910111213#使用镜像centos:latest以后台模式启动一个容器docker run -d centos 问题：然后docker ps -a 进行查看, 会发现容器已经退出很重要的要说明的一点: Docker容器后台运行,就必须有一个前台进程.容器运行的命令如果不是那些一直挂起的命令（比如运行top，tail），就是会自动退出的。 这个是docker的机制问题,比如你的web容器,我们以nginx为例，正常情况下,我们配置启动服务只需要启动响应的service即可。例如service nginx start但是,这样做,nginx为后台进程模式运行,就导致docker前台没有运行的应用,这样的容器后台启动后,会立即自杀因为他觉得他没事可做了.所以，最佳的解决方案是,将你要运行的程序以前台进程的形式运行，常见就是命令行模式，表示我还有交互操作，别中断，O(∩_∩)O哈哈~ redis 前后台启动演示case 前台交互式启动 1docker run -it redis:6.0.8 后台守护式启动 1docker run -d redis:6.0.8 3.4.2查看容器日志1docker logs 容器ID 3.4.3查看容器内运行的进程1docker top 容器ID 3.4.4查看容器内部细节1docker inspect 容器ID 3.4.5进入正在运行的容器并以命令行交互123docker exec -it 容器ID bashShelldocker attach 容器ID 123456789上述两个区别1.attach 直接进入容器启动命令的终端，不会启动新的进程用exit退出，会导致容器的停止。2.exec 是在容器中打开新的终端，并且可以启动新的进程用exit退出，不会导致容器的停止。3.推荐大家使用 docker exec 命令，因为退出容器终端，不会导致容器的停止。 3.4.6从容器内拷贝文件到主机上容器→主机 1docker cp 容器ID:容器内路径 目的主机路径 3.4.7导入和导出容器1export 导出容器的内容留作为一个tar归档文件[对应import命令] 1import 从tar包中的内容创建一个新的文件系统再导入为镜像[对应export] 案例 1docker export 容器ID &gt; 文件名.tar 运行刚才导出的容器 1cat 文件名.tar | docker import - 镜像用户/镜像名:镜像版本号","categories":[],"tags":[]},{"title":"Docker常用命令","slug":"Docker常用命令","date":"2022-01-01T14:15:09.000Z","updated":"2022-01-09T14:18:03.019Z","comments":true,"path":"2022/01/01/Docker常用命令/","link":"","permalink":"http://www.xc234.ltd/2022/01/01/Docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","excerpt":"","text":"attach Attach to a running container # 当前 shell 下 attach 连接指定运行镜像build Build an image from a Dockerfile # 通过 Dockerfile 定制镜像commit Create a new image from a container changes # 提交当前容器为新的镜像cp Copy files/folders from the containers filesystem to the host path #从容器中拷贝指定文件或者目录到宿主机中create Create a new container # 创建一个新的容器，同 run，但不启动容器diff Inspect changes on a container’s filesystem # 查看 docker 容器变化events Get real time events from the server # 从 docker 服务获取容器实时事件exec Run a command in an existing container # 在已存在的容器上运行命令export Stream the contents of a container as a tar archive # 导出容器的内容流作为一个 tar 归档文件[对应 import ]history Show the history of an image # 展示一个镜像形成历史images List images # 列出系统当前镜像import Create a new filesystem image from the contents of a tarball # 从tar包中的内容创建一个新的文件系统映像[对应export]info Display system-wide information # 显示系统相关信息inspect Return low-level information on a container # 查看容器详细信息kill Kill a running container # kill 指定 docker 容器load Load an image from a tar archive # 从一个 tar 包中加载一个镜像[对应 save]login Register or Login to the docker registry server # 注册或者登陆一个 docker 源服务器logout Log out from a Docker registry server # 从当前 Docker registry 退出logs Fetch the logs of a container # 输出当前容器日志信息port Lookup the public-facing port which is NAT-ed to PRIVATE_PORT # 查看映射端口对应的容器内部源端口pause Pause all processes within a container # 暂停容器ps List containers # 列出容器列表pull Pull an image or a repository from the docker registry server # 从docker镜像源服务器拉取指定镜像或者库镜像push Push an image or a repository to the docker registry server # 推送指定镜像或者库镜像至docker源服务器restart Restart a running container # 重启运行的容器rm Remove one or more containers # 移除一个或者多个容器rmi Remove one or more images # 移除一个或多个镜像[无容器使用该镜像才可删除，否则需删除相关容器才可继续或 -f 强制删除]run Run a command in a new container # 创建一个新的容器并运行一个命令save Save an image to a tar archive # 保存一个镜像为一个 tar 包[对应 load]search Search for an image on the Docker Hub # 在 docker hub 中搜索镜像start Start a stopped containers # 启动容器stop Stop a running containers # 停止容器tag Tag an image into a repository # 给源中镜像打标签top Lookup the running processes of a container # 查看容器中运行的进程信息unpause Unpause a paused container # 取消暂停容器version Show the docker version information # 查看 docker 版本号wait Block until a container stops, then print its exit code # 截取容器停止时的退出状态值 Docker常用命令帮助启动类命令启动docker1systemctl start docker 停止docker1systemctl stop docker 重启docker1systemctl restart docker 查看docker状态1systemctl status docker 开机启动1systemctl enable docker 查看docker概要信息1docker info 查看docker总体帮助文档1docker --help 查看docker命令帮助文档1docker 具体命令 --help 镜像命令列出本地主机上的镜像1docker images 搜索镜像1docker search 某个XXX镜像名字 拉取镜像1docker pull 某个XXX镜像名字 查看镜像/容器/数据卷所占的空间1docker system df 删除镜像1docker rmi 某个XXX镜像名字/ID 删除单个 1docker rmi -f 镜像ID 删除多个 1docker rmi -f 镜像名1:TAG 镜像名2:TAG *删除全部** 1docker rmi -f $(docker images -qa) 容器命令新建+启动容器1docker run [OPTIONS] IMAGE [COMMAND] [ARG...] OPTIONS说明（常用）：有些是一个减号，有些是两个减号 –name=”容器新名字” 为容器指定一个名称；-d: 后台运行容器并返回容器ID，也即启动守护式容器(后台运行)； -i：以交互模式运行容器，通常与 -t 同时使用；-t：为容器重新分配一个伪输入终端，通常与 -i 同时使用；也即启动交互式容器(前台有伪终端，等待交互)； -P: 随机端口映射，大写P-p: 指定端口映射，小写p 列出当前所有正在运行的容器1docker ps [OPTIONS] 退出容器两种退出方式 1exit !!!run进去容器，exit退出，容器停止 快捷键 1ctrl+p+q run进去容器，ctrl+p+q退出，容器不停止 启动已停止运行的容器1docker start 容器ID或者容器名 重启容器1docker restart 容器ID或者容器名 停止容器1docker stop 容器ID或者容器名 强制停止容器1docker kill 容器ID或容器名 删除已停止的容器1docker rm 容器ID 一次性删除多个容器实例 123docker rm -f $(docker ps -a -q)#或者docker ps -a -q | xargs docker rm 重要的容器命令有镜像才能创建容器，这是根本前提(下载一个Redis6.0.8镜像演示) 启动守护式容器(后台服务器)在大部分的场景下，我们希望 docker 的服务是在后台运行的，我们可以过 -d 指定容器的后台运行模式。 1docker run -d 容器名 12345678910111213#使用镜像centos:latest以后台模式启动一个容器docker run -d centos 问题：然后docker ps -a 进行查看, 会发现容器已经退出很重要的要说明的一点: Docker容器后台运行,就必须有一个前台进程.容器运行的命令如果不是那些一直挂起的命令（比如运行top，tail），就是会自动退出的。 这个是docker的机制问题,比如你的web容器,我们以nginx为例，正常情况下,我们配置启动服务只需要启动响应的service即可。例如service nginx start但是,这样做,nginx为后台进程模式运行,就导致docker前台没有运行的应用,这样的容器后台启动后,会立即自杀因为他觉得他没事可做了.所以，最佳的解决方案是,将你要运行的程序以前台进程的形式运行，常见就是命令行模式，表示我还有交互操作，别中断，O(∩_∩)O哈哈~ redis 前后台启动演示case 前台交互式启动 1docker run -it redis:6.0.8 后台守护式启动 1docker run -d redis:6.0.8 查看容器日志1docker logs 容器ID 查看容器内运行的进程1docker top 容器ID 查看容器内部细节1docker inspect 容器ID 进入正在运行的容器并以命令行交互123docker exec -it 容器ID bashShelldocker attach 容器ID 123456789上述两个区别1.attach 直接进入容器启动命令的终端，不会启动新的进程用exit退出，会导致容器的停止。2.exec 是在容器中打开新的终端，并且可以启动新的进程用exit退出，不会导致容器的停止。3.推荐大家使用 docker exec 命令，因为退出容器终端，不会导致容器的停止。 从容器内拷贝文件到主机上容器→主机 1docker cp 容器ID:容器内路径 目的主机路径 导入和导出容器1export 导出容器的内容留作为一个tar归档文件[对应import命令] 1import 从tar包中的内容创建一个新的文件系统再导入为镜像[对应export] 案例 1docker export 容器ID &gt; 文件名.tar 运行刚才导出的容器 1cat 文件名.tar | docker import - 镜像用户/镜像名:镜像版本号","categories":[],"tags":[]},{"title":"Linux服务器必备操作","slug":"Linux服务器必备操作","date":"2021-11-01T13:30:03.000Z","updated":"2021-11-01T13:32:15.914Z","comments":true,"path":"2021/11/01/Linux服务器必备操作/","link":"","permalink":"http://www.xc234.ltd/2021/11/01/Linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%BF%85%E5%A4%87%E6%93%8D%E4%BD%9C/","excerpt":"","text":"第一次安装linux服务器一、可以先安装宝塔面板安装教程 二、安装JDK1.8安装教程 三、安装数据库（mysql）可以安装用宝塔安装mysql 远程访问数据库注意如果需要远程访问服务器上的服务器时，需要在安全组上开放相应的端口，然后同样需要在宝塔安全页面放行相应的端口才能访问 四、依次运行以下命令添加yum源1234yum updateyum install epel-release -yyum clean allyum list 五、安装需要的软件docker安装并运行Docker12yum install docker-io -ysystemctl start docker 检查安装结果1docker info 启动使用Docker123systemctl start docker #运行Docker守护进程systemctl stop docker #停止Docker守护进程systemctl restart docker #重启Docker守护进程 修改docker镜像仓库12345678910vim &#x2F;etc&#x2F;docker&#x2F;daemon.json#改为下面内容，然后重启docker&#123;&quot;debug&quot;:true,&quot;experimental&quot;:true,&quot;registry-mirrors&quot;:[&quot;https:&#x2F;&#x2F;pb5bklzr.mirror.aliyuncs.com&quot;,&quot;https:&#x2F;&#x2F;hub-mirror.c.163.com&quot;,&quot;https:&#x2F;&#x2F;docker.mirrors.ustc.edu.cn&quot;]&#125;#大括号不用复制#查看信息docker info 然后重新启动docker(systemctl restart docker)，查看信息(docker info) docker部署redis 如果访问不了，记得看防火墙/网络安全组端口是否开放 源码安装redis的话默认不能远程访问 docker安装redis可以远程访问 1234#docker run -itd --name mall-redis(名称) -p 8000:6379(映射服务器端口：容器端口) redis --requirepass 123456（设置密码）docker run -itd --name startmall-redis -p 8000:6379 redis --requirepass 123456 记得去安全组开放相应端口","categories":[],"tags":[]},{"title":"ActiveMQ消息中间件笔记","slug":"ActiveMQ消息中间件笔记","date":"2021-01-18T10:52:03.000Z","updated":"2022-03-29T02:23:40.756Z","comments":true,"path":"2021/01/18/ActiveMQ消息中间件笔记/","link":"","permalink":"http://www.xc234.ltd/2021/01/18/ActiveMQ%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%AC%94%E8%AE%B0/","excerpt":"","text":"1.入门概述1.1 1.1 MQ的产品种类和对比MQ就是消息中间件。MQ是一种理念，ActiveMQ是MQ的落地产品。不管是哪款消息中间件，都有如下一些技术维度： (1) kafka 编程语言：scala。 大数据领域的主流MQ。 (2) rabbitmq 编程语言：erlang 基于erlang语言，不好修改底层，不要查找问题的原因，不建议选用。 (3) rocketmq 编程语言：java 适用于大型项目。适用于集群。 (4) activemq 编程语言：java 适用于中小型项目。","categories":[],"tags":[{"name":"MQ","slug":"MQ","permalink":"http://www.xc234.ltd/tags/MQ/"}]},{"title":"测试本地图片显示","slug":"测试本地图片显示","date":"2021-01-18T08:21:07.000Z","updated":"2022-03-29T05:31:37.779Z","comments":true,"path":"2021/01/18/测试本地图片显示/","link":"","permalink":"http://www.xc234.ltd/2021/01/18/%E6%B5%8B%E8%AF%95%E6%9C%AC%E5%9C%B0%E5%9B%BE%E7%89%87%E6%98%BE%E7%A4%BA/","excerpt":"","text":"","categories":[],"tags":[{"name":"test","slug":"test","permalink":"http://www.xc234.ltd/tags/test/"},{"name":"本地","slug":"本地","permalink":"http://www.xc234.ltd/tags/%E6%9C%AC%E5%9C%B0/"},{"name":"图片","slug":"图片","permalink":"http://www.xc234.ltd/tags/%E5%9B%BE%E7%89%87/"}]},{"title":"Redis笔记","slug":"Redis笔记","date":"2021-01-17T09:52:18.000Z","updated":"2022-03-29T02:23:40.771Z","comments":true,"path":"2021/01/17/Redis笔记/","link":"","permalink":"http://www.xc234.ltd/2021/01/17/Redis%E7%AC%94%E8%AE%B0/","excerpt":"","text":"一、Nosql概述为什么使用Nosql 1、单机Mysql时代 90年代,一个网站的访问量一般不会太大，单个数据库完全够用。随着用户增多，网站出现以下问题 数据量增加到一定程度，单机数据库就放不下了 数据的索引（B+ Tree）,一个机器内存也存放不下 访问量变大后（读写混合），一台服务器承受不住。 2、Memcached(缓存) + Mysql + 垂直拆分（读写分离） 网站80%的情况都是在读，每次都要去查询数据库的话就十分的麻烦！所以说我们希望减轻数据库的压力，我们可以使用缓存来保证效率！ 优化过程经历了以下几个过程： 优化数据库的数据结构和索引(难度大) 文件缓存，通过IO流获取比每次都访问数据库效率略高，但是流量爆炸式增长时候，IO流也承受不了 MemCache,当时最热门的技术，通过在数据库和数据库访问层之间加上一层缓存，第一次访问时查询数据库，将结果保存到缓存，后续的查询先检查缓存，若有直接拿去使用，效率显著提升。 3、分库分表 + 水平拆分 + Mysql集群 4、如今最近的年代 如今信息量井喷式增长，各种各样的数据出现（用户定位数据，图片数据等），大数据的背景下关系型数据库（RDBMS）无法满足大量数据要求。Nosql数据库就能轻松解决这些问题。 目前一个基本的互联网项目 为什么要用NoSQL ？ 用户的个人信息，社交网络，地理位置。用户自己产生的数据，用户日志等等爆发式增长！这时候我们就需要使用NoSQL数据库的，Nosql可以很好的处理以上的情况！ 什么是NosqlNoSQL = Not Only SQL（不仅仅是SQL） Not Only Structured Query Language 关系型数据库：列+行，同一个表下数据的结构是一样的。 非关系型数据库：数据存储没有固定的格式，并且可以进行横向扩展。 NoSQL泛指非关系型数据库，随着web2.0互联网的诞生，传统的关系型数据库很难对付web2.0时代！尤其是超大规模的高并发的社区，暴露出来很多难以克服的问题，NoSQL在当今大数据环境下发展的十分迅速，Redis是发展最快的。 Nosql特点 方便扩展（数据之间没有关系，很好扩展！） 大数据量高性能（Redis一秒可以写8万次，读11万次，NoSQL的缓存记录级，是一种细粒度的缓存，性能会比较高！） 数据类型是多样型的！（不需要事先设计数据库，随取随用） 传统的 RDBMS 和 NoSQL 12345678传统的 RDBMS(关系型数据库)- 结构化组织- SQL- 数据和关系都存在单独的表中 row col- 操作，数据定义语言- 严格的一致性- 基础的事务- ... 12345678Nosql- 不仅仅是数据- 没有固定的查询语言- 键值对存储，列存储，文档存储，图形数据库（社交关系）- 最终一致性- CAP定理和BASE- 高性能，高可用，高扩展- ... 了解：3V + 3高 大数据时代的3V ：主要是描述问题的 海量Velume 多样Variety 实时Velocity 大数据时代的3高 ： 主要是对程序的要求 高并发 高可扩 高性能 真正在公司中的实践：NoSQL + RDBMS 一起使用才是最强的。 阿里巴巴演进分析推荐阅读：阿里云的这群疯子https://yq.aliyun.com/articles/653511 12345678910111213141516171819202122# 商品信息- 一般存放在关系型数据库：Mysql,阿里巴巴使用的Mysql都是经过内部改动的。# 商品描述、评论(文字居多)- 文档型数据库：MongoDB# 图片- 分布式文件系统 FastDFS- 淘宝：TFS- Google: GFS- Hadoop: HDFS- 阿里云: oss# 商品关键字 用于搜索- 搜索引擎：solr,elasticsearch- 阿里：Isearch 多隆# 商品热门的波段信息- 内存数据库：Redis，Memcache# 商品交易，外部支付接口- 第三方应用 Nosql的四大分类 KV键值对 新浪：Redis 美团：Redis + Tair 阿里、百度：Redis + Memcache 文档型数据库（bson数据格式）： MongoDB(掌握) 基于分布式文件存储的数据库。C++编写，用于处理大量文档。 MongoDB是RDBMS和NoSQL的中间产品。MongoDB是非关系型数据库中功能最丰富的，NoSQL中最像关系型数据库的数据库。 ConthDB 列存储数据库 HBase(大数据必学) 分布式文件系统 图关系数据库 用于广告推荐，社交网络 Neo4j、InfoGrid 分类 Examples举例 典型应用场景 数据模型 优点 缺点 键值对（key-value） Tokyo Cabinet/Tyrant, Redis, Voldemort, Oracle BDB 内容缓存，主要用于处理大量数据的高访问负载，也用于一些日志系统等等。 Key 指向 Value 的键值对，通常用hash table来实现 查找速度快 数据无结构化，通常只被当作字符串或者二进制数据 列存储数据库 Cassandra, HBase, Riak 分布式的文件系统 以列簇式存储，将同一列数据存在一起 查找速度快，可扩展性强，更容易进行分布式扩展 功能相对局限 文档型数据库 CouchDB, MongoDb Web应用（与Key-Value类似，Value是结构化的，不同的是数据库能够了解Value的内容） Key-Value对应的键值对，Value为结构化数据 数据结构要求不严格，表结构可变，不需要像关系型数据库一样需要预先定义表结构 查询性能不高，而且缺乏统一的查询语法。 图形(Graph)数据库 Neo4J, InfoGrid, Infinite Graph 社交网络，推荐系统等。专注于构建关系图谱 图结构 利用图结构相关算法。比如最短路径寻址，N度关系查找等 很多时候需要对整个图做计算才能得出需要的信息，而且这种结构不太好做分布式的集群 二、Redis入门概述 Redis是什么？ Redis（Remote Dictionary Server )，即远程字典服务。 是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。 与memcached一样，为了保证效率，数据都是缓存在内存中。区别的是redis会周期性的把更新的数据写入磁盘或者把修改操作写入追加的记录文件，并且在此基础上实现了master-slave(主从)同步。 Redis能该干什么？ 内存存储、持久化，内存是断电即失的，所以需要持久化（RDB、AOF） 高效率、用于高速缓冲 发布订阅系统 地图信息分析 计时器、计数器(eg：浏览量) 。。。 特性 多样的数据类型 持久化 集群 事务 … 环境搭建官网：https://redis.io/ 推荐使用Linux服务器学习。 windows版本的Redis已经停更很久了… Windows安装https://github.com/dmajkic/redis 解压安装包 开启redis-server.exe 启动redis-cli.exe测试 Linux安装 下载安装包！redis-5.0.8.tar.gz 解压Redis的安装包！程序一般放在 /opt 目录下 基本环境安装 12345yum install gcc-c++# 然后进入redis目录下执行make# 然后执行make install redis默认安装路径 /usr/local/bin 将redis的配置文件复制到 程序安装目录 /usr/local/bin/kconfig下 redis默认不是后台启动的，需要修改配置文件！ 通过制定的配置文件启动redis服务 使用redis-cli连接指定的端口号测试，Redis的默认端口6379 查看redis进程是否开启 关闭Redis服务 shutdown 再次查看进程是否存在 后面我们会使用单机多Redis启动集群测试 测试性能redis-benchmark：Redis官方提供的性能测试工具，参数选项如下： 简单测试： 123# 测试：100个并发连接 100000请求redis-benchmark -h localhost -p 6379 -c 100 -n 10000012 基础知识 redis默认有16个数据库 默认使用的第0个; 16个数据库为：DB 0~DB 15默认使用DB 0 ，可以使用select n切换到DB n，dbsize可以查看当前数据库的大小，与key数量相关。 12345678910111213141516171819202122232425262728127.0.0.1:6379&gt; config get databases # 命令行查看数据库数量databases1) &quot;databases&quot;2) &quot;16&quot;127.0.0.1:6379&gt; select 8 # 切换数据库 DB 8OK127.0.0.1:6379[8]&gt; dbsize # 查看数据库大小(integer) 0# 不同数据库之间 数据是不能互通的，并且dbsize 是根据库中key的个数。127.0.0.1:6379&gt; set name sakura OK127.0.0.1:6379&gt; SELECT 8OK127.0.0.1:6379[8]&gt; get name # db8中并不能获取db0中的键值对。(nil)127.0.0.1:6379[8]&gt; DBSIZE(integer) 0127.0.0.1:6379[8]&gt; SELECT 0OK127.0.0.1:6379&gt; keys *1) &quot;counter:__rand_int__&quot;2) &quot;mylist&quot;3) &quot;name&quot;4) &quot;key:__rand_int__&quot;5) &quot;myset:__rand_int__&quot;127.0.0.1:6379&gt; DBSIZE # size和key个数相关(integer) 5 keys * ：查看当前数据库中所有的key。 flushdb：清空当前数据库中的键值对。 flushall：清空所有数据库的键值对。 Redis是单线程的，Redis是基于内存操作的。 所以Redis的性能瓶颈不是CPU,而是机器内存和网络带宽。 那么为什么Redis的速度如此快呢，性能这么高呢？QPS达到10W+ Redis为什么单线程还这么快？ 误区1：高性能的服务器一定是多线程的？ 误区2：多线程（CPU上下文会切换！）一定比单线程效率高！ 核心：Redis是将所有的数据放在内存中的，所以说使用单线程去操作效率就是最高的，多线程（CPU上下文会切换：耗时的操作！），对于内存系统来说，如果没有上下文切换效率就是最高的，多次读写都是在一个CPU上的，在内存存储数据情况下，单线程就是最佳的方案。 三、五大数据类型 Redis是一个开源（BSD许可），内存存储的数据结构服务器，可用作数据库，高速缓存和消息队列代理。它支持字符串、哈希表、列表、集合、有序集合，位图，hyperloglogs等数据类型。内置复制、Lua脚本、LRU收回、事务以及不同级别磁盘持久化功能，同时通过Redis Sentinel提供高可用，通过Redis Cluster提供自动分区。 Redis-key 在redis中无论什么数据类型，在数据库中都是以key-value形式保存，通过进行对Redis-key的操作，来完成对数据库中数据的操作。 下面学习的命令： exists key：判断键是否存在 del key：删除键值对 move key db：将键值对移动到指定数据库 expire key second：设置键值对的过期时间 type key：查看value的数据类型 1234567891011121314151617181920212223242526272829303132333435363738394041424344127.0.0.1:6379&gt; keys * # 查看当前数据库所有key(empty list or set)127.0.0.1:6379&gt; set name qinjiang # set keyOK127.0.0.1:6379&gt; set age 20OK127.0.0.1:6379&gt; keys *1) &quot;age&quot;2) &quot;name&quot;127.0.0.1:6379&gt; move age 1 # 将键值对移动到指定数据库(integer) 1127.0.0.1:6379&gt; EXISTS age # 判断键是否存在(integer) 0 # 不存在127.0.0.1:6379&gt; EXISTS name(integer) 1 # 存在127.0.0.1:6379&gt; SELECT 1OK127.0.0.1:6379[1]&gt; keys *1) &quot;age&quot;127.0.0.1:6379[1]&gt; del age # 删除键值对(integer) 1 # 删除个数127.0.0.1:6379&gt; set age 20OK127.0.0.1:6379&gt; EXPIRE age 15 # 设置键值对的过期时间(integer) 1 # 设置成功 开始计数127.0.0.1:6379&gt; ttl age # 查看key的过期剩余时间(integer) 13127.0.0.1:6379&gt; ttl age(integer) 11127.0.0.1:6379&gt; ttl age(integer) 9127.0.0.1:6379&gt; ttl age(integer) -2 # -2 表示key过期，-1表示key未设置过期时间127.0.0.1:6379&gt; get age # 过期的key 会被自动delete(nil)127.0.0.1:6379&gt; keys *1) &quot;name&quot;127.0.0.1:6379&gt; type name # 查看value的数据类型string 关于TTL命令 Redis的key，通过TTL命令返回key的过期时间，一般来说有3种： 当前key没有设置过期时间，所以会返回-1. 当前key有设置过期时间，而且key已经过期，所以会返回-2. 当前key有设置过期时间，且key还没有过期，故会返回key的正常剩余时间. 关于重命名RENAME和RENAMENX RENAME key newkey修改 key 的名称 RENAMENX key newkey仅当 newkey 不存在时，将 key 改名为 newkey 。 更多命令学习：https://www.redis.net.cn/order/ [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-wBVZtGVm-1597890996517)(狂神说 Redis.assets/image-20200813114228439.png)] String(字符串)普通的set、get直接略过。 命令 描述 示例 APPEND key value 向指定的key的value后追加字符串 127.0.0.1:6379&gt; set msg hello OK 127.0.0.1:6379&gt; append msg “ world” (integer) 11 127.0.0.1:6379&gt; get msg “hello world” DECR/INCR key 将指定key的value数值进行+1/-1(仅对于数字) 127.0.0.1:6379&gt; set age 20 OK 127.0.0.1:6379&gt; incr age (integer) 21 127.0.0.1:6379&gt; decr age (integer) 20 INCRBY/DECRBY key n 按指定的步长对数值进行加减 127.0.0.1:6379&gt; INCRBY age 5 (integer) 25 127.0.0.1:6379&gt; DECRBY age 10 (integer) 15 INCRBYFLOAT key n 为数值加上浮点型数值 127.0.0.1:6379&gt; INCRBYFLOAT age 5.2 “20.2” STRLEN key 获取key保存值的字符串长度 127.0.0.1:6379&gt; get msg “hello world” 127.0.0.1:6379&gt; STRLEN msg (integer) 11 GETRANGE key start end 按起止位置获取字符串（闭区间，起止位置都取） 127.0.0.1:6379&gt; get msg “hello world” 127.0.0.1:6379&gt; GETRANGE msg 3 9 “lo worl” SETRANGE key offset value 用指定的value 替换key中 offset开始的值 127.0.0.1:6379&gt; SETRANGE msg 2 hello (integer) 7 127.0.0.1:6379&gt; get msg “tehello” GETSET key value 将给定 key 的值设为 value ，并返回 key 的旧值(old value)。 127.0.0.1:6379&gt; GETSET msg test “hello world” SETNX key value 仅当key不存在时进行set 127.0.0.1:6379&gt; SETNX msg test (integer) 0 127.0.0.1:6379&gt; SETNX name sakura (integer) 1 SETEX key seconds value set 键值对并设置过期时间 127.0.0.1:6379&gt; setex name 10 root OK 127.0.0.1:6379&gt; get name (nil) MSET key1 value1 [key2 value2..] 批量set键值对 127.0.0.1:6379&gt; MSET k1 v1 k2 v2 k3 v3 OK MSETNX key1 value1 [key2 value2..] 批量设置键值对，仅当参数中所有的key都不存在时执行 127.0.0.1:6379&gt; MSETNX k1 v1 k4 v4 (integer) 0 MGET key1 [key2..] 批量获取多个key保存的值 127.0.0.1:6379&gt; MGET k1 k2 k3 1) “v1” 2) “v2” 3) “v3” PSETEX key milliseconds value 和 SETEX 命令相似，但它以毫秒为单位设置 key 的生存时间， getset key value 如果不存在值，则返回nil，如果存在值，获取原来的值，并设置新的值 String类似的使用场景：value除了是字符串还可以是数字，用途举例： 计数器 统计多单位的数量：uid:123666：follow 0 粉丝数 对象存储缓存 List(列表) Redis列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边） 一个列表最多可以包含 232 - 1 个元素 (4294967295, 每个列表超过40亿个元素)。 首先我们列表，可以经过规则定义将其变为队列、栈、双端队列等 正如图Redis中List是可以进行双端操作的，所以命令也就分为了LXXX和RLLL两类，有时候L也表示List例如LLEN 命令 描述 LPUSH/RPUSH key value1[value2..] 从左边/右边向列表中PUSH值(一个或者多个)。 LRANGE key start end 获取list 起止元素==（索引从左往右 递增）== LPUSHX/RPUSHX key value 向已存在的列名中push值（一个或者多个） `LINSERT key BEFORE AFTER pivot value` LLEN key 查看列表长度 LINDEX key index 通过索引获取列表元素 LSET key index value 通过索引为元素设值 LPOP/RPOP key 从最左边/最右边移除值 并返回 RPOPLPUSH source destination 将列表的尾部(右)最后一个值弹出，并返回，然后加到另一个列表的头部 LTRIM key start end 通过下标截取指定范围内的列表 LREM key count value List中是允许value重复的 count &gt; 0：从头部开始搜索 然后删除指定的value 至多删除count个 count &lt; 0：从尾部开始搜索… count = 0：删除列表中所有的指定value。 BLPOP/BRPOP key1[key2] timout 移出并获取列表的第一个/最后一个元素， 如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。 BRPOPLPUSH source destination timeout 和RPOPLPUSH功能相同，如果列表没有元素会阻塞列表直到等待超时或发现可弹出元素为止。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129---------------------------LPUSH---RPUSH---LRANGE--------------------------------127.0.0.1:6379&gt; LPUSH mylist k1 # LPUSH mylist=&gt;&#123;1&#125;(integer) 1127.0.0.1:6379&gt; LPUSH mylist k2 # LPUSH mylist=&gt;&#123;2,1&#125;(integer) 2127.0.0.1:6379&gt; RPUSH mylist k3 # RPUSH mylist=&gt;&#123;2,1,3&#125;(integer) 3127.0.0.1:6379&gt; get mylist # 普通的get是无法获取list值的(error) WRONGTYPE Operation against a key holding the wrong kind of value127.0.0.1:6379&gt; LRANGE mylist 0 4 # LRANGE 获取起止位置范围内的元素1) &quot;k2&quot;2) &quot;k1&quot;3) &quot;k3&quot;127.0.0.1:6379&gt; LRANGE mylist 0 21) &quot;k2&quot;2) &quot;k1&quot;3) &quot;k3&quot;127.0.0.1:6379&gt; LRANGE mylist 0 11) &quot;k2&quot;2) &quot;k1&quot;127.0.0.1:6379&gt; LRANGE mylist 0 -1 # 获取全部元素1) &quot;k2&quot;2) &quot;k1&quot;3) &quot;k3&quot;---------------------------LPUSHX---RPUSHX-----------------------------------127.0.0.1:6379&gt; LPUSHX list v1 # list不存在 LPUSHX失败(integer) 0127.0.0.1:6379&gt; LPUSHX list v1 v2 (integer) 0127.0.0.1:6379&gt; LPUSHX mylist k4 k5 # 向mylist中 左边 PUSH k4 k5(integer) 5127.0.0.1:6379&gt; LRANGE mylist 0 -11) &quot;k5&quot;2) &quot;k4&quot;3) &quot;k2&quot;4) &quot;k1&quot;5) &quot;k3&quot;---------------------------LINSERT--LLEN--LINDEX--LSET----------------------------127.0.0.1:6379&gt; LINSERT mylist after k2 ins_key1 # 在k2元素后 插入ins_key1(integer) 6127.0.0.1:6379&gt; LRANGE mylist 0 -11) &quot;k5&quot;2) &quot;k4&quot;3) &quot;k2&quot;4) &quot;ins_key1&quot;5) &quot;k1&quot;6) &quot;k3&quot;127.0.0.1:6379&gt; LLEN mylist # 查看mylist的长度(integer) 6127.0.0.1:6379&gt; LINDEX mylist 3 # 获取下标为3的元素&quot;ins_key1&quot;127.0.0.1:6379&gt; LINDEX mylist 0&quot;k5&quot;127.0.0.1:6379&gt; LSET mylist 3 k6 # 将下标3的元素 set值为k6OK127.0.0.1:6379&gt; LRANGE mylist 0 -11) &quot;k5&quot;2) &quot;k4&quot;3) &quot;k2&quot;4) &quot;k6&quot;5) &quot;k1&quot;6) &quot;k3&quot;---------------------------LPOP--RPOP--------------------------127.0.0.1:6379&gt; LPOP mylist # 左侧(头部)弹出&quot;k5&quot;127.0.0.1:6379&gt; RPOP mylist # 右侧(尾部)弹出&quot;k3&quot;---------------------------RPOPLPUSH--------------------------127.0.0.1:6379&gt; LRANGE mylist 0 -11) &quot;k4&quot;2) &quot;k2&quot;3) &quot;k6&quot;4) &quot;k1&quot;127.0.0.1:6379&gt; RPOPLPUSH mylist newlist # 将mylist的最后一个值(k1)弹出，加入到newlist的头部&quot;k1&quot;127.0.0.1:6379&gt; LRANGE newlist 0 -11) &quot;k1&quot;127.0.0.1:6379&gt; LRANGE mylist 0 -11) &quot;k4&quot;2) &quot;k2&quot;3) &quot;k6&quot;---------------------------LTRIM--------------------------127.0.0.1:6379&gt; LTRIM mylist 0 1 # 截取mylist中的 0~1部分OK127.0.0.1:6379&gt; LRANGE mylist 0 -11) &quot;k4&quot;2) &quot;k2&quot;# 初始 mylist: k2,k2,k2,k2,k2,k2,k4,k2,k2,k2,k2---------------------------LREM--------------------------127.0.0.1:6379&gt; LREM mylist 3 k2 # 从头部开始搜索 至多删除3个 k2(integer) 3# 删除后：mylist: k2,k2,k2,k4,k2,k2,k2,k2127.0.0.1:6379&gt; LREM mylist -2 k2 #从尾部开始搜索 至多删除2个 k2(integer) 2# 删除后：mylist: k2,k2,k2,k4,k2,k2---------------------------BLPOP--BRPOP--------------------------mylist: k2,k2,k2,k4,k2,k2newlist: k1127.0.0.1:6379&gt; BLPOP newlist mylist 30 # 从newlist中弹出第一个值，mylist作为候选1) &quot;newlist&quot; # 弹出2) &quot;k1&quot;127.0.0.1:6379&gt; BLPOP newlist mylist 301) &quot;mylist&quot; # 由于newlist空了 从mylist中弹出2) &quot;k2&quot;127.0.0.1:6379&gt; BLPOP newlist 30(30.10s) # 超时了127.0.0.1:6379&gt; BLPOP newlist 30 # 我们连接另一个客户端向newlist中push了test, 阻塞被解决。1) &quot;newlist&quot;2) &quot;test&quot;(12.54s) 小结 list实际上是一个链表，before Node after , left, right 都可以插入值 如果key不存在，则创建新的链表 如果key存在，新增内容 如果移除了所有值，空链表，也代表不存在 在两边插入或者改动值，效率最高！修改中间元素，效率相对较低 应用： 消息排队！消息队列（Lpush Rpop）,栈（Lpush Lpop） Set(集合) Redis的Set是string类型的无序集合。集合成员是唯一的，这就意味着集合中不能出现重复的数据。 Redis 中 集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是O(1)。 集合中最大的成员数为 232 - 1 (4294967295, 每个集合可存储40多亿个成员)。 命令 描述 SADD key member1[member2..] 向集合中无序增加一个/多个成员 SCARD key 获取集合的成员数 SMEMBERS key 返回集合中所有的成员 SISMEMBER key member 查询member元素是否是集合的成员,结果是无序的 SRANDMEMBER key [count] 随机返回集合中count个成员，count缺省值为1 SPOP key [count] 随机移除并返回集合中count个成员，count缺省值为1 SMOVE source destination member 将source集合的成员member移动到destination集合 SREM key member1[member2..] 移除集合中一个/多个成员 SDIFF key1[key2..] 返回所有集合的差集 key1- key2 - … SDIFFSTORE destination key1[key2..] 在SDIFF的基础上，将结果保存到集合中==(覆盖)==。不能保存到其他类型key噢！ SINTER key1 [key2..] 返回所有集合的交集 SINTERSTORE destination key1[key2..] 在SINTER的基础上，存储结果到集合中。覆盖 SUNION key1 [key2..] 返回所有集合的并集 SUNIONSTORE destination key1 [key2..] 在SUNION的基础上，存储结果到及和张。覆盖 SSCAN KEY [MATCH pattern] [COUNT count] 在大量数据环境下，使用此命令遍历集合中元素，每次遍历部分 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384---------------SADD--SCARD--SMEMBERS--SISMEMBER--------------------127.0.0.1:6379&gt; SADD myset m1 m2 m3 m4 # 向myset中增加成员 m1~m4(integer) 4127.0.0.1:6379&gt; SCARD myset # 获取集合的成员数目(integer) 4127.0.0.1:6379&gt; smembers myset # 获取集合中所有成员1) &quot;m4&quot;2) &quot;m3&quot;3) &quot;m2&quot;4) &quot;m1&quot;127.0.0.1:6379&gt; SISMEMBER myset m5 # 查询m5是否是myset的成员(integer) 0 # 不是，返回0127.0.0.1:6379&gt; SISMEMBER myset m2(integer) 1 # 是，返回1127.0.0.1:6379&gt; SISMEMBER myset m3(integer) 1---------------------SRANDMEMBER--SPOP----------------------------------127.0.0.1:6379&gt; SRANDMEMBER myset 3 # 随机返回3个成员1) &quot;m2&quot;2) &quot;m3&quot;3) &quot;m4&quot;127.0.0.1:6379&gt; SRANDMEMBER myset # 随机返回1个成员&quot;m3&quot;127.0.0.1:6379&gt; SPOP myset 2 # 随机移除并返回2个成员1) &quot;m1&quot;2) &quot;m4&quot;# 将set还原到&#123;m1,m2,m3,m4&#125;---------------------SMOVE--SREM----------------------------------------127.0.0.1:6379&gt; SMOVE myset newset m3 # 将myset中m3成员移动到newset集合(integer) 1127.0.0.1:6379&gt; SMEMBERS myset1) &quot;m4&quot;2) &quot;m2&quot;3) &quot;m1&quot;127.0.0.1:6379&gt; SMEMBERS newset1) &quot;m3&quot;127.0.0.1:6379&gt; SREM newset m3 # 从newset中移除m3元素(integer) 1127.0.0.1:6379&gt; SMEMBERS newset(empty list or set)# 下面开始是多集合操作,多集合操作中若只有一个参数默认和自身进行运算# setx=&gt;&#123;m1,m2,m4,m6&#125;, sety=&gt;&#123;m2,m5,m6&#125;, setz=&gt;&#123;m1,m3,m6&#125;-----------------------------SDIFF------------------------------------127.0.0.1:6379&gt; SDIFF setx sety setz # 等价于setx-sety-setz1) &quot;m4&quot;127.0.0.1:6379&gt; SDIFF setx sety # setx - sety1) &quot;m4&quot;2) &quot;m1&quot;127.0.0.1:6379&gt; SDIFF sety setx # sety - setx1) &quot;m5&quot;-------------------------SINTER---------------------------------------# 共同关注（交集）127.0.0.1:6379&gt; SINTER setx sety setz # 求 setx、sety、setx的交集1) &quot;m6&quot;127.0.0.1:6379&gt; SINTER setx sety # 求setx sety的交集1) &quot;m2&quot;2) &quot;m6&quot;-------------------------SUNION---------------------------------------127.0.0.1:6379&gt; SUNION setx sety setz # setx sety setz的并集1) &quot;m4&quot;2) &quot;m6&quot;3) &quot;m3&quot;4) &quot;m2&quot;5) &quot;m1&quot;6) &quot;m5&quot;127.0.0.1:6379&gt; SUNION setx sety # setx sety 并集1) &quot;m4&quot;2) &quot;m6&quot;3) &quot;m2&quot;4) &quot;m1&quot;5) &quot;m5&quot; Hash（哈希） Redis hash 是一个string类型的field和value的映射表，hash特别适合用于存储对象。 Set就是一种简化的Hash,只变动key,而value使用默认值填充。可以将一个Hash表作为一个对象进行存储，表中存放对象的信息。 命令 描述 HSET key field value 将哈希表 key 中的字段 field 的值设为 value 。重复设置同一个field会覆盖,返回0 HMSET key field1 value1 [field2 value2..] 同时将多个 field-value (域-值)对设置到哈希表 key 中。 HSETNX key field value 只有在字段 field 不存在时，设置哈希表字段的值。 HEXISTS key field 查看哈希表 key 中，指定的字段是否存在。 HGET key field value 获取存储在哈希表中指定字段的值 HMGET key field1 [field2..] 获取所有给定字段的值 HGETALL key 获取在哈希表key 的所有字段和值 HKEYS key 获取哈希表key中所有的字段 HLEN key 获取哈希表中字段的数量 HVALS key 获取哈希表中所有值 HDEL key field1 [field2..] 删除哈希表key中一个/多个field字段 HINCRBY key field n 为哈希表 key 中的指定字段的整数值加上增量n，并返回增量后结果 一样只适用于整数型字段 HINCRBYFLOAT key field n 为哈希表 key 中的指定字段的浮点数值加上增量 n。 HSCAN key cursor [MATCH pattern] [COUNT count] 迭代哈希表中的键值对。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071------------------------HSET--HMSET--HSETNX----------------127.0.0.1:6379&gt; HSET studentx name sakura # 将studentx哈希表作为一个对象，设置name为sakura(integer) 1127.0.0.1:6379&gt; HSET studentx name gyc # 重复设置field进行覆盖，并返回0(integer) 0127.0.0.1:6379&gt; HSET studentx age 20 # 设置studentx的age为20(integer) 1127.0.0.1:6379&gt; HMSET studentx sex 1 tel 15623667886 # 设置sex为1，tel为15623667886OK127.0.0.1:6379&gt; HSETNX studentx name gyc # HSETNX 设置已存在的field(integer) 0 # 失败127.0.0.1:6379&gt; HSETNX studentx email 12345@qq.com(integer) 1 # 成功----------------------HEXISTS--------------------------------127.0.0.1:6379&gt; HEXISTS studentx name # name字段在studentx中是否存在(integer) 1 # 存在127.0.0.1:6379&gt; HEXISTS studentx addr(integer) 0 # 不存在-------------------HGET--HMGET--HGETALL-----------127.0.0.1:6379&gt; HGET studentx name # 获取studentx中name字段的value&quot;gyc&quot;127.0.0.1:6379&gt; HMGET studentx name age tel # 获取studentx中name、age、tel字段的value1) &quot;gyc&quot;2) &quot;20&quot;3) &quot;15623667886&quot;127.0.0.1:6379&gt; HGETALL studentx # 获取studentx中所有的field及其value 1) &quot;name&quot; 2) &quot;gyc&quot; 3) &quot;age&quot; 4) &quot;20&quot; 5) &quot;sex&quot; 6) &quot;1&quot; 7) &quot;tel&quot; 8) &quot;15623667886&quot; 9) &quot;email&quot;10) &quot;12345@qq.com&quot;--------------------HKEYS--HLEN--HVALS--------------127.0.0.1:6379&gt; HKEYS studentx # 查看studentx中所有的field1) &quot;name&quot;2) &quot;age&quot;3) &quot;sex&quot;4) &quot;tel&quot;5) &quot;email&quot;127.0.0.1:6379&gt; HLEN studentx # 查看studentx中的字段数量(integer) 5127.0.0.1:6379&gt; HVALS studentx # 查看studentx中所有的value1) &quot;gyc&quot;2) &quot;20&quot;3) &quot;1&quot;4) &quot;15623667886&quot;5) &quot;12345@qq.com&quot;-------------------------HDEL--------------------------127.0.0.1:6379&gt; HDEL studentx sex tel # 删除studentx 中的sex、tel字段(integer) 2127.0.0.1:6379&gt; HKEYS studentx1) &quot;name&quot;2) &quot;age&quot;3) &quot;email&quot;-------------HINCRBY--HINCRBYFLOAT------------------------127.0.0.1:6379&gt; HINCRBY studentx age 1 # studentx的age字段数值+1(integer) 21127.0.0.1:6379&gt; HINCRBY studentx name 1 # 非整数字型字段不可用(error) ERR hash value is not an integer127.0.0.1:6379&gt; HINCRBYFLOAT studentx weight 0.6 # weight字段增加0.6&quot;90.8&quot; Hash变更的数据user name age，尤其是用户信息之类的，经常变动的信息！Hash更适合于对象的存储，Sring更加适合字符串存储！ Zset（有序集合） 不同的是每个元素都会关联一个double类型的分数（score）。redis正是通过分数来为集合中的成员进行从小到大的排序。 score相同：按字典顺序排序 有序集合的成员是唯一的,但分数(score)却可以重复。 命令 描述 ZADD key score member1 [score2 member2] 向有序集合添加一个或多个成员，或者更新已存在成员的分数 ZCARD key 获取有序集合的成员数 ZCOUNT key min max 计算在有序集合中指定区间score的成员数 ZINCRBY key n member 有序集合中对指定成员的分数加上增量 n ZSCORE key member 返回有序集中，成员的分数值 ZRANK key member 返回有序集合中指定成员的索引 ZRANGE key start end 通过索引区间返回有序集合成指定区间内的成员 ZRANGEBYLEX key min max 通过字典区间返回有序集合的成员 ZRANGEBYSCORE key min max 通过分数返回有序集合指定区间内的成员==-inf 和 +inf分别表示最小最大值，只支持开区间()== ZLEXCOUNT key min max 在有序集合中计算指定字典区间内成员数量 ZREM key member1 [member2..] 移除有序集合中一个/多个成员 ZREMRANGEBYLEX key min max 移除有序集合中给定的字典区间的所有成员 ZREMRANGEBYRANK key start stop 移除有序集合中给定的排名区间的所有成员 ZREMRANGEBYSCORE key min max 移除有序集合中给定的分数区间的所有成员 ZREVRANGE key start end 返回有序集中指定区间内的成员，通过索引，分数从高到底 ZREVRANGEBYSCORRE key max min 返回有序集中指定分数区间内的成员，分数从高到低排序 ZREVRANGEBYLEX key max min 返回有序集中指定字典区间内的成员，按字典顺序倒序 ZREVRANK key member 返回有序集合中指定成员的排名，有序集成员按分数值递减(从大到小)排序 ZINTERSTORE destination numkeys key1 [key2 ..] 计算给定的一个或多个有序集的交集并将结果集存储在新的有序集合 key 中，numkeys：表示参与运算的集合数，将score相加作为结果的score ZUNIONSTORE destination numkeys key1 [key2..] 计算给定的一个或多个有序集的交集并将结果集存储在新的有序集合 key 中 ZSCAN key cursor [MATCH pattern\\] [COUNT count] 迭代有序集合中的元素（包括元素成员和元素分值） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137-------------------ZADD--ZCARD--ZCOUNT--------------127.0.0.1:6379&gt; ZADD myzset 1 m1 2 m2 3 m3 # 向有序集合myzset中添加成员m1 score=1 以及成员m2 score=2..(integer) 2127.0.0.1:6379&gt; ZCARD myzset # 获取有序集合的成员数(integer) 2127.0.0.1:6379&gt; ZCOUNT myzset 0 1 # 获取score在 [0,1]区间的成员数量(integer) 1127.0.0.1:6379&gt; ZCOUNT myzset 0 2(integer) 2----------------ZINCRBY--ZSCORE--------------------------127.0.0.1:6379&gt; ZINCRBY myzset 5 m2 # 将成员m2的score +5&quot;7&quot;127.0.0.1:6379&gt; ZSCORE myzset m1 # 获取成员m1的score&quot;1&quot;127.0.0.1:6379&gt; ZSCORE myzset m2&quot;7&quot;--------------ZRANK--ZRANGE-----------------------------------127.0.0.1:6379&gt; ZRANK myzset m1 # 获取成员m1的索引，索引按照score排序，score相同索引值按字典顺序顺序增加(integer) 0127.0.0.1:6379&gt; ZRANK myzset m2(integer) 2127.0.0.1:6379&gt; ZRANGE myzset 0 1 # 获取索引在 0~1的成员1) &quot;m1&quot;2) &quot;m3&quot;127.0.0.1:6379&gt; ZRANGE myzset 0 -1 # 获取全部成员1) &quot;m1&quot;2) &quot;m3&quot;3) &quot;m2&quot;#testset=&gt;&#123;abc,add,amaze,apple,back,java,redis&#125; score均为0------------------ZRANGEBYLEX---------------------------------127.0.0.1:6379&gt; ZRANGEBYLEX testset - + # 返回所有成员1) &quot;abc&quot;2) &quot;add&quot;3) &quot;amaze&quot;4) &quot;apple&quot;5) &quot;back&quot;6) &quot;java&quot;7) &quot;redis&quot;127.0.0.1:6379&gt; ZRANGEBYLEX testset - + LIMIT 0 3 # 分页 按索引显示查询结果的 0,1,2条记录1) &quot;abc&quot;2) &quot;add&quot;3) &quot;amaze&quot;127.0.0.1:6379&gt; ZRANGEBYLEX testset - + LIMIT 3 3 # 显示 3,4,5条记录1) &quot;apple&quot;2) &quot;back&quot;3) &quot;java&quot;127.0.0.1:6379&gt; ZRANGEBYLEX testset (- [apple # 显示 (-,apple] 区间内的成员1) &quot;abc&quot;2) &quot;add&quot;3) &quot;amaze&quot;4) &quot;apple&quot;127.0.0.1:6379&gt; ZRANGEBYLEX testset [apple [java # 显示 [apple,java]字典区间的成员1) &quot;apple&quot;2) &quot;back&quot;3) &quot;java&quot;-----------------------ZRANGEBYSCORE---------------------127.0.0.1:6379&gt; ZRANGEBYSCORE myzset 1 10 # 返回score在 [1,10]之间的的成员1) &quot;m1&quot;2) &quot;m3&quot;3) &quot;m2&quot;127.0.0.1:6379&gt; ZRANGEBYSCORE myzset 1 51) &quot;m1&quot;2) &quot;m3&quot;--------------------ZLEXCOUNT-----------------------------127.0.0.1:6379&gt; ZLEXCOUNT testset - +(integer) 7127.0.0.1:6379&gt; ZLEXCOUNT testset [apple [java(integer) 3------------------ZREM--ZREMRANGEBYLEX--ZREMRANGBYRANK--ZREMRANGEBYSCORE--------------------------------127.0.0.1:6379&gt; ZREM testset abc # 移除成员abc(integer) 1127.0.0.1:6379&gt; ZREMRANGEBYLEX testset [apple [java # 移除字典区间[apple,java]中的所有成员(integer) 3127.0.0.1:6379&gt; ZREMRANGEBYRANK testset 0 1 # 移除排名0~1的所有成员(integer) 2127.0.0.1:6379&gt; ZREMRANGEBYSCORE myzset 0 3 # 移除score在 [0,3]的成员(integer) 2# testset=&gt; &#123;abc,add,apple,amaze,back,java,redis&#125; score均为0# myzset=&gt; &#123;(m1,1),(m2,2),(m3,3),(m4,4),(m7,7),(m9,9)&#125;----------------ZREVRANGE--ZREVRANGEBYSCORE--ZREVRANGEBYLEX-----------127.0.0.1:6379&gt; ZREVRANGE myzset 0 3 # 按score递减排序，然后按索引，返回结果的 0~31) &quot;m9&quot;2) &quot;m7&quot;3) &quot;m4&quot;4) &quot;m3&quot;127.0.0.1:6379&gt; ZREVRANGE myzset 2 4 # 返回排序结果的 索引的2~41) &quot;m4&quot;2) &quot;m3&quot;3) &quot;m2&quot;127.0.0.1:6379&gt; ZREVRANGEBYSCORE myzset 6 2 # 按score递减顺序 返回集合中分数在[2,6]之间的成员1) &quot;m4&quot;2) &quot;m3&quot;3) &quot;m2&quot;127.0.0.1:6379&gt; ZREVRANGEBYLEX testset [java (add # 按字典倒序 返回集合中(add,java]字典区间的成员1) &quot;java&quot;2) &quot;back&quot;3) &quot;apple&quot;4) &quot;amaze&quot;-------------------------ZREVRANK------------------------------127.0.0.1:6379&gt; ZREVRANK myzset m7 # 按score递减顺序，返回成员m7索引(integer) 1127.0.0.1:6379&gt; ZREVRANK myzset m2(integer) 4# mathscore=&gt;&#123;(xm,90),(xh,95),(xg,87)&#125; 小明、小红、小刚的数学成绩# enscore=&gt;&#123;(xm,70),(xh,93),(xg,90)&#125; 小明、小红、小刚的英语成绩-------------------ZINTERSTORE--ZUNIONSTORE-----------------------------------127.0.0.1:6379&gt; ZINTERSTORE sumscore 2 mathscore enscore # 将mathscore enscore进行合并 结果存放到sumscore(integer) 3127.0.0.1:6379&gt; ZRANGE sumscore 0 -1 withscores # 合并后的score是之前集合中所有score的和1) &quot;xm&quot;2) &quot;160&quot;3) &quot;xg&quot;4) &quot;177&quot;5) &quot;xh&quot;6) &quot;188&quot;127.0.0.1:6379&gt; ZUNIONSTORE lowestscore 2 mathscore enscore AGGREGATE MIN # 取两个集合的成员score最小值作为结果的(integer) 3127.0.0.1:6379&gt; ZRANGE lowestscore 0 -1 withscores1) &quot;xm&quot;2) &quot;70&quot;3) &quot;xg&quot;4) &quot;87&quot;5) &quot;xh&quot;6) &quot;93&quot; 应用案例： set排序 存储班级成绩表 工资表排序！ 普通消息，1.重要消息 2.带权重进行判断 排行榜应用实现，取Top N测试 四、三种特殊数据类型Geospatial(地理位置) 使用经纬度定位地理坐标并用一个有序集合zset保存，所以zset命令也可以使用 命令 描述 geoadd key longitud(经度) latitude(纬度) member [..] 将具体经纬度的坐标存入一个有序集合 geopos key member [member..] 获取集合中的一个/多个成员坐标 geodist key member1 member2 [unit] 返回两个给定位置之间的距离。默认以米作为单位。 `georadius key longitude latitude radius m km GEORADIUSBYMEMBER key member radius... 功能与GEORADIUS相同，只是中心位置不是具体的经纬度，而是使用结合中已有的成员作为中心点。 geohash key member1 [member2..] 返回一个或多个位置元素的Geohash表示。使用Geohash位置52点整数编码。 有效经纬度 有效的经度从-180度到180度。 有效的纬度从-85.05112878度到85.05112878度。 指定单位的参数 unit 必须是以下单位的其中一个： m 表示单位为米。 km 表示单位为千米。 mi 表示单位为英里。 ft 表示单位为英尺。 关于GEORADIUS的参数 通过georadius就可以完成 附近的人功能 withcoord:带上坐标 withdist:带上距离，单位与半径单位相同 COUNT n : 只显示前n个(按距离递增排序) 12345678910111213141516----------------georadius---------------------127.0.0.1:6379&gt; GEORADIUS china:city 120 30 500 km withcoord withdist # 查询经纬度(120,30)坐标500km半径内的成员1) 1) &quot;hangzhou&quot; 2) &quot;29.4151&quot; 3) 1) &quot;120.20000249147415&quot; 2) &quot;30.199999888333501&quot;2) 1) &quot;shanghai&quot; 2) &quot;205.3611&quot; 3) 1) &quot;121.40000134706497&quot; 2) &quot;31.400000253193539&quot; ------------geohash---------------------------127.0.0.1:6379&gt; geohash china:city yichang shanghai # 获取成员经纬坐标的geohash表示1) &quot;wmrjwbr5250&quot;2) &quot;wtw6ds0y300&quot; Hyperloglog(基数统计) Redis HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。 花费 12 KB 内存，就可以计算接近 2^64 个不同元素的基数。 因为 HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。 其底层使用string数据类型 什么是基数？ 数据集中不重复的元素的个数。 应用场景： 网页的访问量（UV）：一个用户多次访问，也只能算作一个人。 传统实现，存储用户的id,然后每次进行比较。当用户变多之后这种方式及其浪费空间，而我们的目的只是计数，Hyperloglog就能帮助我们利用最小的空间完成。 命令 描述 PFADD key element1 [elememt2..] 添加指定元素到 HyperLogLog 中 PFCOUNT key [key] 返回给定 HyperLogLog 的基数估算值。 PFMERGE destkey sourcekey [sourcekey..] 将多个 HyperLogLog 合并为一个 HyperLogLog 1234567891011121314151617----------PFADD--PFCOUNT---------------------127.0.0.1:6379&gt; PFADD myelemx a b c d e f g h i j k # 添加元素(integer) 1127.0.0.1:6379&gt; type myelemx # hyperloglog底层使用Stringstring127.0.0.1:6379&gt; PFCOUNT myelemx # 估算myelemx的基数(integer) 11127.0.0.1:6379&gt; PFADD myelemy i j k z m c b v p q s(integer) 1127.0.0.1:6379&gt; PFCOUNT myelemy(integer) 11----------------PFMERGE-----------------------127.0.0.1:6379&gt; PFMERGE myelemz myelemx myelemy # 合并myelemx和myelemy 成为myelemzOK127.0.0.1:6379&gt; PFCOUNT myelemz # 估算基数(integer) 17 如果允许容错，那么一定可以使用Hyperloglog ! 如果不允许容错，就使用set或者自己的数据类型即可 ！ BitMaps(位图) 使用位存储，信息状态只有 0 和 1 Bitmap是一串连续的2进制数字（0或1），每一位所在的位置为偏移(offset)，在bitmap上可执行AND,OR,XOR,NOT以及其它位操作。 应用场景 签到统计、状态统计 命令 描述 setbit key offset value 为指定key的offset位设置值 getbit key offset 获取offset位的值 bitcount key [start end] 统计字符串被设置为1的bit数，也可以指定统计范围按字节 bitop operration destkey key[key..] 对一个或多个保存二进制位的字符串 key 进行位元操作，并将结果保存到 destkey 上。 BITPOS key bit [start] [end] 返回字符串里面第一个被设置为1或者0的bit位。start和end只能按字节,不能按位 1234567891011121314151617181920212223------------setbit--getbit--------------127.0.0.1:6379&gt; setbit sign 0 1 # 设置sign的第0位为 1 (integer) 0127.0.0.1:6379&gt; setbit sign 2 1 # 设置sign的第2位为 1 不设置默认 是0(integer) 0127.0.0.1:6379&gt; setbit sign 3 1(integer) 0127.0.0.1:6379&gt; setbit sign 5 1(integer) 0127.0.0.1:6379&gt; type signstring127.0.0.1:6379&gt; getbit sign 2 # 获取第2位的数值(integer) 1127.0.0.1:6379&gt; getbit sign 3(integer) 1127.0.0.1:6379&gt; getbit sign 4 # 未设置默认是0(integer) 0-----------bitcount----------------------------127.0.0.1:6379&gt; BITCOUNT sign # 统计sign中为1的位数(integer) 4 bitmaps的底层 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-9PlszjhS-1597890996519)(D:\\我\\MyBlog\\狂神说 Redis.assets\\image-20200803234336175.png)] 这样设置以后你能get到的值是：\\xA2\\x80，所以bitmaps是一串从左到右的二进制串 五、事务Redis的单条命令是保证原子性的，但是redis事务不能保证原子性 Redis事务本质：一组命令的集合。 —————– 队列 set set set 执行 ——————- 事务中每条命令都会被序列化，执行过程中按顺序执行，不允许其他命令进行干扰。 一次性 顺序性 排他性 Redis事务没有隔离级别的概念 Redis单条命令是保证原子性的，但是事务不保证原子性！ Redis事务操作过程 开启事务（multi） 命令入队 执行事务（exec） 所以事务中的命令在加入时都没有被执行，直到提交时才会开始执行(Exec)一次性完成。 123456789101112131415161718192021127.0.0.1:6379&gt; multi # 开启事务OK127.0.0.1:6379&gt; set k1 v1 # 命令入队QUEUED127.0.0.1:6379&gt; set k2 v2 # ..QUEUED127.0.0.1:6379&gt; get k1QUEUED127.0.0.1:6379&gt; set k3 v3QUEUED127.0.0.1:6379&gt; keys *QUEUED127.0.0.1:6379&gt; exec # 事务执行1) OK2) OK3) &quot;v1&quot;4) OK5) 1) &quot;k3&quot; 2) &quot;k2&quot; 3) &quot;k1&quot; 取消事务(discurd) 12345678910111213127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set k1 v1QUEUED127.0.0.1:6379&gt; set k2 v2QUEUED127.0.0.1:6379&gt; DISCARD # 放弃事务OK127.0.0.1:6379&gt; EXEC (error) ERR EXEC without MULTI # 当前未开启事务127.0.0.1:6379&gt; get k1 # 被放弃事务中命令并未执行(nil) 事务错误 代码语法错误（编译时异常）所有的命令都不执行 123456789101112131415127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set k1 v1QUEUED127.0.0.1:6379&gt; set k2 v2QUEUED127.0.0.1:6379&gt; error k1 # 这是一条语法错误命令(error) ERR unknown command `error`, with args beginning with: `k1`, # 会报错但是不影响后续命令入队 127.0.0.1:6379&gt; get k2QUEUED127.0.0.1:6379&gt; EXEC(error) EXECABORT Transaction discarded because of previous errors. # 执行报错127.0.0.1:6379&gt; get k1 (nil) # 其他命令并没有被执行 代码逻辑错误 (运行时异常) **其他命令可以正常执行 ** &gt;&gt;&gt; 所以不保证事务原子性 12345678910111213141516171819127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; set k1 v1QUEUED127.0.0.1:6379&gt; set k2 v2QUEUED127.0.0.1:6379&gt; INCR k1 # 这条命令逻辑错误（对字符串进行增量）QUEUED127.0.0.1:6379&gt; get k2QUEUED127.0.0.1:6379&gt; exec1) OK2) OK3) (error) ERR value is not an integer or out of range # 运行时报错4) &quot;v2&quot; # 其他命令正常执行# 虽然中间有一条命令报错了，但是后面的指令依旧正常执行成功了。# 所以说Redis单条指令保证原子性，但是Redis事务不能保证原子性。 监控悲观锁： 很悲观，认为什么时候都会出现问题，无论做什么都会加锁 乐观锁： 很乐观，认为什么时候都不会出现问题，所以不会上锁！更新数据的时候去判断一下，在此期间是否有人修改过这个数据 获取version 更新的时候比较version 使用watch key监控指定数据，相当于乐观锁加锁。 正常执行 12345678910111213141516127.0.0.1:6379&gt; set money 100 # 设置余额:100OK127.0.0.1:6379&gt; set use 0 # 支出使用:0OK127.0.0.1:6379&gt; watch money # 监视money (上锁)OK127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; DECRBY money 20QUEUED127.0.0.1:6379&gt; INCRBY use 20QUEUED127.0.0.1:6379&gt; exec # 监视值没有被中途修改，事务正常执行1) (integer) 802) (integer) 20 测试多线程修改值，使用watch可以当做redis的乐观锁操作（相当于getversion） 我们启动另外一个客户端模拟插队线程。 线程1： 12345678910127.0.0.1:6379&gt; watch money # money上锁OK127.0.0.1:6379&gt; multiOK127.0.0.1:6379&gt; DECRBY money 20QUEUED127.0.0.1:6379&gt; INCRBY use 20QUEUED127.0.0.1:6379&gt; # 此时事务并没有执行 模拟线程插队，线程2： 1234127.0.0.1:6379&gt; INCRBY money 500 # 修改了线程一中监视的money(integer) 60012 回到线程1，执行事务： 1234567127.0.0.1:6379&gt; EXEC # 执行之前，另一个线程修改了我们的值，这个时候就会导致事务执行失败(nil) # 没有结果，说明事务执行失败127.0.0.1:6379&gt; get money # 线程2 修改生效&quot;600&quot;127.0.0.1:6379&gt; get use # 线程1事务执行失败，数值没有被修改&quot;0&quot; 解锁获取最新值，然后再加锁进行事务。 unwatch进行解锁。 注意：每次提交执行exec后都会自动释放锁，不管是否成功 六、Jedis使用Java来操作Redis，Jedis是Redis官方推荐使用的Java连接redis的客户端。 导入依赖 123456789101112&lt;!--导入jredis的包--&gt;&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;3.2.0&lt;/version&gt;&lt;/dependency&gt;&lt;!--fastjson--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.70&lt;/version&gt;&lt;/dependency&gt; 编码测试 连接数据库 修改redis的配置文件 123vim /usr/local/bin/myconfig/redis.conf1 将只绑定本地注释 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-4IRUFJ95-1597890996520)(狂神说 Redis.assets/image-20200813161921480.png)] 保护模式改为 no [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-oKjIVapw-1597890996521)(狂神说 Redis.assets/image-20200813161939847.png)] 允许后台运行 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-c2IMvpZL-1597890996522)(狂神说 Redis.assets/image-20200813161954567.png)] 开放端口6379 123firewall-cmd --zone=public --add-port=6379/tcp --permanet1 重启防火墙服务 123systemctl restart firewalld.service1 阿里云服务器控制台配置安全组 重启redis-server 123[root@AlibabaECS bin]# redis-server myconfig/redis.conf 1 操作命令 TestPing.java 12345678public class TestPing &#123; public static void main(String[] args) &#123; Jedis jedis = new Jedis(&quot;192.168.xx.xxx&quot;, 6379); String response = jedis.ping(); System.out.println(response); // PONG &#125;&#125; 断开连接 事务 12345678910111213141516171819202122232425262728public class TestTX &#123; public static void main(String[] args) &#123; Jedis jedis = new Jedis(&quot;39.99.xxx.xx&quot;, 6379); JSONObject jsonObject = new JSONObject(); jsonObject.put(&quot;hello&quot;, &quot;world&quot;); jsonObject.put(&quot;name&quot;, &quot;kuangshen&quot;); // 开启事务 Transaction multi = jedis.multi(); String result = jsonObject.toJSONString(); // jedis.watch(result) try &#123; multi.set(&quot;user1&quot;, result); multi.set(&quot;user2&quot;, result); // 执行事务 multi.exec(); &#125;catch (Exception e)&#123; // 放弃事务 multi.discard(); &#125; finally &#123; // 关闭连接 System.out.println(jedis.get(&quot;user1&quot;)); System.out.println(jedis.get(&quot;user2&quot;)); jedis.close(); &#125; &#125;&#125; 七、SpringBoot整合 导入依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; springboot 2.x后 ，原来使用的 Jedis 被 lettuce 替换。 jedis：采用的直连，多个线程操作的话，是不安全的。如果要避免不安全，使用jedis pool连接池！更像BIO模式 lettuce：采用netty，实例可以在多个线程中共享，不存在线程不安全的情况！可以减少线程数据了，更像NIO模式 我们在学习SpringBoot自动配置的原理时，整合一个组件并进行配置一定会有一个自动配置类xxxAutoConfiguration,并且在spring.factories中也一定能找到这个类的完全限定名。Redis也不例外。 那么就一定还存在一个RedisProperties类 之前我们说SpringBoot2.x后默认使用Lettuce来替换Jedis，现在我们就能来验证了。 先看Jedis: @ConditionalOnClass注解中有两个类是默认不存在的，所以Jedis是无法生效的 然后再看Lettuce： 完美生效。 现在我们回到RedisAutoConfiguratio 只有两个简单的Bean RedisTemplate StringRedisTemplate 当看到xxTemplate时可以对比RestTemplat、SqlSessionTemplate,通过使用这些Template来间接操作组件。那么这俩也不会例外。分别用于操作Redis和Redis中的String数据类型。 在RedisTemplate上也有一个条件注解，说明我们是可以对其进行定制化的 说完这些，我们需要知道如何编写配置文件然后连接Redis，就需要阅读RedisProperties 这是一些基本的配置属性。 还有一些连接池相关的配置。注意使用时一定使用Lettuce的连接池。 编写配置文件 1234# 配置redisspring.redis.host=39.99.xxx.xxspring.redis.port=6379 使用RedisTemplate 1234567891011121314151617181920212223242526@SpringBootTestclass Redis02SpringbootApplicationTests &#123; @Autowired private RedisTemplate redisTemplate; @Test void contextLoads() &#123; // redisTemplate 操作不同的数据类型，api和我们的指令是一样的 // opsForValue 操作字符串 类似String // opsForList 操作List 类似List // opsForHah // 除了基本的操作，我们常用的方法都可以直接通过redisTemplate操作，比如事务和基本的CRUD // 获取连接对象 //RedisConnection connection = redisTemplate.getConnectionFactory().getConnection(); //connection.flushDb(); //connection.flushAll(); redisTemplate.opsForValue().set(&quot;mykey&quot;,&quot;kuangshen&quot;); System.out.println(redisTemplate.opsForValue().get(&quot;mykey&quot;)); &#125;&#125; 测试结果 此时我们回到Redis查看数据时候，惊奇发现全是乱码，可是程序中可以正常输出： 这时候就关系到存储对象的序列化问题，在网络中传输的对象也是一样需要序列化，否者就全是乱码。 我们转到看那个默认的RedisTemplate内部什么样子： 在最开始就能看到几个关于序列化的参数。 默认的序列化器是采用JDK序列化器 而默认的RedisTemplate中的所有序列化器都是使用这个序列化器： 后续我们定制RedisTemplate就可以对其进行修改。 RedisSerializer提供了多种序列化方案： 直接调用RedisSerializer的静态方法来返回序列化器，然后set 自己new 相应的实现类，然后set 定制RedisTemplate的模板： 我们创建一个Bean加入容器，就会触发RedisTemplate上的条件注解使默认的RedisTemplate失效。 123456789101112131415161718192021222324@Configurationpublic class RedisConfig &#123; @Bean public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) throws UnknownHostException &#123; // 将template 泛型设置为 &lt;String, Object&gt; RedisTemplate&lt;String, Object&gt; template = new RedisTemplate(); // 连接工厂，不必修改 template.setConnectionFactory(redisConnectionFactory); /* * 序列化设置 */ // key、hash的key 采用 String序列化方式 template.setKeySerializer(RedisSerializer.string()); template.setHashKeySerializer(RedisSerializer.string()); // value、hash的value 采用 Jackson 序列化方式 template.setValueSerializer(RedisSerializer.json()); template.setHashValueSerializer(RedisSerializer.json()); template.afterPropertiesSet(); return template; &#125;&#125; 这样一来，只要实体类进行了序列化，我们存什么都不会有乱码的担忧了。 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-oc8kJP08-1597890996523)(狂神说 Redis.assets/image-20200817175638086.png)] 八、自定义Redis工具类使用RedisTemplate需要频繁调用.opForxxx然后才能进行对应的操作，这样使用起来代码效率低下，工作中一般不会这样使用，而是将这些常用的公共API抽取出来封装成为一个工具类，然后直接使用工具类来间接操作Redis,不但效率高并且易用。 工具类参考博客： https://www.cnblogs.com/zeng1994/p/03303c805731afc9aa9c60dbbd32a323.html https://www.cnblogs.com/zhzhlong/p/11434284.html 九、Redis.conf 容量单位不区分大小写，G和GB有区别 可以使用 include 组合多个配置问题 网络配置 日志输出级别 日志输出文件 持久化规则 由于Redis是基于内存的数据库，需要将数据由内存持久化到文件中 持久化方式： RDB AOF RDB文件相关 主从复制 Security模块中进行密码设置 客户端连接相关 1234maxclients 10000 最大客户端数量maxmemory &lt;bytes&gt; 最大内存限制maxmemory-policy noeviction # 内存达到限制值的处理策略 redis 中的默认的过期策略是 volatile-lru 。 设置方式 123config set maxmemory-policy volatile-lru 1 maxmemory-policy 六种方式1、volatile-lru：只对设置了过期时间的key进行LRU（默认值） 2、allkeys-lru ： 删除lru算法的key 3、volatile-random：随机删除即将过期key 4、allkeys-random：随机删除 5、volatile-ttl ： 删除即将过期的 6、noeviction ： 永不过期，返回错误 AOF相关部分 十、持久化—RDBRDB：Redis Databases [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-C0mm1D4A-1597890996524)(狂神说 Redis.assets/image-20200818122236614.png)] 什么是RDB 在指定时间间隔后，将内存中的数据集快照写入数据库 ；在恢复时候，直接读取快照文件，进行数据的恢复 ； 默认情况下， Redis 将数据库快照保存在名字为 dump.rdb的二进制文件中。文件名可以在配置文件中进行自定义。 工作原理 在进行 RDB 的时候，**redis** 的主线程是不会做 io 操作的，主线程会 fork 一个子线程来完成该操作； Redis 调用forks。同时拥有父进程和子进程。 子进程将数据集写入到一个临时 RDB 文件中。 当子进程完成对新 RDB 文件的写入时，Redis 用新 RDB 文件替换原来的 RDB 文件，并删除旧的 RDB 文件。 这种工作方式使得 Redis 可以从写时复制（copy-on-write）机制中获益(因为是使用子进程进行写操作，而父进程依然可以接收来自客户端的请求。) 触发机制 save的规则满足的情况下，会自动触发rdb原则 执行flushall命令，也会触发我们的rdb原则 退出redis，也会自动产生rdb文件 save使用 save 命令，会立刻对当前内存中的数据进行持久化 ,但是会阻塞，也就是不接受其他操作了； 由于 save 命令是同步命令，会占用Redis的主进程。若Redis数据非常多时，save命令执行速度会非常慢，阻塞所有客户端的请求。 flushall命令flushall 命令也会触发持久化 ； 触发持久化规则满足配置条件中的触发条件 ； 可以通过配置文件对 Redis 进行设置， 让它在“ N 秒内数据集至少有 M 个改动”这一条件被满足时， 自动进行数据集保存操作。 bgsavebgsave 是异步进行，进行持久化的时候，redis 还可以将继续响应客户端请求 ； bgsave和save对比 命令 save bgsave IO类型 同步 异步 阻塞？ 是 是（阻塞发生在fock()，通常非常快） 复杂度 O(n) O(n) 优点 不会消耗额外的内存 不阻塞客户端命令 缺点 阻塞客户端命令 需要fock子进程，消耗内存 优缺点优点： 适合大规模的数据恢复 对数据的完整性要求不高 缺点： 需要一定的时间间隔进行操作，如果redis意外宕机了，这个最后一次修改的数据就没有了。 fork进程的时候，会占用一定的内容空间。 十一、持久化AOFAppend Only File 将我们所有的命令都记录下来，history，恢复的时候就把这个文件全部再执行一遍 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-Z8wr9lBW-1597890996525)(狂神说 Redis.assets/image-20200818123711375.png)] 以日志的形式来记录每个写的操作，将Redis执行过的所有指令记录下来（读操作不记录），只许追加文件但不可以改写文件，redis启动之初会读取该文件重新构建数据，换言之，redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。 什么是AOF 快照功能（RDB）并不是非常耐久（durable）： 如果 Redis 因为某些原因而造成故障停机， 那么服务器将丢失最近写入、以及未保存到快照中的那些数据。 从 1.1 版本开始， Redis 增加了一种完全耐久的持久化方式： AOF 持久化。 如果要使用AOF，需要修改配置文件： appendonly no yes则表示启用AOF 默认是不开启的，我们需要手动配置，然后重启redis，就可以生效了！ 如果这个aof文件有错位，这时候redis是启动不起来的，我需要修改这个aof文件 redis给我们提供了一个工具redis-check-aof --fix 优点和缺点 1234567appendonly yes # 默认是不开启aof模式的，默认是使用rdb方式持久化的，在大部分的情况下，rdb完全够用appendfilename &quot;appendonly.aof&quot;# appendfsync always # 每次修改都会sync 消耗性能appendfsync everysec # 每秒执行一次 sync 可能会丢失这一秒的数据# appendfsync no # 不执行 sync ,这时候操作系统自己同步数据，速度最快 优点 每一次修改都会同步，文件的完整性会更加好 没秒同步一次，可能会丢失一秒的数据 从不同步，效率最高 缺点 相对于数据文件来说，aof远远大于rdb，修复速度比rdb慢！ Aof运行效率也要比rdb慢，所以我们redis默认的配置就是rdb持久化 十二、RDB和AOP选择RDB 和 AOF 对比 RDB AOF 启动优先级 低 高 体积 小 大 恢复速度 快 慢 数据安全性 丢数据 根据策略决定 如何选择使用哪种持久化方式？一般来说， 如果想达到足以媲美 PostgreSQL 的数据安全性， 你应该同时使用两种持久化功能。 如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失， 那么你可以只使用 RDB 持久化。 有很多用户都只使用 AOF 持久化， 但并不推荐这种方式： 因为定时生成 RDB 快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快。 十三、Redis发布与订阅Redis 发布订阅(pub/sub)是一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息。 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-IBT2pjCa-1597890996526)(狂神说 Redis.assets/image-20200818162849693.png)] 下图展示了频道 channel1 ， 以及订阅这个频道的三个客户端 —— client2 、 client5 和 client1 之间的关系： 当有新消息通过 PUBLISH 命令发送给频道 channel1 时， 这个消息就会被发送给订阅它的三个客户端： 命令 命令 描述 PSUBSCRIBE pattern [pattern..] 订阅一个或多个符合给定模式的频道。 PUNSUBSCRIBE pattern [pattern..] 退订一个或多个符合给定模式的频道。 PUBSUB subcommand [argument[argument]] 查看订阅与发布系统状态。 PUBLISH channel message 向指定频道发布消息 SUBSCRIBE channel [channel..] 订阅给定的一个或多个频道。 SUBSCRIBE channel [channel..] 退订一个或多个频道 示例1234567891011121314151617181920212223------------订阅端----------------------127.0.0.1:6379&gt; SUBSCRIBE sakura # 订阅sakura频道Reading messages... (press Ctrl-C to quit) # 等待接收消息1) &quot;subscribe&quot; # 订阅成功的消息2) &quot;sakura&quot;3) (integer) 11) &quot;message&quot; # 接收到来自sakura频道的消息 &quot;hello world&quot;2) &quot;sakura&quot;3) &quot;hello world&quot;1) &quot;message&quot; # 接收到来自sakura频道的消息 &quot;hello i am sakura&quot;2) &quot;sakura&quot;3) &quot;hello i am sakura&quot;--------------消息发布端-------------------127.0.0.1:6379&gt; PUBLISH sakura &quot;hello world&quot; # 发布消息到sakura频道(integer) 1127.0.0.1:6379&gt; PUBLISH sakura &quot;hello i am sakura&quot; # 发布消息(integer) 1-----------------查看活跃的频道------------127.0.0.1:6379&gt; PUBSUB channels1) &quot;sakura&quot; 原理每个 Redis 服务器进程都维持着一个表示服务器状态的 redis.h/redisServer 结构， 结构的 pubsub_channels 属性是一个字典， 这个字典就用于保存订阅频道的信息，其中，字典的键为正在被订阅的频道， 而字典的值则是一个链表， 链表中保存了所有订阅这个频道的客户端。 客户端订阅，就被链接到对应频道的链表的尾部，退订则就是将客户端节点从链表中移除。 缺点 如果一个客户端订阅了频道，但自己读取消息的速度却不够快的话，那么不断积压的消息会使redis输出缓冲区的体积变得越来越大，这可能使得redis本身的速度变慢，甚至直接崩溃。 这和数据传输可靠性有关，如果在订阅方断线，那么他将会丢失所有在短线期间发布者发布的消息。 应用 消息订阅：公众号订阅，微博关注等等（起始更多是使用消息队列来进行实现） 多人在线聊天室。 稍微复杂的场景，我们就会使用消息中间件MQ处理。 十四、Redis主从复制概念 主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点（Master/Leader）,后者称为从节点（Slave/Follower）， 数据的复制是单向的！只能由主节点复制到从节点（主节点以写为主、从节点以读为主）。 默认情况下，每台Redis服务器都是主节点，一个主节点可以有0个或者多个从节点，但每个从节点只能由一个主节点。 作用 数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余的方式。 故障恢复：当主节点故障时，从节点可以暂时替代主节点提供服务，是一种服务冗余的方式 负载均衡：在主从复制的基础上，配合读写分离，由主节点进行写操作，从节点进行读操作，分担服务器的负载；尤其是在多读少写的场景下，通过多个从节点分担负载，提高并发量。 高可用基石：主从复制还是哨兵和集群能够实施的基础。 为什么使用集群 单台服务器难以负载大量的请求 单台服务器故障率高，系统崩坏概率大 单台服务器内存容量有限。 环境配置我们在讲解配置文件的时候，注意到有一个replication模块 (见Redis.conf中第8条) 查看当前库的信息：info replication 12345678910111213127.0.0.1:6379&gt; info replication# Replicationrole:master # 角色connected_slaves:0 # 从机数量master_replid:3b54deef5b7b7b7f7dd8acefa23be48879b4fcffmaster_replid2:0000000000000000000000000000000000000000master_repl_offset:0second_repl_offset:-1repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0 既然需要启动多个服务，就需要多个配置文件。每个配置文件对应修改以下信息： 端口号 pid文件名 日志文件名 rdb文件名 启动单机多服务集群： 一主二从配置==默认情况下，每台Redis服务器都是主节点；==我们一般情况下只用配置从机就好了！ 认老大！一主（79）二从（80，81） 使用SLAVEOF host port就可以为从机配置主机了。 然后主机上也能看到从机的状态： 我们这里是使用命令搭建，是暂时的，==真实开发中应该在从机的配置文件中进行配置，==这样的话是永久的。 使用规则 从机只能读，不能写，主机可读可写但是多用于写。 12345678910 127.0.0.1:6381&gt; set name sakura # 从机6381写入失败(error) READONLY You can&#x27;t write against a read only replica.127.0.0.1:6380&gt; set name sakura # 从机6380写入失败(error) READONLY You can&#x27;t write against a read only replica.127.0.0.1:6379&gt; set name sakuraOK127.0.0.1:6379&gt; get name&quot;sakura&quot; 当主机断电宕机后，默认情况下从机的角色不会发生变化 ，集群中只是失去了写操作，当主机恢复以后，又会连接上从机恢复原状。 当从机断电宕机后，若不是使用配置文件配置的从机，再次启动后作为主机是无法获取之前主机的数据的，若此时重新配置称为从机，又可以获取到主机的所有数据。这里就要提到一个同步原理。 第二条中提到，默认情况下，主机故障后，不会出现新的主机，有两种方式可以产生新的主机： 从机手动执行命令slaveof no one,这样执行以后从机会独立出来成为一个主机 使用哨兵模式（自动选举） 如果没有老大了，这个时候能不能选择出来一个老大呢？手动！ 如果主机断开了连接，我们可以使用SLAVEOF no one让自己变成主机！其他的节点就可以手动连接到最新的主节点（手动）！如果这个时候老大修复了，那么久重新连接！ 十五、哨兵模式更多信息参考博客：https://www.jianshu.com/p/06ab9daf921d 主从切换技术的方法是：当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间内服务不可用。这不是一种推荐的方式，更多时候，我们优先考虑哨兵模式。 单机单个哨兵 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-2ENYVAPp-1597890996527)(狂神说 Redis.assets/image-20200818233231154.png)] 哨兵的作用： 通过发送命令，让Redis服务器返回监控其运行状态，包括主服务器和从服务器。 当哨兵监测到master宕机，会自动将slave切换成master，然后通过发布订阅模式通知其他的从服务器，修改配置文件，让它们切换主机。 多哨兵模式 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-Ga1RyfVc-1597890996528)(狂神说 Redis.assets/image-20200818233316478.png)] 哨兵的核心配置 12sentinel monitor mymaster 127.0.0.1 6379 1 数字1表示 ：当一个哨兵主观认为主机断开，就可以客观认为主机故障，然后开始选举新的主机。 测试 12redis-sentinel xxx&#x2F;sentinel.conf 成功启动哨兵模式 此时哨兵监视着我们的主机6379，当我们断开主机后： 哨兵模式优缺点 优点： 哨兵集群，基于主从复制模式，所有主从复制的优点，它都有 主从可以切换，故障可以转移，系统的可用性更好 哨兵模式是主从模式的升级，手动到自动，更加健壮 缺点： Redis不好在线扩容，集群容量一旦达到上限，在线扩容就十分麻烦 实现哨兵模式的配置其实是很麻烦的，里面有很多配置项 哨兵模式的全部配置 完整的哨兵模式配置文件 sentinel.conf 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970# Example sentinel.conf # 哨兵sentinel实例运行的端口 默认26379port 26379 # 哨兵sentinel的工作目录dir /tmp # 哨兵sentinel监控的redis主节点的 ip port # master-name 可以自己命名的主节点名字 只能由字母A-z、数字0-9 、这三个字符&quot;.-_&quot;组成。# quorum 当这些quorum个数sentinel哨兵认为master主节点失联 那么这时 客观上认为主节点失联了# sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt;sentinel monitor mymaster 127.0.0.1 6379 1 # 当在Redis实例中开启了requirepass foobared 授权密码 这样所有连接Redis实例的客户端都要提供密码# 设置哨兵sentinel 连接主从的密码 注意必须为主从设置一样的验证密码# sentinel auth-pass &lt;master-name&gt; &lt;password&gt;sentinel auth-pass mymaster MySUPER--secret-0123passw0rd # 指定多少毫秒之后 主节点没有应答哨兵sentinel 此时 哨兵主观上认为主节点下线 默认30秒# sentinel down-after-milliseconds &lt;master-name&gt; &lt;milliseconds&gt;sentinel down-after-milliseconds mymaster 30000 # 这个配置项指定了在发生failover主备切换时最多可以有多少个slave同时对新的master进行 同步，这个数字越小，完成failover所需的时间就越长，但是如果这个数字越大，就意味着越 多的slave因为replication而不可用。可以通过将这个值设为 1 来保证每次只有一个slave 处于不能处理命令请求的状态。# sentinel parallel-syncs &lt;master-name&gt; &lt;numslaves&gt;sentinel parallel-syncs mymaster 1 # 故障转移的超时时间 failover-timeout 可以用在以下这些方面： #1. 同一个sentinel对同一个master两次failover之间的间隔时间。#2. 当一个slave从一个错误的master那里同步数据开始计算时间。直到slave被纠正为向正确的master那里同步数据时。#3.当想要取消一个正在进行的failover所需要的时间。 #4.当进行failover时，配置所有slaves指向新的master所需的最大时间。不过，即使过了这个超时，slaves依然会被正确配置为指向master，但是就不按parallel-syncs所配置的规则来了# 默认三分钟# sentinel failover-timeout &lt;master-name&gt; &lt;milliseconds&gt;sentinel failover-timeout mymaster 180000 # SCRIPTS EXECUTION #配置当某一事件发生时所需要执行的脚本，可以通过脚本来通知管理员，例如当系统运行不正常时发邮件通知相关人员。#对于脚本的运行结果有以下规则：#若脚本执行后返回1，那么该脚本稍后将会被再次执行，重复次数目前默认为10#若脚本执行后返回2，或者比2更高的一个返回值，脚本将不会重复执行。#如果脚本在执行过程中由于收到系统中断信号被终止了，则同返回值为1时的行为相同。#一个脚本的最大执行时间为60s，如果超过这个时间，脚本将会被一个SIGKILL信号终止，之后重新执行。 #通知型脚本:当sentinel有任何警告级别的事件发生时（比如说redis实例的主观失效和客观失效等等），将会去调用这个脚本，#这时这个脚本应该通过邮件，SMS等方式去通知系统管理员关于系统不正常运行的信息。调用该脚本时，将传给脚本两个参数，#一个是事件的类型，#一个是事件的描述。#如果sentinel.conf配置文件中配置了这个脚本路径，那么必须保证这个脚本存在于这个路径，并且是可执行的，否则sentinel无法正常启动成功。#通知脚本# sentinel notification-script &lt;master-name&gt; &lt;script-path&gt; sentinel notification-script mymaster /var/redis/notify.sh # 客户端重新配置主节点参数脚本# 当一个master由于failover而发生改变时，这个脚本将会被调用，通知相关的客户端关于master地址已经发生改变的信息。# 以下参数将会在调用脚本时传给脚本:# &lt;master-name&gt; &lt;role&gt; &lt;state&gt; &lt;from-ip&gt; &lt;from-port&gt; &lt;to-ip&gt; &lt;to-port&gt;# 目前&lt;state&gt;总是“failover”,# &lt;role&gt;是“leader”或者“observer”中的一个。 # 参数 from-ip, from-port, to-ip, to-port是用来和旧的master和新的master(即旧的slave)通信的# 这个脚本应该是通用的，能被多次调用，不是针对性的。# sentinel client-reconfig-script &lt;master-name&gt; &lt;script-path&gt;sentinel client-reconfig-script mymaster /var/redis/reconfig.sh 十六、缓存穿透与雪崩缓存穿透（查不到） 概念 在默认情况下，用户请求数据时，会先在缓存(Redis)中查找，若没找到即缓存未命中，再在数据库中进行查找，数量少可能问题不大，可是一旦大量的请求数据（例如秒杀场景）缓存都没有命中的话，就会全部转移到数据库上，造成数据库极大的压力，就有可能导致数据库崩溃。网络安全中也有人恶意使用这种手段进行攻击被称为洪水攻击。 解决方案 布隆过滤器 对所有可能查询的参数以Hash的形式存储，以便快速确定是否存在这个值，在控制层先进行拦截校验，校验不通过直接打回，减轻了存储系统的压力。 缓存空对象 一次请求若在缓存和数据库中都没找到，就在缓存中方一个空对象用于处理后续这个请求。 这样做有一个缺陷：存储空对象也需要空间，大量的空对象会耗费一定的空间，存储效率并不高。解决这个缺陷的方式就是设置较短过期时间 即使对空值设置了过期时间，还是会存在缓存层和存储层的数据会有一段时间窗口的不一致，这对于需要保持一致性的业务会有影响。 缓存击穿（量太大，缓存过期） 概念 相较于缓存穿透，缓存击穿的目的性更强，一个存在的key，在缓存过期的一刻，同时有大量的请求，这些请求都会击穿到DB，造成瞬时DB请求量大、压力骤增。这就是缓存被击穿，只是针对其中某个key的缓存不可用而导致击穿，但是其他的key依然可以使用缓存响应。 比如热搜排行上，一个热点新闻被同时大量访问就可能导致缓存击穿。 解决方案 设置热点数据永不过期 这样就不会出现热点数据过期的情况，但是当Redis内存空间满的时候也会清理部分数据，而且此种方案会占用空间，一旦热点数据多了起来，就会占用部分空间。 加互斥锁(分布式锁) 在访问key之前，采用SETNX（set if not exists）来设置另一个短期key来锁住当前key的访问，访问结束再删除该短期key。保证同时刻只有一个线程访问。这样对锁的要求就十分高。 缓存雪崩 概念 大量的key设置了相同的过期时间，导致在缓存在同一时刻全部失效，造成瞬时DB请求量大、压力骤增，引起雪崩。 解决方案 redis高可用 这个思想的含义是，既然redis有可能挂掉，那我多增设几台redis，这样一台挂掉之后其他的还可以继续工作，其实就是搭建的集群 限流降级 这个解决方案的思想是，在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。 数据预热 数据加热的含义就是在正式部署之前，我先把可能的数据先预先访问一遍，这样部分可能大量访问的数据就会加载到缓存中。在即将发生大并发访问前手动触发加载缓存不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀。","categories":[],"tags":[{"name":"Redis","slug":"Redis","permalink":"http://www.xc234.ltd/tags/Redis/"}]},{"title":"springcloud笔记","slug":"springcloud笔记","date":"2021-01-13T09:54:27.000Z","updated":"2022-03-29T02:23:40.773Z","comments":true,"path":"2021/01/13/springcloud笔记/","link":"","permalink":"http://www.xc234.ltd/2021/01/13/springcloud%E7%AC%94%E8%AE%B0/","excerpt":"","text":"1、前言1.1、回顾回顾之前的知识 JavaSE 数据库 前端 Servlet Http Mybatis Spring SpringMVC SpringBoot Dubbo、Zookeeper、分布式基础 Maven、Git Ajax、Json … 串一下自己会的东西 数据库 Mybatis Spring SpringMVC SpringBoot Dubbo、Zookeeper、分布式基础 Maven、Git Ajax、Json 这个阶段该如何学习 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051三层架构 + MVC框架： Spring IOC AOP SpringBoot：新一代的javaEE开发标准，自动装配 模块化 all in one 模块化的开发&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;all in one 代码没有变化 微服务的四个核心问题？ 1.服务很多，客户端怎么访问？ 2.这么多服务？服务之间如何通信？ 3.这么多服务？如何治理？ 4.服务挂了怎么办？ 解决方案： Spring Cloud 生态！ SprintBoot 1.Spring Cloud NetFlix 一站式解决方案 api网关：zuul组件 通信：Feign ---- HttpClient ---- Http通信方式,同步,阻塞 服务注册和发现：Eureka 熔断机制：Hystrix ...... 2. Apache Dubbo Zookeeper：半自动！需要整合别人的 API网关：没有,找第三方组件(比如整合zull组件),或者自己实现 通信：Dubbo 是一个基于Java的高性能的RPC通信框架(性能比Feign强大) 服务注册和发现：Zookeeper 熔断机制：没有,需要借助Hystrix Dubbo这个方案并不完善 3. Spring Cloud Alibaba：目前最新的一站式解决方案！可解决上述4个核心问题,更简单 API网关： 通信： 服务注册和发现： 熔断机制： 新概念：服务网格~ Server Mesh istio 万变不离其宗4个问题： 1. API网关 2. HTTP,RPC通信 3. 注册和发现 4. 熔断机制 网络不可靠！ 1.2 、常见面试题1.1、 什么是微服务？ 1.2 、微服务之间是如何独立通讯的？ 1.3 、SpringCloud 和 Dubbo有那些区别？ 1.4 、SpringBoot 和 SpringCloud，请谈谈你对他们的理解 1.5 、什么是服务熔断？什么是服务降级？ 1.6 、微服务的优缺点分别是什么？说下你在项目开发中遇到的坑 1.7 、你所知道的微服务技术栈有哪些？列举一二 1.8、 Eureka和Zookeeper都可以提供服务注册与发现的功能，请说说两者的区别 2. 微服务概述2.1 什么是微服务？什么是微服务？微服务(Microservice Architecture) 是近几年流行的一种架构思想，关于它的概念很难一言以蔽之。 究竟什么是微服务呢？我们在此引用ThoughtWorks 公司的首席科学家 Martin Fowler 于2014年提出的一段话： 原文：https://martinfowler.com/articles/microservices.html 汉化：https://www.cnblogs.com/liuning8023/p/4493156.html 就目前而言，对于微服务，业界并没有一个统一的，标准的定义。 但通常而言，微服务架构是一种架构模式，或者说是一种架构风。格，它体长将单一的应用程序划分成一组小的服务，每个服务运行在其独立的自己的进程内，服务之间互相协调，互相配置，为用户提供最终价值，服务之间采用轻量级的通信机制(HTTP)互相沟通，每个服务都围绕着具体的业务进行构建，并且能狗被独立的部署到生产环境中，另外，应尽量避免统一的，集中式的服务管理机制，对具体的一个服务而言，应该根据业务上下文，选择合适的语言，工具(Maven)对其进行构建，可以有一个非常轻量级的集中式管理来协调这些服务，可以使用不同的语言来编写服务，也可以使用不同的数据存储。 再来从技术维度角度理解下： 微服务化的核心就是将传统的一站式应用，根据业务拆分成一个一个的服务，彻底地去耦合，每一个微服务提供单个业务功能的服务，一个服务做一件事情，从技术角度看就是一种小而独立的处理过程，类似进程的概念，能够自行单独启动或销毁，拥有自己独立的数据库。 2.2 微服务与微服务架构微服务 强调的是服务的大小，它关注的是某一个点，是具体解决某一个问题/提供落地对应服务的一个服务应用，狭义的看，可以看作是IDEA中的一个个微服务工程，或者Moudel。 12IDEA 工具里面使用Maven开发的一个个独立的小Moudel，它具体是使用SpringBoot开发的一个小模块，专业的事情交给专业的模块来做，一个模块就做着一件事情。强调的是一个个的个体，每个个体完成一个具体的任务或者功能。 微服务架构 一种新的架构形式，Martin Fowler 于2014年提出。 微服务架构是一种架构模式，它体长将单一应用程序划分成一组小的服务，服务之间相互协调，互相配合，为用户提供最终价值。每个服务运行在其独立的进程中，服务与服务之间采用轻量级的通信机制**(如HTTP)互相协作，每个服务都围绕着具体的业务进行构建，并且能够被独立的部署到生产环境中，另外，应尽量避免统一的，集中式的服务管理机制，对具体的一个服务而言，应根据业务上下文，选择合适的语言、工具(如Maven)**对其进行构建。 2.3 微服务优缺点优点 单一职责原则； 每个服务足够内聚，足够小，代码容易理解，这样能聚焦一个指定的业务功能或业务需求； 开发简单，开发效率高，一个服务可能就是专一的只干一件事； 微服务能够被小团队单独开发，这个团队只需2-5个开发人员组成； 微服务是松耦合的，是有功能意义的服务，无论是在开发阶段或部署阶段都是独立的； 微服务能使用不同的语言开发； 易于和第三方集成，微服务允许容易且灵活的方式集成自动部署，通过持续集成工具，如jenkins，Hudson，bamboo； 微服务易于被一个开发人员理解，修改和维护，这样小团队能够更关注自己的工作成果，无需通过合作才能体现价值； 微服务允许利用和融合最新技术； 微服务只是业务逻辑的代码，不会和HTML，CSS，或其他的界面混合; 每个微服务都有自己的存储能力，可以有自己的数据库，也可以有统一的数据库； 缺点 开发人员要处理分布式系统的复杂性； 多服务运维难度，随着服务的增加，运维的压力也在增大； 系统部署依赖问题； 服务间通信成本问题； 数据一致性问题； 系统集成测试问题； 性能和监控问题； 2.4 微服务技术栈有那些？ 微服务技术条目 落地技术 服务开发 SpringBoot、Spring、SpringMVC等 服务配置与管理 Netfix公司的Archaius、阿里的Diamond等 服务注册与发现 Eureka、Consul、Zookeeper等 服务调用 Rest、PRC、gRPC 服务熔断器 Hystrix、Envoy等 负载均衡 Ribbon、Nginx等 服务接口调用(客户端调用服务的简化工具) Fegin等 消息队列 Kafka、RabbitMQ、ActiveMQ等 服务配置中心管理 SpringCloudConfig、Chef等 服务路由(API网关) Zuul等 服务监控 Zabbix、Nagios、Metrics、Specatator等 全链路追踪 Zipkin、Brave、Dapper等 数据流操作开发包 SpringCloud Stream(封装与Redis，Rabbit，Kafka等发送接收消息) 时间消息总栈 SpringCloud Bus 服务部署 Docker、OpenStack、Kubernetes等 2.5 为什么选择SpringCloud作为微服务架构 选型依据 整体解决方案和框架成熟度 社区热度 可维护性 学习曲线 当前各大IT公司用的微服务架构有那些？ 阿里：dubbo+HFS 京东：JFS 新浪：Motan 当当网：DubboX … 各微服务框架对比 功能点/服务框架 Netflix/SpringCloud Motan gRPC Thrift Dubbo/DubboX 功能定位 完整的微服务框架 RPC框架，但整合了ZK或Consul，实现集群环境的基本服务注册发现 RPC框架 RPC框架 服务框架 支持Rest 是，Ribbon支持多种可拔插的序列号选择 否 否 否 否 支持RPC 否 是(Hession2) 是 是 是 支持多语言 是(Rest形式) 否 是 是 否 负载均衡 是(服务端zuul+客户端Ribbon)，zuul-服务，动态路由，云端负载均衡Eureka（针对中间层服务器） 是(客户端) 否 否 是(客户端) 配置服务 Netfix Archaius，Spring Cloud Config Server 集中配置 是(Zookeeper提供) 否 否 否 服务调用链监控 是(zuul)，zuul提供边缘服务，API网关 否 否 否 否 高可用/容错 是(服务端Hystrix+客户端Ribbon) 是(客户端) 否 否 是(客户端) 典型应用案例 Netflix Sina Google Facebook 社区活跃程度 高 一般 高 一般 2017年后重新开始维护，之前中断了5年 学习难度 中等 低 高 高 低 文档丰富程度 高 一般 一般 一般 高 其他 Spring Cloud Bus为我们的应用程序带来了更多管理端点 支持降级 Netflix内部在开发集成gRPC IDL定义 实践的公司比较多 3. SpringCloud入门概述3.1 SpringCloud是什么？Spring官网：https://spring.io/ 原文 Spring Cloud provides tools for developers to quickly build some of the common patterns in distributed systems (e.g. configuration management, service discovery, circuit breakers, intelligent routing, micro-proxy, control bus, one-time tokens, global locks, leadership election, distributed sessions, cluster state). Coordination of distributed systems leads to boiler plate patterns, and using Spring Cloud developers can quickly stand up services and applications that implement those patterns. They will work well in any distributed environment, including the developer’s own laptop, bare metal data centres, and managed platforms such as Cloud Foundry. 翻译：SpringCloud,基于SpringBoot提供了一套微服务解决方案，包括服务注册与发现，配置中心，全链路监控，服务网关，负载均衡，熔断器等组件，除了基于NetFlix的开源组件做高度抽象封装之外，还有一些选型中立的开源组件。 SpringCloud利用SpringBoot的开发便利性，巧妙地简化了分布式系统基础设施的开发，SpringCloud为开发人员提供了快速构建分布式系统的一些工具，包括配置管理，服务发现，断路器，路由，微代理，事件总线，全局锁，决策竞选，分布式会话等等，他们都可以用SpringBoot的开发风格做到一键启动和部署。 SpringBoot并没有重复造轮子，它只是将目前各家公司开发的比较成熟，经得起实际考研的服务框架组合起来，通过SpringBoot风格进行再封装，屏蔽掉了复杂的配置和实现原理，最终给开发者留出了一套简单易懂，易部署和易维护的分布式系统开发工具包 SpringCloud是分布式微服务架构下的一站式解决方案，是各个微服务架构落地技术的集合体，俗称微服务全家桶。 3.2 SpringCloud和SpringBoot的关系 SpringBoot专注于开苏方便的开发单个个体微服务； SpringCloud是关注全局的微服务协调整理治理框架，它将SpringBoot开发的一个个单体微服务，整合并管理起来，为各个微服务之间提供：配置管理、服务发现、断路器、路由、为代理、事件总栈、全局锁、决策竞选、分布式会话等等集成服务； SpringBoot可以离开SpringCloud独立使用，开发项目，但SpringCloud离不开SpringBoot，属于依赖关系； SpringBoot专注于快速、方便的开发单个个体微服务，SpringCloud关注全局的服务治理框架； 3.3 Dubbo 和 SpringCloud技术选型1. 分布式+服务治理Dubbo 目前成熟的互联网架构，应用服务化拆分+消息中间件 2. Dubbo 和 SpringCloud对比 可以看一下社区活跃度： https://github.com/dubbo https://github.com/spring-cloud 对比结果： Dubbo SpringCloud 服务注册中心 Zookeeper Spring Cloud Netfilx Eureka 服务调用方式 RPC REST API 服务监控 Dubbo-monitor Spring Boot Admin 断路器 不完善 Spring Cloud Netfilx Hystrix 服务网关 无 Spring Cloud Netfilx Zuul 分布式配置 无 Spring Cloud Config 服务跟踪 无 Spring Cloud Sleuth 消息总栈 无 Spring Cloud Bus 数据流 无 Spring Cloud Stream 批量任务 无 Spring Cloud Task 最大区别：Spring Cloud 抛弃了Dubbo的RPC通信，采用的是基于HTTP的REST方式 严格来说，这两种方式各有优劣。虽然从一定程度上来说，后者牺牲了服务调用的性能，但也避免了上面提到的原生RPC带来的问题。而且REST相比RPC更为灵活，服务提供方和调用方的依赖只依靠一纸契约，不存在代码级别的强依赖，这个优点在当下强调快速演化的微服务环境下，显得更加合适。 品牌机和组装机的区别 很明显，Spring Cloud的功能比DUBBO更加强大，涵盖面更广，而且作为Spring的拳头项目，它也能够与SpringFramework、Spring Boot、Spring Data、Spring Batch等其他Spring项目完美融合，这些对于微服务而言是至关重要的。使用Dubbo构建的微服务架构就像组装电脑，各环节我们的选择自由度很高，但是最终结果很有可能因为一条内存质量不行就点不亮了，总是让人不怎么放心，但是如果你是一名高手，那这些都不是问题;而SpringCloud就像品牌机，在Spring Source的整合下，做了大量的兼容性测试，保证了机器拥有更高的稳定性，但是如果要在使用非原装组件外的东西，就需要对其基础有足够的了解。 社区支持与更新力度的区别 最为重要的是，DUBBO停止了5年左右的更新，虽然2017.7重启了。对于技术发展的新需求，需要由开发者自行拓展升级（比如当当网弄出了DubboX)，这对于很多想要采用微服务架构的中小软件组织，显然是不太合适的，中小公司没有这么强大的技术能力去修改Dubbo源码+周边的一整套解决方案，并不是每一个公司都有阿里的大牛+真实的线上生产环境测试过。 设计模式+微服务拆分思想：不一定善于表达，软实力 总结： 二者解决的问题域不一样：Dubbo的定位是一款RPC框架，而SpringCloud的目标是微服务架构下的一站式解决方案。 3.4 SpringCloud能干嘛？ Distributed/versioned configuration 分布式/版本控制配置 Service registration and discovery 服务注册与发现 Routing 路由 Service-to-service calls 服务到服务的调用 Load balancing 负载均衡配置 Circuit Breakers 断路器 Distributed messaging 分布式消息管理 … 3.5 SpringCloud下载官网：http://projects.spring.io/spring-cloud/ 版本号有点特别： spring cloud是一个由众多独立子项目组成的大型综合项目，每个子项目有不同的发行节奏，都维护着自己的发布版木号。spring cloud通过一个资源清单BOM(Bil1 of Materials）来管理每个版木的子项目清单。为避免与子项目的发布号混淆，所以没有采用版本号的方式，而是通过命名的方式。 SpringCloud没有采用数字编号的方式命名版本号，而是采用了伦敦地铁站的名称，同时根据字母表的顺序来对应版本时间顺序，比如最早的Realse版本：Angel，第二个Realse版本：Brixton，然后是Camden、Dalston、Edgware，目前最新的是Hoxton SR4 CURRENT GA通用稳定版。 自学参考书： SpringCloud Netflix 中文文档：https://springcloud.cc/spring-cloud-netflix.html SpringCloud 中文API文档(官方文档翻译版)：https://springcloud.cc/spring-cloud-dalston.html SpringCloud中国社区：http://springcloud.cn/ SpringCloud中文网：https://springcloud.cc 4. SpringCloud Rest学习环境搭建：服务提供者4.1 介绍 我们会使用一个Dept部门模块做一个微服务通用案例Consumer消费者(Client)通过REST调用Provider提供者(Server)提供的服务。 回顾Spring，SpringMVC，Mybatis等以往学习的知识。 Maven的分包分模块架构复习。 123456789101112一个简单的Maven模块结构是这样的：-- app-parent: 一个父项目(app-parent)聚合了很多子项目(app-util\\app-dao\\app-web...) |-- pom.xml | |-- app-core ||---- pom.xml | |-- app-web ||---- pom.xml ......1234567891011 一个父工程带着多个Moudule子模块 MicroServiceCloud父工程(Project)下初次带着3个子模块(Module) microservicecloud-api 【封装的整体entity/接口/公共配置等】 microservicecloud-consumer-dept-80 【服务提供者】 microservicecloud-provider-dept-8001 【服务消费者】 4.2 SpringCloud版本选择大版本说明 SpringBoot SpringCloud 关系 1.2.x Angel版本(天使) 兼容SpringBoot1.2x 1.3.x Brixton版本(布里克斯顿) 兼容SpringBoot1.3x，也兼容SpringBoot1.4x 1.4.x Camden版本(卡姆登) 兼容SpringBoot1.4x，也兼容SpringBoot1.5x 1.5.x Dalston版本(多尔斯顿) 兼容SpringBoot1.5x，不兼容SpringBoot2.0x 1.5.x Edgware版本(埃奇韦尔) 兼容SpringBoot1.5x，不兼容SpringBoot2.0x 2.0.x Finchley版本(芬奇利) 兼容SpringBoot2.0x，不兼容SpringBoot1.5x 2.1.x Greenwich版本(格林威治) 实际开发版本关系 spring-boot-starter-parent spring-cloud-dependencles 版本号 发布日期 版本号 发布日期 1.5.2.RELEASE 2017-03 Dalston.RC1 2017-x 1.5.9.RELEASE 2017-11 Edgware.RELEASE 2017-11 1.5.16.RELEASE 2018-04 Edgware.SR5 2018-10 1.5.20.RELEASE 2018-09 Edgware.SR5 2018-10 2.0.2.RELEASE 2018-05 Fomchiey.BULD-SNAPSHOT 2018-x 2.0.6.RELEASE 2018-10 Fomchiey-SR2 2018-10 2.1.4.RELEASE 2019-04 Greenwich.SR1 2019-03 使用后两个 4.3 创建工程1、创建父工程 新建父工程项目springcloud，切记Packageing是pom模式 主要是定义POM文件，将后续各个子模块公用的jar包等统一提取出来，类似一个抽象父类 父工程pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;nuc.ss&lt;/groupId&gt; &lt;artifactId&gt;springcloud&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;modules&gt; &lt;/modules&gt; &lt;!--打包方式 pom--&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;lombok.version&gt;1.18.12&lt;/lombok.version&gt; &lt;log4j.version&gt;1.2.17&lt;/log4j.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--springcloud的依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Hoxton.SR8&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--springboot的依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.3.1.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--数据库--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.20&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.0.9&lt;/version&gt; &lt;/dependency&gt; &lt;!--springboot启动器--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.3&lt;/version&gt; &lt;/dependency&gt; &lt;!--日志测试~--&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;version&gt;1.2.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;$&#123;junit.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;$&#123;log4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--lombok--&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;$&#123;lombok.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.yml&lt;/include&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.yml&lt;/include&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt;&lt;/project&gt; 2、创建子模块springcloud-api pom配置： 123456789101112131415161718192021&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud&lt;/artifactId&gt; &lt;groupId&gt;nuc.ss&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;sprintcloud-api&lt;/artifactId&gt; &lt;!--当前的module自己需要的依赖，如果父依赖中已经配置了版本，这里就不用写了--&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 数据库的创建 实体类的编写 1234567891011121314151617181920212223242526272829package nuc.ss.springcloud.pojo; import lombok.Data;import lombok.NoArgsConstructor;import lombok.experimental.Accessors;import java.io.Serializable; @Data@NoArgsConstructor@Accessors(chain = true)public class Dept implements Serializable &#123;//实体类 orm 类表关系映射 private long deptno;//主键 private String dname; //这个数据存在那个数据库的字段，微服务，一个服务对应一个数据库，同一个信息可能存在不同的数据库 private String db_source; public Dept(String dname) &#123; this.dname = dname; &#125; /* * 链式写法： * Dept dept = new Dept(); * * dept.setDeptNo(11).setDname(&#x27;ssss&#x27;).setDb_source(&#x27;db01&#x27;) * */&#125; 3、子模块springcloud-provider-dept-8081服务的提供者的编写 ​ pom配置： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud&lt;/artifactId&gt; &lt;groupId&gt;nuc.ss&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;springcloud-provider-dept-8081&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--我们需要拿到实体类，所以要配置api module--&gt; &lt;dependency&gt; &lt;groupId&gt;nuc.ss&lt;/groupId&gt; &lt;artifactId&gt;springcloud-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--junit--&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--test--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--jetty--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--热部署工具--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; application.yml的配置 12345678910111213141516171819server: port: 8081# mybatis的配置mybatis: type-aliases-package: nuc.ss.springcloud.pojo config-location: classpath:mybatis/mybatis-config.xml mapper-locations: classpath:mybatis/mapper/*.xml# spring的配置spring: application: name: springcloud-provider-dept datasource: type: com.alibaba.druid.pool.DruidDataSource #数据库 driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql//localhost:3306/db01?useUnicode=true&amp;characterEncoding=utf-8 username: root password: admin mybatis-config.xml的配置 1234567891011&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE configuration PUBLIC &quot;-//mybatis.org//DTD Config 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-config.dtd&quot;&gt;&lt;configuration&gt; &lt;settings&gt; &lt;setting name=&quot;cacheEnabled&quot; value=&quot;true&quot;/&gt; &lt;/settings&gt;&lt;/configuration&gt; DeptMapper.xml的编写 12345678910111213141516171819202122&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt;&lt;!DOCTYPE mapper PUBLIC &quot;-//mybatis.org//DTD Mapper 3.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-3-mapper.dtd&quot;&gt;&lt;mapper namespace=&quot;nuc.ss.springcloud.dao.DeptDao&quot;&gt; &lt;insert id=&quot;addDept&quot; parameterType=&quot;Dept&quot;&gt; insert into dept (dname,db_source) values (#&#123;dname&#125;,DATABASE()) &lt;/insert&gt; &lt;select id=&quot;queryById&quot; resultType=&quot;Dept&quot; parameterType=&quot;Long&quot;&gt; select * from dept where deptno = #&#123;id&#125; &lt;/select&gt; &lt;select id=&quot;queryAll&quot; resultType=&quot;Dept&quot;&gt; select * from dept &lt;/select&gt;&lt;/mapper&gt; 接口DeptController的编写 12345678910111213141516171819202122//视图Restful服务@RestControllerpublic class DeptController &#123; @Autowired DeptService deptService; @PostMapping(&quot;/dept/add&quot;) public boolean addDept(Dept dept) &#123; return deptService.addDept(dept); &#125; @GetMapping(&quot;/dept/get/&#123;id&#125;&quot;) public Dept get(@PathVariable(&quot;id&quot;) Long id) &#123; return deptService.queryById(id); &#125; @GetMapping(&quot;/dept/list&quot;) public List&lt;Dept&gt; queryAll() &#123; return deptService.queryAll(); &#125;&#125; 整体目录结构 4、子模块springcloud-consumer-dept-80的编写 pom依赖编写 123456789101112131415161718192021222324252627&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud&lt;/artifactId&gt; &lt;groupId&gt;nuc.ss&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;springcloud-consumer-dept-80&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;nuc.ss&lt;/groupId&gt; &lt;artifactId&gt;springcloud-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; application.yml 123server: port: 80 将RestTemplate注册到spring中：ConfigBean.java 123456789@Configurationpublic class ConfigBean &#123; //Cofiguration -- spring applicationContext.xml @Bean public RestTemplate getRestTemplate() &#123; return new RestTemplate(); &#125;&#125; DeptConsumerController.java 123456789101112131415161718192021222324252627@RestControllerpublic class DeptConsumerController &#123; // 理解：消费者，不应该有service层 // RestTemplate ... 供我们直接调用就可以了！注解到spring中 // (url,实体:Map, Class&lt;T&gt; responseType) @Autowired private RestTemplate restTemplate;//提供多种便捷访问Http的方法 private static final String REST_URL_PREFIX = &quot;http://localhost:8081&quot;; @RequestMapping(&quot;/consumer/dept/add&quot;) public boolean add(Dept dept) &#123; return restTemplate.postForObject(REST_URL_PREFIX+&quot;/dept/add&quot;,dept,Boolean.class); &#125; @RequestMapping(&quot;/consumer/dept/get/&#123;id&#125;&quot;) public Dept get(@PathVariable(&quot;id&quot;) Long id) &#123; return restTemplate.getForObject(REST_URL_PREFIX+&quot;/dept/get/&quot;+id,Dept.class); &#125; @RequestMapping(&quot;/consumer/dept/list&quot;) public List&lt;Dept&gt; list() &#123; return restTemplate.getForObject(REST_URL_PREFIX+&quot;/dept/list&quot;,List.class); &#125;&#125; **启动服务: **DeptConsumer_80 1234567@SpringBootApplicationpublic class DeptConsumer_80 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptConsumer_80.class,args); &#125;&#125; 整体目录结构 5、Eureka服务注册与发现5.1 什么是Eureka Eureka：怎么读 Netflix在涉及Eureka时，遵循的就是API原则. Eureka是Netflix的有个子模块，也是核心模块之一。Eureka是基于REST的服务，用于定位服务，以实现云端中间件层服务发现和故障转移，服务注册与发现对于微服务来说是非常重要的，有了服务注册与发现，只需要使用服务的标识符，就可以访问到服务，而不需要修改服务调用的配置文件了，功能类似于Dubbo的注册中心，比如Zookeeper. 5.2 原理理解 Eureka基本的架构 Springcloud 封装了Netflix公司开发的Eureka模块来实现服务注册与发现 (对比Zookeeper). Eureka采用了C-S的架构设计，EurekaServer作为服务注册功能的服务器，他是服务注册中心. 而系统中的其他微服务，使用Eureka的客户端连接到EurekaServer并维持心跳连接。这样系统的维护人员就可以通过EurekaServer来监控系统中各个微服务是否正常运行，Springcloud 的一些其他模块 (比如Zuul) 就可以通过EurekaServer来发现系统中的其他微服务，并执行相关的逻辑. 和Dubbo架构对比 Eureka 包含两个组件：Eureka Server 和 Eureka Client. Eureka Server 提供服务注册，各个节点启动后，回在EurekaServer中进行注册，这样Eureka Server中的服务注册表中将会储存所有课用服务节点的信息，服务节点的信息可以在界面中直观的看到. Eureka Client 是一个Java客户端，用于简化EurekaServer的交互，客户端同时也具备一个内置的，使用轮询负载算法的负载均衡器。在应用启动后，将会向EurekaServer发送心跳 (默认周期为30秒) 。如果Eureka Server在多个心跳周期内没有接收到某个节点的心跳，EurekaServer将会从服务注册表中把这个服务节点移除掉 (默认周期为90s). 三大角色 Eureka Server：提供服务的注册与发现 Service Provider：服务生产方，将自身服务注册到Eureka中，从而使服务消费方能狗找到 Service Consumer：服务消费方，从Eureka中获取注册服务列表，从而找到消费服务 目前工程状况 5.3 构建步骤1. eureka-server springcloud-eureka-7001 模块建立 pom.xml 配置 123456789101112131415&lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-starter-eureka-server --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt; &lt;version&gt;1.4.6.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--热部署--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; application.yml 12345678910111213server: port: 7001# Eureka配置eureka: instance: hostname: localhost # Eureka服务端的名字 client: register-with-eureka: false # 表示是否想Eureka中心注册自己 fetch-registry: false # fetch-registry如果为false，则表示自己为注册中心 service-url: defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ 源码中Eureka的默认端口以及访问路径: 主启动类EurekaServer_7001.java 12345678@SpringBootApplication@EnableEurekaServerpublic class EurekaServer_7001 &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServer_7001.class,args); &#125;&#125; 启动成功后访问 http://localhost:7001/ 得到以下页面 2. eureka-client 调整之前创建的springlouc-provider-dept-8081 导入Eureca依赖 1234567&lt;!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-starter-eureka --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt;&lt;/dependency&gt; application.yml中新增Eureca配置 123456# Eureka的配置eureka: client: service-url: defaultZone: http://localhost:7001/eureka/ 为主启动类添加@EnableEurekaClient注解 123456789//启动类@SpringBootApplication@EnableEurekaClient //在服务启动后自动注册到Eureka中public class DeptProvider_8081 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptProvider_8081.class,args); &#125;&#125; 先启动7001服务端后启动8001客户端进行测试，然后访问监控页http://localhost:7001/ 产看结果如图，成功 修改Eureka上的默认描述信息 12345678# Eureka的配置eureka: client: service-url: defaultZone: http://localhost:7001/eureka/ instance: instance-id: springcloud-provider-dept-8081 #修改Eureka上的默认描述信息 结果如图： 等30s后 监控会开启保护机制 配置关于服务加载的监控信息 pom.xml中添加依赖 123456&lt;!--actuator完善监控信息--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; application.yml中添加配置 12345#info配置info: app.name: lzh-springcloud #项目的名称 company.name: com.lzh #公司的名称 刷新页面，点击 3. EureKa自我保护机制：好死不如赖活着 一句话总结就是：某时刻某一个微服务不可用，eureka不会立即清理，依旧会对该微服务的信息进行保存！ 默认情况下，当eureka server在一定时间内没有收到实例的心跳，便会把该实例从注册表中删除（默认是90秒），但是，如果短时间内丢失大量的实例心跳，便会触发eureka server的自我保护机制，比如在开发测试时，需要频繁地重启微服务实例，但是我们很少会把eureka server一起重启（因为在开发过程中不会修改eureka注册中心），当一分钟内收到的心跳数大量减少时，会触发该保护机制。可以在eureka管理界面看到Renews threshold和Renews(last min)，当后者（最后一分钟收到的心跳数）小于前者（心跳阈值）的时候，触发保护机制，会出现红色的警告：**EMERGENCY!EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY’RE NOT.RENEWALS ARE LESSER THAN THRESHOLD AND HENCE THE INSTANCES ARE NOT BEGING EXPIRED JUST TO BE SAFE.**从警告中可以看到，eureka认为虽然收不到实例的心跳，但它认为实例还是健康的，eureka会保护这些实例，不会把它们从注册表中删掉。 该保护机制的目的是避免网络连接故障，在发生网络故障时，微服务和注册中心之间无法正常通信，但服务本身是健康的，不应该注销该服务，如果eureka因网络故障而把微服务误删了，那即使网络恢复了，该微服务也不会重新注册到eureka server了，因为只有在微服务启动的时候才会发起注册请求，后面只会发送心跳和服务列表请求，这样的话，该实例虽然是运行着，但永远不会被其它服务所感知。所以，eureka server在短时间内丢失过多的客户端心跳时，会进入自我保护模式，该模式下，eureka会保护注册表中的信息，不在注销任何微服务，当网络故障恢复后，eureka会自动退出保护模式。自我保护模式可以让集群更加健壮。 但是我们在开发测试阶段，需要频繁地重启发布，如果触发了保护机制，则旧的服务实例没有被删除，这时请求有可能跑到旧的实例中，而该实例已经关闭了，这就导致请求错误，影响开发测试。所以，在开发测试阶段，我们可以把自我保护模式关闭，只需在eureka server配置文件中加上如下配置即可：eureka.server.enable-self-preservation=false· 4. 注册进来的微服务，获取一些消息（团队开发会用到） 启动类添加注解@EnableDiscoveryClient 12345678910//启动类@SpringBootApplication@EnableEurekaClient //在服务启动后自动注册到Eureka中@EnableDiscoveryClientpublic class DeptProvider_8081 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptProvider_8081.class,args); &#125;&#125; DeptController.java新增方法 123456789101112131415161718192021222324//获取一些配置的信息，得到具体的微服务！@Autowiredprivate DiscoveryClient client; //注册进来的微服务~，获取一些消息~ @GetMapping(&quot;/dept/discovery&quot;) public Object discovery() &#123; //获取微服务列表的清单 List&lt;String&gt; services = client.getServices(); System.out.println(&quot;discovery=&gt;services:&quot; + services); //得到一个具体的微服务信息,通过具体的微服务id，applicaioinName； List&lt;ServiceInstance&gt; instances = client.getInstances(&quot;SPRINGCLOUD-PROVIDER-DEPT&quot;); for (ServiceInstance instance : instances) &#123; System.out.println( instance.getHost() + &quot;\\t&quot; + // 主机名称 instance.getPort() + &quot;\\t&quot; + // 端口号 instance.getUri() + &quot;\\t&quot; + // uri instance.getServiceId() // 服务id ); &#125; return this.client; &#125; 结果 5.4 Eureka：集群环境配置1.初始化 新建springcloud-eureka-7002、springcloud-eureka-7003 模块 为pom.xml添加依赖 (与springcloud-eureka-7001相同) 123456789101112131415&lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-starter-eureka-server --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--热部署--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; application.yml配置(与springcloud-eureka-7001相同) 端口号分别换成7002和7003 主启动类(与springcloud-eureka-7001相同) 2.集群成员相互关联 配置一些自定义本机名字，找到本机hosts文件并打开 在hosts文件最后加上，要访问的本机名称，默认是localhost 修改application.yml的配置，如图为springcloud-eureka-7001配置，springcloud-eureka-7002/springcloud-eureka-7003同样分别修改为其对应的名称即可 在集群中使springcloud-eureka-7001关联springcloud-eureka-7002、springcloud-eureka-7003 以7001为例：完整的springcloud-eureka-7001下的application.yml如下 1234567891011121314151617server: port: 7001# Eureka配置eureka: instance: hostname: eureka7001.com # Eureka服务端的名字 client: register-with-eureka: false # 表示是否想Eureka中心注册自己 fetch-registry: false # fetch-registry如果为false，则表示自己为注册中心 service-url: #监控页面~ #重写Eureka的默认端口以及访问路径 ---&gt;http://localhost:7001/eureka/ # 单机 defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ # 集群（关联）：7001关联7002、7003 defaultZone: http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ 通过springcloud-provider-dept-8081下的yml配置文件，修改Eureka配置：配置服务注册中心地址 12345678# Eureka的配置eureka: client: service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ instance: instance-id: springcloud-provider-dept-8081 #修改Eureka上的默认描述信息 这样模拟集群就搭建号了，就可以把一个项目挂载到三个服务器上了 5.5 对比和Zookeeper区别1. 回顾CAP原则 RDBMS (MySQL\\Oracle\\sqlServer) ===&gt; ACID NoSQL (Redis\\MongoDB) ===&gt; CAP 2. ACID是什么？ A (Atomicity) 原子性 C (Consistency) 一致性 I (Isolation) 隔离性 D (Durability) 持久性 3. CAP是什么? C (Consistency) 强一致性 A (Availability) 可用性 P (Partition tolerance) 分区容错性 CAP的三进二：CA、AP、CP 4. CAP理论的核心 一个分布式系统不可能同时很好的满足一致性，可用性和分区容错性这三个需求 根据CAP原理，将NoSQL数据库分成了满足CA原则，满足CP原则和满足AP原则三大类 CA：单点集群，满足一致性，可用性的系统，通常可扩展性较差 CP：满足一致性，分区容错的系统，通常性能不是特别高 AP：满足可用性，分区容错的系统，通常可能对一致性要求低一些 5. 作为分布式服务注册中心，Eureka比Zookeeper好在哪里？ 著名的CAP理论指出，一个分布式系统不可能同时满足C (一致性) 、A (可用性) 、P (容错性)，由于分区容错性P再分布式系统中是必须要保证的，因此我们只能再A和C之间进行权衡。 Zookeeper 保证的是CP Eureka 保证的是AP Zookeeper保证的是CP 当向注册中心查询服务列表时，我们可以容忍注册中心返回的是几分钟以前的注册信息，但不能接收服务直接down掉不可用。也就是说，服务注册功能对可用性的要求要高于一致性。但zookeeper会出现这样一种情况，当master节点因为网络故障与其他节点失去联系时，剩余节点会重新进行leader选举。问题在于，选举leader的时间太长，30-120s，且选举期间整个zookeeper集群是不可用的，这就导致在选举期间注册服务瘫痪。在云部署的环境下，因为网络问题使得zookeeper集群失去master节点是较大概率发生的事件，虽然服务最终能够恢复，但是，漫长的选举时间导致注册长期不可用，是不可容忍的。 Eureka保证的是AP Eureka看明白了这一点，因此在设计时就优先保证可用性。Eureka各个节点都是平等的，几个节点挂掉不会影响正常节点的工作，剩余的节点依然可以提供注册和查询服务。而Eureka的客户端在向某个Eureka注册时，如果发现连接失败，则会自动切换至其他节点，只要有一台Eureka还在，就能保住注册服务的可用性，只不过查到的信息可能不是最新的，除此之外，Eureka还有之中自我保护机制，如果在15分钟内超过85%的节点都没有正常的心跳，那么Eureka就认为客户端与注册中心出现了网络故障，此时会出现以下几种情况： Eureka不在从注册列表中移除因为长时间没收到心跳而应该过期的服务 Eureka仍然能够接受新服务的注册和查询请求，但是不会被同步到其他节点上 (即保证当前节点依然可用) 当网络稳定时，当前实例新的注册信息会被同步到其他节点中 因此，Eureka可以很好的应对因网络故障导致部分节点失去联系的情况，而不会像zookeeper那样使整个注册服务瘫痪 6. Ribbon：负载均衡(基于客户端)6.1 负载均衡以及RibbonRibbon是什么？ Spring Cloud Ribbon 是基于Netflix Ribbon 实现的一套客户端负载均衡的工具。 简单的说，Ribbon 是 Netflix 发布的开源项目，主要功能是提供客户端的软件负载均衡算法，将 Netflix 的中间层服务连接在一起。Ribbon 的客户端组件提供一系列完整的配置项，如：连接超时、重试等。简单的说，就是在配置文件中列出 LoadBalancer (简称LB：负载均衡) 后面所有的及其，Ribbon 会自动的帮助你基于某种规则 (如简单轮询，随机连接等等) 去连接这些机器。我们也容易使用 Ribbon 实现自定义的负载均衡算法！ 面试造飞机，工作拧螺丝 Ribbon能干嘛？ LB，即负载均衡 (LoadBalancer) ，在微服务或分布式集群中经常用的一种应用。 负载均衡简单的说就是将用户的请求平摊的分配到多个服务上，从而达到系统的HA (高用)。 常见的负载均衡软件有 Nginx、Lvs 等等。 Dubbo、SpringCloud 中均给我们提供了负载均衡，SpringCloud 的负载均衡算法可以自定义。 负载均衡简单分类： 集中式LB 即在服务的提供方和消费方之间使用独立的LB设施，如Nginx，由该设施负责把访问请求通过某种策略转发至服务的提供方！ 进程式LB 将LB逻辑集成到消费方，消费方从服务注册中心获知有哪些地址可用，然后自己再从这些地址中选出一个合适的服务器。 Ribbon 就属于进程内LB，它只是一个类库，集成于消费方进程，消费方通过它来获取到服务提供方的地址！ 6.2 集成Ribbon springcloud-consumer-dept-80向pom.xml中添加Ribbon和Eureka依赖 1234567891011121314&lt;!-- Ribbon --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!--eureka--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt;&lt;/dependency&gt; 在application.yml文件中配置Eureka 1234567# Eureka配置eureka: client: register-with-eureka: false # 不向 Eureka注册自己 service-url: # 从三个注册中心中随机取一个去访问 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ 主启动类加上@EnableEurekaClient注解，开启Eureka 12345678@SpringBootApplication@EnableEurekaClient //开启Eureka 客户端public class DeptConsumer_80 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptConsumer_80.class,args); &#125;&#125; 自定义Spring配置类：ConfigBean.java 配置负载均衡实现RestTemplate 12345678910@Configurationpublic class ConfigBean &#123; //Cofiguration -- spring applicationContext.xml @LoadBalanced //配置负载均衡实现RestTemplate @Bean public RestTemplate getRestTemplate() &#123; return new RestTemplate(); &#125; &#125; ​ 6.3 使用Ribbon实现负载均衡1.实现负载均衡 流程图： 创建db02和db03数据库(一样的) 1234567891011121314151617CREATE DATABASE &#96;db02&#96;USE &#96;db02&#96;;DROP TABLE IF EXISTS &#96;dept&#96;;CREATE TABLE &#96;dept&#96; ( &#96;deptno&#96; BIGINT(20) NOT NULL AUTO_INCREMENT, &#96;dname&#96; VARCHAR(60) DEFAULT NULL, &#96;db_source&#96; VARCHAR(60) DEFAULT NULL, PRIMARY KEY (&#96;deptno&#96;)) ENGINE&#x3D;INNODB AUTO_INCREMENT&#x3D;1 DEFAULT CHARSET&#x3D;utf8 COMMENT&#x3D;&#39;部门表&#39;;INSERT INTO &#96;dept&#96;(&#96;dname&#96;,&#96;db_source&#96;) VALUES (&#39;开发部&#39;,DATABASE()),(&#39;人事部&#39;,DATABASE()),(&#39;财务部&#39;,DATABASE()),(&#39;市场部&#39;,DATABASE()),(&#39;运维部&#39;,DATABASE()); 新建两个服务提供者Moudle：springcloud-provider-dept-8082、springcloud-provider-dept-8083 参照springcloud-provider-dept-8081 依次为另外两个Moudle添加pom.xml依赖 、resourece下的mybatis和application.yml配置，Java代码 三个服务（spring.application.name）的名称必须一致 启动所有服务测试(根据自身电脑配置决定启动服务的个数)，访问http://eureka7001.com:7001/查看结果 测试访问http://localhost/consumer/dept/list 这时候随机访问的是服务提供者8081 再次访问http://localhost/consumer/dept/list这时候随机的是服务提供者8083 再次访问http://localhost/consumer/dept/list这时候随机的是服务提供者8082 以上这种每次访问http://localhost/consumer/dept/list随机访问集群中某个服务提供者，这种情况叫做轮询，轮询算法在SpringCloud中可以自定义。 2.如何切换或者自定义规则呢？ 在springcloud-provider-dept-80模块下的ConfigBean中进行配置，切换使用不同的规则 1234567891011121314151617181920212223@Configurationpublic class ConfigBean &#123;//@Configuration -- spring applicationContext.xml /** * IRule: * RoundRobinRule 轮询 * RandomRule 随机 * AvailabilityFilteringRule ： 会先过滤掉，跳闸，访问故障的服务~，对剩下的进行轮询~ * RetryRule ： 会先按照轮询获取服务~，如果服务获取失败，则会在指定的时间内进行，重试 */ @LoadBalanced //配置负载均衡实现RestTemplate @Bean public RestTemplate getRestTemplate() &#123; return new RestTemplate(); &#125; @Bean public IRule myRule()&#123; return new RandomRule();//使用随机规则 &#125;&#125; 也可以自定义规则，在myRule包下自定义一个配置类MyRule.java，注意：**该包不要和主启动类所在的包同级，要跟启动类所在包同级**： MyRule.java 123456789@Configurationpublic class MyRule &#123; @Bean public IRule lzhMyRule() &#123; return new MyRandomRule();//默认是轮循，现在我们自定义 &#125;&#125; 主启动类开启负载均衡并指定自定义的MyRule配置类 1234567891011// Ribbon和Eureka整合之后，客户端可以直接调用，不用关系IP地址@SpringBootApplication@EnableEurekaClient //开启Eureka 客户端//在微服务启动的时候就能加载自定义的Ribbon类(自定义的规则会覆盖原有默认的规则)@RibbonClient(name = &quot;SPRINGCLOUD-PROVIDER-DEPT&quot;,configuration = MyRule.class)//开启负载均衡,并指定自定义的规则public class DeptConsumer_80 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptConsumer_80.class,args); &#125;&#125; 自定义的规则(这里我们参考Ribbon中默认的规则代码自己稍微改动)：MyRandomRule.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990package nuc.ss.myrule;import com.netflix.client.config.IClientConfig;import com.netflix.loadbalancer.AbstractLoadBalancerRule;import com.netflix.loadbalancer.ILoadBalancer;import com.netflix.loadbalancer.Server;import java.util.List;import java.util.concurrent.ThreadLocalRandom;public class MyRandomRule extends AbstractLoadBalancerRule &#123; /** * 每个服务访问5次，则换下一个服务(总共3个服务) * total=0,默认=0,如果=5,指向下一个服务节点 * index=0,默认=0,如果total=5,index+1 */ private int total = 0; //被调用的次数 private int currentIndex = 0; //当前是谁在提供服务 public Server choose(ILoadBalancer lb, Object key) &#123; if (lb == null) &#123; return null; &#125; Server server = null; while (server == null) &#123; if (Thread.interrupted()) &#123; return null; &#125; List&lt;Server&gt; upList = lb.getReachableServers(); //获得当前活着的服务 List&lt;Server&gt; allList = lb.getAllServers(); //获取所有的服务 int serverCount = allList.size(); if (serverCount == 0) &#123; return null; &#125; //int index = chooseRandomInt(serverCount);//生成区间随机数 //server = upList.get(index);//从或活着的服务中,随机获取一个 //=====================自定义代码========================= if (total &lt; 5) &#123; server = upList.get(currentIndex); total++; &#125; else &#123; total = 0; currentIndex++; if (currentIndex &gt;= upList.size()) &#123; currentIndex = 0; &#125; //server = upList.get(currentIndex);//从活着的服务中,获取指定的服务来进行操作 &#125; //====================================================== if (server == null) &#123; Thread.yield(); continue; &#125; if (server.isAlive()) &#123; return (server); &#125; server = null; Thread.yield(); &#125; return server; &#125; protected int chooseRandomInt(int serverCount) &#123; return ThreadLocalRandom.current().nextInt(serverCount); &#125; @Override public Server choose(Object key) &#123; return choose(getLoadBalancer(), key); &#125; @Override public void initWithNiwsConfig(IClientConfig clientConfig) &#123; // TODO Auto-generated method stub &#125;&#125; 7.Feign：负载均衡(基于服务端)7.1 Feign简介Feign是声明式Web Service客户端，它让微服务之间的调用变得更简单，类似controller调用service。SpringCloud集成了Ribbon和Eureka，可以使用Feigin提供负载均衡的http客户端 只需要创建一个接口，然后添加注解即可~ Feign，主要是社区版，大家都习惯面向接口编程。这个是很多开发人员的规范。调用微服务访问两种方法 微服务名字 【ribbon】 接口和注解 【feign】 Feign能干什么？ Feign旨在使编写Java Http客户端变得更容易 前面在使用Ribbon + RestTemplate时，利用RestTemplate对Http请求的封装处理，形成了一套模板化的调用方法。但是在实际开发中，由于对服务依赖的调用可能不止一处，往往一个接口会被多处调用，所以通常都会针对每个微服务自行封装一个客户端类来包装这些依赖服务的调用。所以，Feign在此基础上做了进一步的封装，由他来帮助我们定义和实现依赖服务接口的定义，在Feign的实现下，我们只需要创建一个接口并使用注解的方式来配置它 (类似以前Dao接口上标注Mapper注解，现在是一个微服务接口上面标注一个Feign注解即可)，即可完成对服务提供方的接口绑定，简化了使用Spring Cloud Ribbon 时，自动封装服务调用客户端的开发量。 Feign默认集成了Ribbon 利用Ribbon维护了MicroServiceCloud-Dept的服务列表信息，并且通过轮询实现了客户端的负载均衡，而与Ribbon不同的是，通过Feign只需要定义服务绑定接口且以声明式的方法，优雅而简单的实现了服务调用。 7.2 Feign的使用步骤 改造springcloud-api模块 pom.xml添加feign依赖 123456&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt;&lt;/dependency&gt; 新建service层，并新建DeptClientService.java接口， 123456789101112131415@Service//@FeignClient:微服务客户端注解,value:指定微服务的名字,这样就可以使Feign客户端直接找到对应的微服务@FeignClient(value = &quot;SPRINGCLOUD-PROVIDER-DEPT&quot;)public interface DeptClientService &#123; @GetMapping(&quot;/dept/get/&#123;id&#125;&quot;) Dept queryById(@PathVariable(&quot;id&quot;) Long id); @GetMapping(&quot;/dept/list&quot;) List&lt;Dept&gt; queryAll(); @PostMapping(&quot;/dept/add&quot;) boolean addDept(Dept dept);&#125; 创建springcloud-consumer-dept-feign模块 拷贝springcloud-consumer-dept-80模块下的pom.xml，resource，以及java代码到springcloud-consumer-feign模块，并添加feign依赖。 1234567&lt;!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-starter-feign --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-feign&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt;&lt;/dependency&gt; 通过Feign实现DeptConsumerController.java 1234567891011121314151617181920212223@RestControllerpublic class DeptConsumerController &#123; @Autowired private DeptClientService deptClientService = null; @RequestMapping(&quot;/consumer/dept/add&quot;) public boolean add(Dept dept) &#123; return this.deptClientService.addDept(dept); &#125; @RequestMapping(&quot;/consumer/dept/get/&#123;id&#125;&quot;) public Dept get(@PathVariable(&quot;id&quot;) Long id) &#123; return this.deptClientService.queryById(id); &#125; @RequestMapping(&quot;/consumer/dept/list&quot;) public List&lt;Dept&gt; list() &#123; return this.deptClientService.queryAll(); &#125;&#125; 主配置类 123456789@SpringBootApplication@EnableEurekaClient //开启Eureka 客户端@EnableFeignClients(basePackages = &#123;&quot;nuc.ss.springcloud&quot;&#125;)public class FeignDeptConsumer_80 &#123; public static void main(String[] args) &#123; SpringApplication.run(FeignDeptConsumer_80.class,args); &#125;&#125; 结果 7.3 Feign和Ribbon如何选择？根据个人习惯而定，如果喜欢REST风格使用Ribbon；如果喜欢社区版的面向接口风格使用Feign. 8. Hystrix：服务熔断分布式系统面临的问题 复杂分布式体系结构中的应用程序有数十个依赖关系，每个依赖关系在某些时候将不可避免失败！ 8.1 服务雪崩 多个微服务之间调用的时候，假设微服务A调用微服务B和微服务C，微服务B和微服务C又调用其他的微服务，这就是所谓的“扇出”，如果扇出的链路上某个微服务的调用响应时间过长，或者不可用，对微服务A的调用就会占用越来越多的系统资源，进而引起系统崩溃，所谓的“雪崩效应”。 对于高流量的应用来说，单一的后端依赖可能会导致所有服务器上的所有资源都在几十秒内饱和。比失败更糟糕的是，这些应用程序还可能导致服务之间的延迟增加，备份队列，线程和其他系统资源紧张，导致整个系统发生更多的级联故障，这些都表示需要对故障和延迟进行隔离和管理，以便单个依赖关系的失败，不能取消整个应用程序或系统。 我们需要，弃车保帅 8.2 什么是Hystrix？ Hystrix是一个应用于处理分布式系统的延迟和容错的开源库，在分布式系统里，许多依赖不可避免的会调用失败，比如超时，异常等，Hystrix能够保证在一个依赖出问题的情况下，不会导致整个体系服务失败，避免级联故障，以提高分布式系统的弹性。 “断路器”本身是一种开关装置，当某个服务单元发生故障之后，通过断路器的故障监控 (类似熔断保险丝) ，向调用方方茴一个服务预期的，可处理的备选响应 (FallBack) ，而不是长时间的等待或者抛出调用方法无法处理的异常，这样就可以保证了服务调用方的线程不会被长时间，不必要的占用，从而避免了故障在分布式系统中的蔓延，乃至雪崩。 8.3 Hystrix能干嘛？ 服务降级 服务熔断 服务限流 接近实时的监控 … 当一切正常时，请求流可以如下所示： 当许多后端系统中有一个潜在时，它可以阻止整个用户请求： 随着大容量通信量的增加，单个后端依赖项的潜在性会导致所有服务器上的所有资源在几秒钟内饱和。 应用程序中通过网络或客户端库可能导致网络请求的每个点都是潜在故障的来源。比失败更糟糕的是，这些应用程序还可能导致服务之间的延迟增加，从而备份队列、线程和其他系统资源，从而导致更多跨系统的级联故障。 当使用hystrix包装每个基础依赖项时，上面的图表中所示的体系结构会发生类似于以下关系图的变化。每个依赖项是相互隔离的，限制在延迟发生时它可以填充的资源中，并包含在回退逻辑中，该逻辑决定在依赖项中发生任何类型的故障时要做出什么样的响应： 官网资料：https://github.com/Netflix/Hystrix/wiki，图片加载不出来请看另一篇文章 github加载图片失败问题 8.4、服务熔断8.4.1、什么是服务熔断 熔断机制是赌赢雪崩效应的一种微服务链路保护机制。 在微服务架构中，微服务之间的数据交互通过远程调用完成，微服务A调用微服务B和微服务C，微服务B和微服务C又调用其它的微服务，此时如果链路上某个微服务的调用响应时间过长或者不可用，那么对微服务A的调用就会占用越来越多的系统资源，进而引起系统崩溃，导致“雪崩效应”。 服务熔断是应对雪崩效应的一种微服务链路保护机制。例如在高压电路中，如果某个地方的电压过高，熔断器就会熔断，对电路进行保护。同样，在微服务架构中，熔断机制也是起着类似的作用。当调用链路的某个微服务不可用或者响应时间太长时，会进行服务熔断，不再有该节点微服务的调用，快速返回错误的响应信息。当检测到该节点微服务调用响应正常后，恢复调用链路。 当扇出链路的某个微服务不可用或者响应时间太长时，会进行服务的降级，进而熔断该节点微服务的调用，快速返回错误的响应信息。检测到该节点微服务调用响应正常后恢复调用链路。在SpringCloud框架里熔断机制通过Hystrix实现。Hystrix会监控微服务间调用的状况，当失败的调用到一定阀值缺省是5秒内20次调用失败，就会启动熔断机制。熔断机制的注解是：**@HystrixCommand** 。 服务熔断解决如下问题： 当所依赖的对象不稳定时，能够起到快速失败的目的 快速失败后，能够根据一定的算法动态试探所依赖对象是否恢复 8.4.2、入门案例新建springcloud-provider-dept-hystrix-8081模块并拷贝springcloud-provider-dept–8081内的pom.xml、resource和Java代码进行初始化并调整。 导入hystrix依赖 1234567&lt;!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-starter-hystrix --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt;&lt;/dependency&gt; 调整yml配置文件 123456789# Eureka的配置eureka: client: service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ instance: instance-id: springcloud-provider-dept-hystrix-8081 #修改Eureka上的默认描述信息 prefer-ip-address: true #改为true后默认显示的是ip地址而不再是localhost prefer-ip-address: false： prefer-ip-address: true： 修改controller 1234567891011121314151617181920212223242526272829//视图Restful服务@RestControllerpublic class DeptController &#123; @Autowired private DeptService deptService; //获取一些配置的信息，得到具体的微服务！ @Autowired private DiscoveryClient client; @HystrixCommand(fallbackMethod = &quot;hystrixGet&quot;)//如果根据id查询出现异常,走这段代码 @GetMapping(&quot;/dept/get/&#123;id&#125;&quot;) public Dept get(@PathVariable(&quot;id&quot;) Long id) &#123; Dept dept = deptService.queryById(id); if (dept==null)&#123; throw new RuntimeException(&quot;这个id=&gt;&quot;+id+&quot;,不存在该用户，或信息无法找到~&quot;); &#125; return dept; &#125; //根据id查询备选方案(熔断) public Dept hystrixGet(@PathVariable(&quot;id&quot;) Long id)&#123; return new Dept().setDeptno(id) .setDname(&quot;这个id=&gt;&quot;+id+&quot;,没有对应的信息,null---@Hystrix~&quot;) .setDb_source(&quot;在MySQL中没有这个数据库&quot;); &#125;&#125; 为主启动类添加对熔断的支持注解@EnableCircuitBreaker 1234567891011//启动类@SpringBootApplication@EnableEurekaClient //在服务启动后自动注册到Eureka中@EnableDiscoveryClient //服务发现~@EnableCircuitBreaker//添加对熔断的支持public class DeptProviderHystrix_8081 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptProviderHystrix_8081.class,args); &#125;&#125; 测试： 使用熔断后，当访问一个存在的id时，前台页展示数据如下 使用熔断后，当访问一个不存在的id时，前台页展示数据如下 而不适用熔断的springcloud-provider-dept–8081模块访问相同地址会出现下面状况 因此，为了避免因某个微服务后台出现异常或错误而导致整个应用或网页报错，使用熔断是必要的 8.5 服务降级什么是服务降级​ 服务降级是指 当服务器压力剧增的情况下，根据实际业务情况及流量，对一些服务和页面有策略的不处理或换种简单的方式处理，从而释放服务器资源以保证核心业务正常运作或高效运作。说白了，就是尽可能的把系统资源让给优先级高的服务。 资源有限，而请求是无限的。如果在并发高峰期，不做服务降级处理，一方面肯定会影响整体服务的性能，严重的话可能会导致宕机某些重要的服务不可用。所以，一般在高峰期，为了保证核心功能服务的可用性，都要对某些服务降级处理。比如当双11活动时，把交易无关的服务统统降级，如查看蚂蚁深林，查看历史订单等等。 服务降级主要用于什么场景呢？当整个微服务架构整体的负载超出了预设的上限阈值或即将到来的流量预计将会超过预设的阈值时，为了保证重要或基本的服务能正常运行，可以将一些 不重要 或 不紧急 的服务或任务进行服务的 延迟使用 或 暂停使用。 降级的方式可以根据业务来，可以延迟服务，比如延迟给用户增加积分，只是放到一个缓存中，等服务平稳之后再执行 ；或者在粒度范围内关闭服务，比如关闭相关文章的推荐。 由上图可得，当某一时间内服务A的访问量暴增，而B和C的访问量较少，为了缓解A服务的压力，这时候需要B和C暂时关闭一些服务功能，去承担A的部分服务，从而为A分担压力，叫做服务降级。 服务降级需要考虑的问题 1）那些服务是核心服务，哪些服务是非核心服务 2）那些服务可以支持降级，那些服务不能支持降级，降级策略是什么 3）除服务降级之外是否存在更复杂的业务放通场景，策略是什么？ 自动降级分类1）超时降级：主要配置好超时时间和超时重试次数和机制，并使用异步机制探测回复情况 2）失败次数降级：主要是一些不稳定的api，当失败调用次数达到一定阀值自动降级，同样要使用异步机制探测回复情况 3）故障降级：比如要调用的远程服务挂掉了（网络故障、DNS故障、http服务返回错误的状态码、rpc服务抛出异常），则可以直接降级。降级后的处理方案有：默认值（比如库存服务挂了，返回默认现货）、兜底数据（比如广告挂了，返回提前准备好的一些静态页面）、缓存（之前暂存的一些缓存数据） 4）限流降级：秒杀或者抢购一些限购商品时，此时可能会因为访问量太大而导致系统崩溃，此时会使用限流来进行限制访问量，当达到限流阀值，后续请求会被降级；降级后的处理方案可以是：排队页面（将用户导流到排队页面等一会重试）、无货（直接告知用户没货了）、错误页（如活动太火爆了，稍后重试）。 入门案例在springcloud-api模块下的service包中新建降级配置类DeptClientServiceFallBackFactory.java 12345678910111213141516171819202122232425262728//降级 ~@Componentpublic class DeptClientServiceFallBackFactory implements FallbackFactory &#123; @Override public Object create(Throwable throwable) &#123; return new DeptClientService() &#123; @Override public Dept queryById(Long id) &#123; return new Dept() .setDeptno(id) .setDname(&quot;id=&gt;&quot; + id + &quot;没有对应的信息，客户端提供了降级的信息，这个服务现在已经被关闭&quot;) .setDb_source(&quot;没有数据~&quot;); &#125; @Override public List&lt;Dept&gt; queryAll() &#123; return null; &#125; @Override public boolean addDept(Dept dept) &#123; return false; &#125; &#125;; &#125;&#125; 在DeptClientService中指定降级配置类DeptClientServiceFallBackFactory 123456789101112131415@Service//@FeignClient:微服务客户端注解,value:指定微服务的名字,这样就可以使Feign客户端直接找到对应的微服务@FeignClient(value = &quot;SPRINGCLOUD-PROVIDER-DEPT&quot;,fallbackFactory = DeptClientServiceFallBackFactory.class)public interface DeptClientService &#123; @GetMapping(&quot;/dept/get/&#123;id&#125;&quot;) Dept queryById(@PathVariable(&quot;id&quot;) Long id); @GetMapping(&quot;/dept/list&quot;) List&lt;Dept&gt; queryAll(); @PostMapping(&quot;/dept/add&quot;) boolean addDept(Dept dept);&#125; 在springcloud-consumer-dept-feign模块中开启降级 12345# 开启降级feign.hystrixfeign: hystrix: enabled: true 测试 正常访问 关掉服务DeptProvider_8081继续访问 8.6 服务熔断和降级的区别 服务熔断—&gt;服务端：某个服务超时或异常，引起熔断~，类似于保险丝(自我熔断) 服务降级—&gt;客户端：从整体网站请求负载考虑，当某个服务熔断或者关闭之后，服务将不再被调用，此时在客户端，我们可以准备一个 FallBackFactory ，返回一个默认的值(缺省值)。会导致整体的服务下降，但是好歹能用，比直接挂掉强。 触发原因不太一样，服务熔断一般是某个服务（下游服务）故障引起，而服务降级一般是从整体负荷考虑；管理目标的层次不太一样，熔断其实是一个框架级的处理，每个微服务都需要（无层级之分），而降级一般需要对业务有层级之分（比如降级一般是从最外围服务开始） 实现方式不太一样，服务降级具有代码侵入性(由控制器完成/或自动降级)，熔断一般称为自我熔断。 限流：限制并发的请求访问量，超过阈值则拒绝；降级：服务分优先级，牺牲非核心服务（不可用），保证核心服务稳定；从整体负荷考虑；熔断：依赖的下游服务故障触发熔断，避免引发本系统崩溃；系统自动执行和恢复 8.7 Dashboard 流监控新建springcloud-consumer-hystrix-dashboard模块 添加依赖 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/org.springframework.cloud/spring-cloud-starter-hystrix --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix-dashboard&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Ribbon --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--eureka--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;nuc.ss&lt;/groupId&gt; &lt;artifactId&gt;springcloud-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 主启动类 123456789@SpringBootApplication@EnableHystrixDashboard //开启public class DeptConsumerDashboard_9001 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptConsumerDashboard_9001.class,args); &#125;&#125; 启动应用程序，访问：localhost:9001/hystrix 服务端8081是否有监控应用程依赖，没有添加 123456&lt;!--actuator完善监控信息--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; 给springcloud-provider-dept-hystrix-8081模块下的主启动类添加如下代码,添加监控 1234567891011121314151617181920//启动类@SpringBootApplication@EnableEurekaClient //在服务启动后自动注册到Eureka中@EnableDiscoveryClient //服务发现~@EnableCircuitBreaker//添加对熔断的支持public class DeptProviderHystrix_8081 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptProviderHystrix_8081.class,args); &#125; //增加一个 Servlet @Bean public ServletRegistrationBean hystrixMetricsStreamServlet()&#123; ServletRegistrationBean registrationBean = new ServletRegistrationBean(new HystrixMetricsStreamServlet()); //访问该页面就是监控页面 registrationBean.addUrlMappings(&quot;/actuator/hystrix.stream&quot;); return registrationBean; &#125;&#125; 注意：先访问localhost:8081/dept/get/1，在访问localhost:8081/actuator/hystrix.stream，不然也会报错 在springcloud-consumer-hystrix-dashboard中的yml中添加配置（刚开始没加，一直报这个错: Unable to connect to Command Metric Stream） 1234hystrix: dashboard: proxy-stream-allow-list: &quot;*&quot; 运行结果：（注意心跳和圆的大小变化） 如何看运行结果 七色 绿色：成功数 蓝色：熔断数 浅绿色：错误请求数 黄色：超时数 紫色：线程池拒绝数 红色：失败/异常数 Hosts：服务请求频率 Circuit Closed：断路状态 一圈实心圆:公有两种含义，他通过颜色的变化代表了实例的健康程度它的健康程度从绿色&lt;黄色&lt;橙色&lt;红色 递减该实心圆除了颜色的变化之外，它的大小也会根据实例的请求流量发生变化，流量越大，该实心圆就越大，所以通过该实心圆的展示，就可以在大量的实例中快速发现故障实例和高压力实例。 一线曲线：用来记录2分钟内流量的相对变化，可以通过它来观察到流量的上升和下降趋势! 9. Zull路由网关概述什么是zuul? Zull包含了对请求的路由(用来跳转的)和过滤两个最主要功能： 其中路由功能负责将外部请求转发到具体的微服务实例上，是实现外部访问统一入口的基础，而过滤器功能则负责对请求的处理过程进行干预，是实现请求校验，服务聚合等功能的基础。Zuul和Eureka进行整合，将Zuul自身注册为Eureka服务治理下的应用，同时从Eureka中获得其他服务的消息，也即以后的访问微服务都是通过Zuul跳转后获得。 注意：Zuul服务最终还是会注册进Eureka 提供：代理+路由+过滤 三大功能！ Zuul能干嘛？ 路由 过滤 官方文档：https://github.com/Netflix/zuul/ 入门案例新建springcloud-zuul模块，并导入依赖 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;dependencies&gt; &lt;!--zuul--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zuul&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Hystrix依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix-dashboard&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Ribbon --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-ribbon&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--eureka--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;nuc.ss&lt;/groupId&gt; &lt;artifactId&gt;springcloud-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; application.yml 1234567891011121314151617server: port: 9527spring: application: name: springcloud-zuuleureka: client: service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ instance: instance-id: zuul9527.com prefer-ip-address: trueinfo: app.name: springcloud company.name: blog.kuangstudy.com 启动如下图三个服务（先去host文件里面添加www.kuangstudy.com的服务） 访问http://localhost:8081/dept/get/1和http://www.kuangstudy.com:9527/springcloud-provider-dept/dept/get/1都可以获得数据 隐藏微服务springcloud-provider-dept的名称在地址栏，application.yml中添加配置 12345zuul: routes: mydept.serviceId: springcloud-provider-dept mydept.path: /mydept/** 访问这个地址即可http://www.kuangstudy.com:9527/mydept/dept/get/1 但是原路径http://www.kuangstudy.com:9527/springcloud-provider-dept/dept/get/1也能访问 继续配置application.yml,原来的http://www.kuangstudy.com:9527/springcloud-provider-dept/dept/get/1不能访问了 123456zuul: routes: mydept.serviceId: springcloud-provider-dept mydept.path: /mydept/** ignored-services: &quot;*&quot; # 不能再使用某个(*：全部)路径访问了，ignored ： 忽略,隐藏全部的~ 继续想application添加公共的访问前缀,访问路径变为http://www.kuangstudy.com:9527/kuang/mydept/dept/get/1 1234567zuul: routes: mydept.serviceId: springcloud-provider-dept mydept.path: /mydept/** ignored-services: &quot;*&quot; # 不能再使用某个(*：全部)路径访问了，ignored ： 忽略,隐藏全部的~ prefix: /kuang # 设置公共的前缀,实现隐藏原有路由 10. Spring Cloud Config 分布式配置概述分布式系统面临的–配置文件问题 微服务意味着要将单体应用中的业务拆分成一个个子服务，每个服务的粒度相对较小，因此系统中会出现大量的服务，由于每个服务都需要必要的配置信息才能运行，所以一套集中式的，动态的配置管理设施是必不可少的。spring cloud提供了configServer来解决这个问题，我们每一个微服务自己带着一个application.yml，那上百个的配置文件修改起来，令人头疼！ 什么是SpringCloud config分布式配置中心？ spring cloud config 为微服务架构中的微服务提供集中化的外部支持，配置服务器为各个不同微服务应用的所有环节提供了一个中心化的外部配置。 spring cloud config 分为服务端和客户端两部分。 服务端也称为 分布式配置中心，它是一个独立的微服务应用，用来连接配置服务器并为客户端提供获取配置信息，加密，解密信息等访问接口。 客户端则是通过指定的配置中心来管理应用资源，以及与业务相关的配置内容，并在启动的时候从配置中心获取和加载配置信息。配置服务器默认采用git来存储配置信息，这样就有助于对环境配置进行版本管理。并且可用通过git客户端工具来方便的管理和访问配置内容。 spring cloud config 分布式配置中心能干嘛？ 集中式管理配置文件 不同环境，不同配置，动态化的配置更新，分环境部署，比如 /dev /test /prod /beta /release 运行期间动态调整配置，不再需要在每个服务部署的机器上编写配置文件，服务会向配置中心统一拉取配置自己的信息 当配置发生变动时，服务不需要重启，即可感知到配置的变化，并应用新的配置 将配置信息以REST接口的形式暴露 spring cloud config 分布式配置中心与GitHub整合 由于spring cloud config 默认使用git来存储配置文件 (也有其他方式，比如自持SVN 和本地文件)，但是最推荐的还是git ，而且使用的是 http / https 访问的形式。 入门案例服务端编写application.yml提交到github上或者码云上面（注意：—和空格的输入，否则之后访问补到） 12345678910111213141516spring: profiles: active: dev---spring: profiles: dev application: name: springcloud-config-dev---spring: profiles: test application: name: springcloud-config-test 新建springcloud-config-server-3344模块导入pom.xml依赖 123456789101112131415161718192021&lt;dependencies&gt; &lt;!--web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--config--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;version&gt;2.2.5.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--eureka--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;version&gt;1.4.7.RELEASE&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; resource下创建application.yml配置文件，Spring Cloud Config服务器从git存储库（必须提供）为远程客户端提供配置： 1234567891011121314151617181920212223server: port: 3344spring: application: name: springcloud-config-server # 连接github远程仓库 cloud: config: server: git: # 注意是https的而不是ssh uri: https://github.com/lzh66666/spring-cloud-kuang.git # 通过 config-server可以连接到git，访问其中的资源以及配置~ default-label: main# 不加这个配置会报Cannot execute request on any known server 这个错：连接Eureka服务端地址不对# 或者直接注释掉eureka依赖 这里暂时用不到eurekaeureka: client: register-with-eureka: false fetch-registry: false 注意：default-label属性，默认是master提交，我改成main提交之后页面死活出不来 可以输入git status查看自己的分支 访问：http://localhost:3344/application-dev.yml页面 访问：http://localhost:3344/application-test.yml页面 HTTP服务具有以下格式的资源：（main是我的分支，默认为master） 123456/&#123;application&#125;/&#123;profile&#125;[/&#123;label&#125;] // http://localhost:3344/application/test/main/&#123;application&#125;-&#123;profile&#125;.yml // http://localhost:3344/application-test.yml/&#123;label&#125;/&#123;application&#125;-&#123;profile&#125;.yml // http://localhost:3344/main/application-test.yml/&#123;application&#125;-&#123;profile&#125;.properties/&#123;label&#125;/&#123;application&#125;-&#123;profile&#125;.properties 客户端将本地git仓库springcloud-config文件夹下新建的config-client.yml提交到github或码云仓库：（千万别加注释，否则路径找不到） 12345678910111213141516171819202122232425262728spring: profiles: active: dev---server: port: 8201spring: profiles: dev application: name: springcloud-provider-depteureka: client: service-url: defaultZone: http://eureka7001.com:7001/eureka/---server: port: 8202spring: profiles: test application: name: springcloud-provider-depteureka: client: service-url: defaultZone: http://eureka7001.com:7001/eureka/ 新建一个springcloud-config-client-3355模块，并导入依赖 123456789101112131415161718192021&lt;dependencies&gt; &lt;!--web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--config--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;version&gt;2.1.1.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--actuator--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; resources下创建application.yml和bootstrap.yml配置文件 bootstrap.yml是系统级别的配置 12345678910# 系统级别的配置spring: cloud: config: name: config-client # 需要从git上读取的资源名称，不要后缀 profile: dev label: main uri: http://localhost:3344 application.yml是用户级别的配置 12345# 用户级别的配置spring: application: name: springcloud-config-client 创建controller包下的ConfigClientController.java用于测试 1234567891011121314151617181920@RestControllerpublic class ConfigClientController &#123; @Value(&quot;$&#123;spring.application.name&#125;&quot;) private String applicationName; //获取微服务名称 @Value(&quot;$&#123;eureka.client.service-url.defaultZone&#125;&quot;) private String eurekaServer; //获取Eureka服务 @Value(&quot;$&#123;server.port&#125;&quot;) private String port; //获取服务端的端口号 @RequestMapping(&quot;/config&quot;) public String getConfig()&#123; return &quot;applicationName:&quot;+applicationName + &quot;eurekaServer:&quot;+eurekaServer + &quot;port:&quot;+port; &#125;&#125; 主启动类 1234567@SpringBootApplicationpublic class ConfigClient_3355 &#123; public static void main(String[] args) &#123; SpringApplication.run(ConfigClient_3355.class,args); &#125;&#125; 测试： 启动服务端Config_server_3344 再启动客户端ConfigClient 访问：http://localhost:8201/config/ 小案例本地新建config-dept.yml和config-eureka.yml并提交到码云仓库 config-dept.yml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566spring: profiles: active: dev---server: port: 8081mybatis: type-aliases-package: nuc.ss.springcloud.pojo config-location: classpath:mybatis/mybatis-config.xml mapper-locations: classpath:mybatis/mapper/*.xmlspring: profiles: dev application: name: springcloud-config-dept datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: org.gjt.mm.mysql.Driver url: jdbc:mysql://localhost:3306/db01?characterEncoding=utf-8&amp;useUnicode=true username: root password: admineureka: client: service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ instance: instance-id: springcloud-provider-dept-8081info: app.name: lzh-springcloud company.name: com.lzh---server: port: 8081mybatis: type-aliases-package: nuc.ss.springcloud.pojo config-location: classpath:mybatis/mybatis-config.xml mapper-locations: classpath:mybatis/mapper/*.xmlspring: profiles: test application: name: springcloud-config-dept datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: org.gjt.mm.mysql.Driver url: jdbc:mysql://localhost:3306/db02?characterEncoding=utf-8&amp;useUnicode=true username: root password: admineureka: client: service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ instance: instance-id: springcloud-provider-dept-8081info: app.name: lzh-springcloud company.name: com.lzh config-eureka.yml 1234567891011121314151617181920212223242526272829303132333435363738spring: profiles: active: dev---server: port: 7001spring: profiles: dev application: name: springcloud-config-eurekaeureka: instance: hostname: eureka7001.com client: register-with-eureka: false fetch-registry: false service-url: defaultZone: http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/---server: port: 7001spring: profiles: test application: name: springcloud-config-eurekaeureka: instance: hostname: eureka7001.com client: register-with-eureka: false fetch-registry: false service-url: defaultZone: http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ 上传成功 新建springcloud-config-eureka-7001模块，并将原来的springcloud-eureka-7001模块下的内容拷贝的该模块。 清空该模块的application.yml配置 1234spring: application: name: springcloud-config-eureka-7001 并新建bootstrap.yml连接远程配置 12345678spring: cloud: config: name: config-eureka # 仓库中的配置文件名称 label: main profile: dev uri: http://localhost:3344 在pom.xml中添加spring cloud config依赖 123456&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;version&gt;2.1.1.RELEASE&lt;/version&gt;&lt;/dependency&gt; 主启动类 12345678@SpringBootApplication@EnableEurekaServerpublic class EurekaServer_7001 &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServer_7001.class,args); &#125;&#125; 测试 启动 Config_Server_3344，并访问 http://localhost:3344/master/config-eureka-dev.yml 测试 启动ConfigEurekaServer_7001，访问 http://localhost:7001/ 测试 显示上图则成功 新建springcloud-config-dept-8081模块并拷贝springcloud-provider-dept-8081的内容 同理导入spring cloud config依赖、清空application.yml 、新建bootstrap.yml配置文件并配置 12345678spring: cloud: config: name: config-dept label: main profile: dev uri: http://localhost:3344 主启动类 12345678910111213141516171819//启动类@SpringBootApplication@EnableEurekaClient //在服务启动后自动注册到Eureka中@EnableDiscoveryClient //服务发现~@EnableCircuitBreaker//添加对熔断的支持public class DeptProvider_8081 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptProvider_8081.class,args); &#125; //增加一个 Servlet @Bean public ServletRegistrationBean hystrixMetricsStreamServlet()&#123; ServletRegistrationBean registrationBean = new ServletRegistrationBean(new HystrixMetricsStreamServlet()); //访问该页面就是监控页面 registrationBean.addUrlMappings(&quot;/actuator/hystrix.stream&quot;); return registrationBean; &#125;&#125; 只需更改github远程即可实现部署","categories":[],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://www.xc234.ltd/tags/SpringCloud/"}]},{"title":"SpringBoot注解整理笔记","slug":"SpringBoot注解笔记","date":"2021-01-10T04:12:15.000Z","updated":"2022-03-29T02:23:40.759Z","comments":true,"path":"2021/01/10/SpringBoot注解笔记/","link":"","permalink":"http://www.xc234.ltd/2021/01/10/SpringBoot%E6%B3%A8%E8%A7%A3%E7%AC%94%E8%AE%B0/","excerpt":"","text":"一、注解(annotations)列表1.@SpringBootApplication 包含了@ComponentScan、@Configuration和@EnableAutoConfiguration注解。其中@ComponentScan让Spring Boot扫描到Configuration类并把它加入到程序上下文。 2.@ComponentScan 组件扫描，可自动发现和装配一下Bean 3.@Configuration 等同于Spring的XML配置文件；使用Java代码可以检查类型安全 4.@EnableAutoConfiguration 自动配置 5.@RestController该注解是@Controller和@ResponseBody的合集，表示这是个控制器Bean，并且是将函数的返回值直接填入HTPP响应体中，是REST风格的控制器 6.@Autowired自动导入 7.@PathVariable获取参数 8.@JsonBackReference (未使用过)解决嵌套外链问题 9.@RepositoryRestResourcepublic (未使用过)配合spring-boot-starter-data-rest使用 二、注解(annotations)详解1.@SpringBootApplication申明让Spring Boot自动给程序进行必要的配置，这个配置等同于：@Configuration ，@EnableAutoConfiguration 和 @ComponentScan 三个配置。 12345678910import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplication// same as @Configuration @EnableAutoConfiguration @ComponentScanpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; 2.@ResponseBody表示该方法的返回值结果直接写入HTTP Response Body中，一般在异步获取数据时使用，用于构建RESTful的api。 在使用 @RequestMapping 后，返回值通常解析为跳转路径，加上@ResponseBody后返回结果是不会被解析为跳转路径，而是直接写入HTTP Response Body中。 比如异步获取json数据，加上@ResponseBody后，会直接返回json数据。 该注解一般会配合@RequestMapping一起使用 示例代码： 12345@RequestMapping(“/test”)@ResponseBodypublic String test()&#123; return ”ok”;&#125; 3.@Controller 用于定义控制器类，在spring项目中由控制器负责将用户发来的URL请求转发到对应的服务接口（service层） 一般这个注解在类中，通常方法需要配合注解 @RequestMapping。 实例代码： 123456789101112131415@Controller@RequestMapping(&quot;/demoInfo&quot;)publicclass DemoController &#123; @Autowired private DemoInfoService demoInfoService; @RequestMapping(&quot;/hello&quot;) public String hello(Map map)&#123; System.out.println(&quot;DemoController.hello()&quot;); map.put(&quot;hello&quot;,&quot;from TemplateController.helloHtml&quot;); // 会使用hello.html或者hello.ftl模板进行渲染显示. return&quot;/hello&quot;; &#125;&#125; 4.@RestController 用于标注控制层组件(如struts中的action)，@ResponseBody和@Controller的合集。 实例代码： 123456789101112import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@RestController@RequestMapping(“/demoInfo2”)publicclass DemoController2 &#123; @RequestMapping(&quot;/test&quot;) public String test()&#123; return&quot;ok&quot;; &#125;&#125; 5.@RequestMapping 提供路由信息，负责URL到Controller中的具体函数的映射。 6.@EnableAutoConfiguration Spring Boot自动配置（auto-configuration）：尝试根据你添加的jar依赖自动配置你的Spring应用。 7.@ComponentScan 表示将该类自动发现扫描组件 8.@Configuration 相当于传统的xml配置文件，如果有些第三方库需要用到xml文件，建议仍然通过@Configuration类作为项目的配置主类——可以使用@ImportResource注解加载xml配置文件。 9.@Import 用来导入其他配置类 10.@ImportResource 用来加载xml配置文件。 11.@Autowired 自动导入依赖的bean。byType方式。把配置好的Bean拿来用，完成属性、方法的组装，它可以对类成员变量、方法及构造函数进行标注，完成自动装配的工作。当加上（required=false）时，就算找不到bean也不报错。 12.@Service 一般用于修饰service层的组件 13.@Repository 使用@Repository注解可以确保DAO或者repositories提供异常转译，这个注解修饰的DAO或者repositories类会被ComponetScan发现并配置，同时也不需要为它们提供XML配置项。 14.@Bean 用@Bean标注方法等价于XML中配置的bean。 相当于XML中的,放在方法的上面，而不是类，意思是产生一个bean,并交给spring管理 15.@Value 注入Spring boot application.properties配置的属性的值。 示例代码： 12@Value(value = “#&#123;message&#125;”)private String message; 16.@Inject 等价于默认的@Autowired，只是没有required属性； 17.@Component 泛指组件，当组件不好归类的时候，我们可以使用这个注解进行标注。 18.@Qualifier 当有多个同一类型的Bean时，可以用@Qualifier(“name”)来指定。与@Autowired配合使用。@Qualifier限定描述符除了能根据名字进行注入，但能进行更细粒度的控制如何选择候选者，具体使用方式如下： 123@Autowired@Qualifier(value = “demoInfoService”)private DemoInfoService demoInfoService; 19.@Resource(name=”name”,type=”type”) 没有括号内内容的话，默认byName。与@Autowired干类似的事。 三、JPA注解1、@Entity：@Table(name=”“)表明这是一个实体类。一般用于jpa这两个注解一般一块使用，但是如果表名和实体类名相同的话，@Table可以省略。 2、@MappedSuperClass用在确定是父类的entity上。父类的属性子类可以继承。 3、@NoRepositoryBean一般用作父类的repository，有这个注解，Spring不会去实例化该repository。 4、@Column如果字段名与列名相同，则可以省略。 5、@Id表示该属性为主键。 6@GeneratedValue(strategy=GenerationType.SEQUENCE,generator= “repair_seq”)表示主键生成策略是sequence（可以为Auto、IDENTITY、native等，Auto表示可在多个数据库间切换），指定sequence的名字是repair_seq。 7、@SequenceGeneretor(name = “repair_seq”, sequenceName = “seq_repair”, allocationSize = 1)name为sequence的名称，以便使用，sequenceName为数据库的sequence名称，两个名称可以一致。 8、@Transient表示该属性并非一个到数据库表的字段的映射,ORM框架将忽略该属性。 如果一个属性并非数据库表的字段映射,就务必将其标示为@Transient,否则,ORM框架默认其注解为@Basic。 9、@Basic(fetch=FetchType.LAZY)标记可以指定实体属性的加载方式。 10、@JsonIgnore作用是json序列化时将Java bean中的一些属性忽略掉,序列化和反序列化都受影响。 11、@JoinColumn（name=”loginId”）一对一：本表中指向另一个表的外键。一对多：另一个表指向本表的外键。 12、@OneToOne、@OneToMany、@ManyToOne对应hibernate配置文件中的一对一，一对多，多对一。 四、SpringMVC相关注解1.@RequestMapping@RequestMapping(“/path”)表示该控制器处理所有“/path”的UR L请求。 RequestMapping是一个用来处理请求地址映射的注解，可用于类或方法上。 用于类上，表示类中的所有响应请求的方法都是以该地址作为父路径。该注解有六个属性： params:指定request中必须包含某些参数值是，才让该方法处理。 headers:指定request中必须包含某些指定的header值，才能让该方法处理请求。 value:指定请求的实际地址，指定的地址可以是URI Template 模式 method:指定请求的method类型， GET、POST、PUT、DELETE等 consumes:指定处理请求的提交内容类型（Content-Type），如application/json,text/html; produces:指定返回的内容类型，仅当request请求头中的(Accept)类型中包含该指定类型才返回。 2.@RequestParam 用在方法的参数前面。 3. @PathVariable 路径变量。如： 1234RequestMapping(“user/get/&#123;macAddress&#125;”)public String getByMacAddress(@PathVariable String macAddress)&#123; //do something;&#125; 五、全局异常处理@ControllerAdvice：包含@Component。可以被扫描到。统一处理异常。 @ExceptionHandler（Exception.class）：用在方法上面表示遇到这个异常就执行以下方法。","categories":[],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.xc234.ltd/tags/SpringBoot/"}]},{"title":"什么是MySQL索引，为什么要有索引？","slug":"什么是MySQL索引，为什么要有索引？","date":"2021-01-08T03:19:00.000Z","updated":"2022-03-29T02:23:40.762Z","comments":true,"path":"2021/01/08/什么是MySQL索引，为什么要有索引？/","link":"","permalink":"http://www.xc234.ltd/2021/01/08/%E4%BB%80%E4%B9%88%E6%98%AFMySQL%E7%B4%A2%E5%BC%95%EF%BC%8C%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E6%9C%89%E7%B4%A2%E5%BC%95%EF%BC%9F/","excerpt":"","text":"一、什么是索引？索引就好比字典的目录一样，我们通常都会先去目录查找关键偏旁或者字母再去查找，要比直接翻查字典查询要快很多 二、为什么要有索引？然而我们在使用mysql数据库的时候也像字典一样有索引的情况下去查询，肯定速度要快很多 2.1问题1.mysql数据存储在什么地方？磁盘 2.查询数据慢，一般卡在哪？磁盘IO 3.索引存储在哪？ 磁盘，查询数据的时候会优先将索引加载到内存中 4.索引在存储的时候，需要什么信息？需要存储什么字段值？key:实际数据行中存储的值 文件地址 offset:偏移量 5.这种格式的数据要使用什么样的数据结构来进行存储？ key-values 哈希表，树(二叉树、红黑树、AVL树、B树、B+树) 三、mysql的索引数据结构3.1哈希表 HashMap数据加链表的结构，不适合作为索引的原因： 1.哈希冲突会造成数据散列不均匀，会产生大量的线性查询，比较浪费时间 2.不支持范围查询，当进行范围查询的时候，必须挨个遍历 3.对于内存空间的要求比较高 优点： 如果是等值查询，非常快 在mysql中有没有hash索引?1.memory存储引擎使用的是hash索引 2.innodb支持自适应hash 123create table test(id int primary key,name varchar(30))engine=&#x27;innodb/memory/myisam&#x27;-- 5.1之后默认innodb 3.2树: 树这种数据结构有很多，我们常见的有： 二叉树、BST、AVL、红黑树、B树、B+树 ①二叉树：无序插入 这就是我们的树的结构图，但是二叉树的数据插入是无序的，也就是说当需要查找的时候，还是得一个一个挨着去遍历查找 ②BST(二叉搜索树)： 插入的数据有序，左子树必须小于根节点，右子树必须大于根节点——–使用二分查找来提高效率 这样的话如果要查询数据，可以通过二分查找，快速缩小范围，减少了时间复杂度 但是如果插入的顺序是升序或者降序的话，树的形状会变成如下： 此时二叉搜索树就会退化成链表，时间复杂度又会变成O(n) ③AVL：平衡二叉树 为了解决上述问题，通过左旋转或右旋转让树平衡 最短子树跟最长子树高度只差不能超过1 由图我们可以看到，当顺序插入的时候，会自动的进行旋转，以达到平衡 但是会通过插入性能的损失来弥补查询性能的提升 当我们插入的数据很多时候，而查询很少的时候，由于插入数据会旋转同样会消耗很多时间 ④红黑树(解决了读写请求一样多) 同样是经过左右旋让树平衡起来，还要变色的行为 最长子树只要不超过最短子树的两倍即可 查询性能和插入性能近似取得平衡 但是随着数据的插入、发现树的深度会变深，树的深度会越来越深，意味着IO次数越多，影响数据读取的效率 ⑤ B树 为了解决上述数据插入过多，树深度变深的问题，我们采用B树 把原来的有序二叉树变成有序多叉树 举例： 如果要查询select * from table where id=14？ 第一步，将磁盘一加载到内存中，发现14&lt;16,寻找地址磁盘2 第二步，将磁盘二加载到内存中，发现14&gt;11,寻找地址磁盘7 第三步，将磁盘七加载到内存中，发现14=14，读取data，取出data，结束 思考：B树就是完美的嘛？ 问题1： B树不支持范围查询的快速查找，如果我们查询一个范围的数据，查找到范围一个边界时，需要回到根节点重新遍历查找，需要从根节点进行多次遍历，即便找到范围的另一个边界，查询效率会降低。 问题2： 如果data存储的是行记录，行的大小随着列数的增多，所占空间会变大。这时，一个页中可存储的数据量就会变少，树相应就会变高，磁盘IO次数就会变大。 思考2：三层B树能够存储多少条记录？ 答: 假设一个data为1k，innodb存储引擎一次读取数据为16k，三层即161616=4096； 但是往往在开发中，一个表的数据要远远大于4096，难道要继续加层，这样岂不就加大了IO 四、为什么使用B+树？实际存储表数据的时候，怎么存储呢？ key 完整的数据行 改造B+树 B+树对B树进行了改进，把数据全放在了叶子节点中，叶子节点之间使用双向指针连接，最底层的叶子节点形成了一个双向有序链表。 例如： 查询范围 select * from table where id between 11 and 35？ 第一步，将磁盘一加载到内存中，发现11&lt;28,寻找地址磁盘2 第二步，将磁盘二加载到内存中，发现10&gt;11&gt;17,寻找地址磁盘5 第三步，将磁盘五加载到内存中，发现11=11，读取data 第四步，继续向右查询，读取磁盘5，发现35=35，读取11-35之间数据，结束 由此可见，这样的范围查询比B树速度提高了不少 对比B树和B+树？ 叶子节点中才放数据 非叶子节点中不存储数据 B+树每个节点包含更多个节点，这样做的好处，可以降低树的高度，同时将数据范围变成多个区间，区间越多查询越快 问题： 创建索引时用int还是varchar？ 答：视情况而定，但是记住一定让key越小越好 五、索引的创建在创建索引之前，我先说一下存储引擎 存储引擎： 表示不同的数据在磁盘的不同表现形式 大家去观察mysql的磁盘文件会发现 innodb： innodb的数据和索引都存储在一个文件下.idb myisam： myisam的索引存储在.MYI文件中，数据存储在.MYD中 5.1聚簇索引和非聚簇索引概念：判断是否是聚簇索引就看数据和索引是否在一个文件中 innodb： 只能有一个聚簇索引，但是有很多非聚簇索引 向innodb插入数据的时候，必须要包含一个索引的key值 这个索引的key值，可以是主键，如果没有主键，那么就是唯一键，如果没有唯一键，那么就是一个自生成的6字节的rowid myisam： 非聚簇索引 MySQL—innodb—-B+树 索引和数据存储在一起，找到索引即可读取对应的数据 5.2回表 接下来，我会创建一张案例表给大家展示 12345678910111213141516CREATE TABLE user_test(id INT PRIMARY KEY AUTO_INCREMENT,-- id为主键uname VARCHAR(20) ,age INT,gender VARCHAR(10), KEY `idx_uname` (`uname`) -- 索引选择为名字)ENGINE = INNODB;INSERT INTO user_test VALUES(1,&#x27;张三&#x27;,18,&#x27;男&#x27;);INSERT INTO user_test VALUES(NULL,&#x27;马冬梅&#x27;,19,&#x27;女&#x27;);INSERT INTO user_test VALUES(NULL,&#x27;赵四&#x27;,18,&#x27;男&#x27;);INSERT INTO user_test VALUES(NULL,&#x27;王老七&#x27;,22,&#x27;男&#x27;);INSERT INTO user_test VALUES(NULL,&#x27;刘燕&#x27;,16,&#x27;女&#x27;);INSERT INTO user_test VALUES(NULL,&#x27;万宝&#x27;,26,&#x27;男&#x27;); 123select * from user_test where uname = &#x27;张三&#x27;;-- 当我们表中有主键索引的时候，我们再去设置一个uname为索引，那么此时这条sql语句的查询过程应该如下： 首先先根据uname查询到id，再根据id查询到行的信息 这样的操作走了两棵B+树，就是回表 当根据普通索引查询到聚簇索引的key值之后，再根据key值在聚簇索引中获取数据 我们可以发现这样的操作是很浪费时间的，因此我们日常操作的时候，尽量减少回表的次数 5.3覆盖索引12345select id,uname from table where uname = &#x27;张三&#x27;;-- 根据uname 可以直接查询到id，uname两个列的值，直接返回即可-- 不需要从聚簇索引查询任何数据，此时叫做索引覆盖 5.4最左匹配 在说最左匹配之前，我们先聊一下几个名词 主键(一般为一个列)——–&gt;联合主键(多个列) 索引——–&gt;联合索引(可能包含多个索引列) 1234567891011-- 假设有一张表，有id，name，age，gender四个字段，id是主键，name，age是组合索引列-- 组合索引使用的时候必须先匹配name，然后匹配ageselect * from table where name = ? and age = ? ;-- 生效select * from table where name = ?;-- 生效select * from table where age = ? ;-- 不生效select * from table where age = ? and name = ? ;-- 生效--在mysql内部有优化器会调整对应的顺序 5.5索引下推 mysql5.7之后，默认支持的一个特点 举一个例子： 1234567select * from table where name = ? and age = ? ;-- mysql里的三层架构:-- 客户端:JDBC-- 服务端:server-- 存储引擎:数据存储在没有索引下推之前，根据name从存储引擎中获取符合规则的数据，在server层对age进行过滤有索引下推之后，根据name、age两个条件从存储引擎中获取对应的数据 分析：有索引下推的好处，如果我们有50条数据，我们通过过滤会得到10条数据，如果没有索引下推，会先获取50条再去排除得到10条，而有了下推之后，我们会直接在存储引擎就过滤成了10条 原作者：你丫才CRUD 原文链接：","categories":[],"tags":[{"name":"MySql","slug":"MySql","permalink":"http://www.xc234.ltd/tags/MySql/"},{"name":"索引","slug":"索引","permalink":"http://www.xc234.ltd/tags/%E7%B4%A2%E5%BC%95/"}]},{"title":"JAVA前端与后端交互的知识点总结","slug":"我自己的第一篇博客","date":"2021-01-01T02:39:20.000Z","updated":"2022-03-29T02:23:40.768Z","comments":true,"path":"2021/01/01/我自己的第一篇博客/","link":"","permalink":"http://www.xc234.ltd/2021/01/01/%E6%88%91%E8%87%AA%E5%B7%B1%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/","excerpt":"","text":"1.1. 描述Servlet调用过程？ （1）在浏览器输入地址，浏览器先去查找hosts文件，将主机名翻译为ip地址，如果找不到就再去查询dns服务器将主机名翻译成ip地址。（2）浏览器根据ip地址和端口号访问服务器，组织http请求信息发送给服务器。（3）服务器收到请求后首先根据Host请求头判断当前访问的是哪台虚拟主机。（4）服务器根据http请求头中的请求URI判断当前访问的是哪个web应用。（5）服务器根据http请求头中的请求URI判断当前访问的是web应用中的哪个web资源。（6）检查web应用的web.xml文件，如果根据路径找到具体的servlet处理类的全路径名交给该servlet处理,如果找不到就交给缺省servlet处理。（7）这个过程中浏览器只知道自己发出来http请求，不久就收到了http响应，浏览器不知道也不关心服务器内部是如何处理的。浏览器和服务器之间的关系是非常单纯的，只有HTTP协议。（8）解析请求、封装RequestResponse对象、创建Servlet、调用Service方法都是服务器自动进行的，开发人员只需要写好Servlet配置进容器中即可，无需操心具体的底层实现。 1.2. 简述Servlet生命周期？1.Servlet第一次被访问到时创建对象，创建出来后立即执行init方法执行初始化的操作。2.从此以后该对象一直驻留在内存中为后续的对这个Servlet的请求进行服务。3.直到服务器关闭或web应用移除出容器时，随着web应用的销毁Servlet对象销毁掉，在销毁之前调用destory方法执行善后工作。4.在存活期间，每次对Servlet 的调用都会导致Service方法的执行。 1.3. 什么是http协议？ HTTP协议就是一套基于tcp/ip协议的应用层协议 。简单来说，就是一个基于应用层的通信规范，双方要进行通信，大家都要遵守一个规范，这个规范就是HTTP协议。它规定了客户端（通常是浏览器）和服务器之间的通信方式。 1.4. HTTP协议工作原理？ HTTP协议基于请求响应模型。一次请求对应一次响应。首先客户端发送一个请求(request)给服务器，服务器在接收到这个请求后将生成一个响应(response)返回给客户端。 1.5. HTTP协议的特点是什么 ? （1） 它是一个无状态的协议，服务器端在处理相应请求后不会保留任何客户端的信息，每次请求都是独立的（2） 客户端与服务器端的每一次数据交互，都要经过一次请求/响应的过程。（3） 服务器端无法识别能够出发客户端请求的方法。（4） 一个典型的HTTP请求分为 一个请求行 若干请求头 一个空行 实体内容 1.6. get和post请求的区别？ 1） get请求用来从服务器上获得资源，而post是用来向服务器提交数据；（2） get将表单中数据按照name=value的形式，添加到action 所指向的URL 后面，并且两者使用”?“连接，而各个变量之间使用”&amp;“连接；post是将表单中的数据放在HTTP协议的请求头或消息体中，传递到action所指向URL；（3） get传输的数据要受到URL长度限制（1024字节）；而post可以传输大量的数据， POST数据是没有限制的，上传文件通常要使用post方式；（4） 使用get时参数会显示在地址栏上，如果这些数据不是敏感数据，那么可以使用get；对于敏感数据还是应用使用post；（5） get使用MIME类型application/x-www-form-urlencoded的URL编码（也叫百分号编码）文本的格式传递参数，保证被传送的参数由遵循规范的文本组成，例如一个空格的编码是”%20”。（6） Jsp页面中的FORM标签里的method属性为get时调用doGet()，为post时调用doPost()。 1.7. 请求乱码产生的原因？ 浏览器用什么码表来打开表单页面就用什么编码来发送数据。当前我们的注册页面指定了用utf-8来打开。这就决定了浏览器是用utf-8打开的页面，浏览器在提交表单时是用utf-8编码的。而tomcat默认情况下会使用iso8859-1来进行解码。我们知道全世界的码表都兼容iso8859-1，所以英文处理是没有问题的。但是iso8859-1中并没有中文，iso8859-1对于无法处理的字节都使用?替代，所以我们看到的都是？ 1.8. 如何来处理get请求产生的乱码? 由于客户端发送时使用的是utf-8编码而服务器用iso8859-1解码造成了乱码，虽然字符已经乱掉了，但底层的字节仍然是正确的，我们只要将乱码字符getBytes(“iso8859-1”)转换为字节，就是正确的字节，再将这些字节new String(bytes，“utf-8”)按照正确的码表编码，就可以转换回正确的字符了。从而解决了乱码。 1.9. Request生命周期 request对象的生命周期是针对一个客户端(一个浏览器应用程序)的一次请求，当请求完毕之后，request里边的内容也将被释放，一个请求开始时创建，请求结束后销毁。 1.10. 如何处理响应乱码？ 通过response.setHeader(“Content-Type”, “text/html;charset=utf-8”)方法，通知服务器发送数据时的码表；通过response.setCharacterEncoding(“utf-8”)方法，通知浏览器解析时使用的码表。两码相同就不会有乱码了。response提供了setContentType(“text/html;charset=UTF-8”)快捷方法，在它的底层，会同时做上面两件事，所以可以一行代码解决response产生的乱码问题。 1.11. 简述ServletContext生命周期？ServletContext对象代表当前web应用。当服务器启动时，服务器在启动时会依次加载web应用，每一个web应用加载完成后都会创建一个ServletContext对象唯一代表该web应用，这个对象一直存活，直到web应用移除出容器或服务器关闭时，随着应用销毁，ServletContext对象跟着销毁。 1.12. 转发与重定向的比较？ 重定向：首先服务器受到浏览器客户端请求之后，服务器发送新的链接到客户端浏览器，浏览器接收到新的链接之后又重新请求收到的链接地址，在整个过程中完成之后在客户端浏览器看来是发生了一次跳转，其实是客户端浏览器请求了两次而已，所以在浏览器的地址栏里网络地址自然就会改变成新的连接 转发：服务器接收到客户端的请求之后，服务器把控制权交到另一个JSP页面手里，新的JSP页面接收到请求之后根据情况是继续转交控制权或者显示页面由自己决定，到最后显示页面的整个过程就是一个页面跳转过程，在这个过程中，服务器可以把请求的数据在经过的页面进行传递，而不会担心数据的丢失 1.转发在服务器端完成的；重定向是在客户端完成的 2.转发的速度快；重定向速度慢 3.转发的是同一次请求；重定向是两次不同请求 4.转发不会执行转发后的代码；重定向会执行重定向之后的代码 5.转发地址栏没有变化；重定向地址栏有变化 6.转发必须是在同一台服务器下完成；重定向可以在不同的服务器下完成 1.13. Session生命周期？ 当程序第一次调用到request.getSession()代码时,服务器明确的知道了需要用到session了,此时创建session。如果session超过30分钟(可以在web.xml中配置的)没人使用,服务器认为这个session超时了,销毁session。明确的调用session.invalidate(),session立即销毁。服务器被非正常关闭或web应用被移除出容器,此时随着web应用的销毁session销毁.如果是正常关闭,session会被钝化.当下次服务器正常启动时,没有超时的session还会被活化回来。 1.14. session的原理？ session的原理：在服务器第一次调用request.getSession()方法的时候，会在内存中创建一个session对象，此对象具有一个独一无二的id值，此id值将会以cookie（JSESSIONID）的形式发送给浏览器，浏览器以后每次访问都会带着此cookie，服务器就利用此cookie区分浏览器找到对应的session空间。 1.15. cookie与session的区别 cookie数据存放在客户的浏览器上，session数据放在服务器上cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗，考虑到安全应当使用sessionsession会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能，考虑到减轻服务器性能方面，应当使用COOKIE 1.16. JSP和Servlet是什么关系？1.17. JSP的九大隐式对象是哪九个 1：request: 请求对象 在javax.servlet.ServletRequest 作用域为Request来自客服端的请求，如：FORM表单中填写的信息，常用的方法有getParameter，getParamterName 和getParamterValue通过表用获取请求对象中包含的参数值。2:response表示客服端的响应。3：pageContext对象为页面的上下文对象，代表当请运行页面的一些属性。4：session：对象代码服务器与客服端所建立的会话，比如在写购物，客服轨迹跟踪，session”是建立在cookie的基础之上的。常用方法有getId,getValues等。5：application对象负责提供应用程序在服务端运行时的一些全局信息，方法有getMimeType等。6：out：与response不同，通过out对象发送的内容是浏览器需要的显示内容，还可以直接想客服端编写一个有程序动态生成的HTML的文件。7：page：page里的变量没法从index.jsp传递到test.jsp。只要页面跳转了，就不见了。8： exception：他是一个列外的对象，当页面发生了列外，就会会创建该对象。9：config：是在servlet初始化Servlet的时候，JSP引擎向他传递信息用的，此消息包括Servlet初始化时所需要的参数。 1.19. Mysql数据库优化 (1)查询时，能不用* 就不用，尽量写全字段名。(2)索引不是越多越好，每个表控制在6个索引以内。范围where条件的情况下，索引不起作用，比如where value&lt;100(3)大部分情况连接效率远大于子查询，但是有例外。当你对连接查询的效率都感到不能接受的时候可以试试用子查询，虽然大部分情况下你会更失望，但总有碰到惊喜的时候不是么…(4)多用explain 和 profile分析查询语句(5)有时候可以1条大的SQL可以分成几个小SQL顺序执行，分了吧，速度会快很多。(6)每隔一段时间用alter table table_name engine=innodb;优化表(7)连接时注意:小表 jion 大表的原则(8)学会用explain 和 profile判断是什么原因使你的SQL慢(9)查看慢查询日志，找出执行时间长的SQL进行优化(10)尽量避免使用order by(11)因为where子句后面的条件是执行顺序是从右到左，所以尽量把能过滤掉大部分数据的条件放在最后 1.22. 什么是数据库连接池及其工作原理 对于共享资源，有一个很著名的设计模式：资源池（resource pool）。该模式正是为了解决资源的频繁分配﹑释放所造成的问题。为解决上述问题，可以采用数据库连接池技术。数据库连接池的基本思想就是为数据库连接建立一个“缓冲池”。预先在缓冲池中放入一定数量的连接，当需要建立数据库连接时，只需从“缓冲池”中取出一个，使用完毕之后再放回去。我们可以通过设定连接池最大连接数来防止系统无尽的与数据库连接。更为重要的是我们可以通过连接池的管理机制监视数据库的连接的数量﹑使用情况，为系统开发﹑测试及性能调整提供依据。 1.24. http和https的区别？ HTTP协议传输的数据都是未加密的，也就是明文的，因此使用HTTP协议传输隐私信息非常不安全，为了保证这些隐私数据能加密传输，于是网景公司设计了SSL（Secure Sockets Layer）协议用于对HTTP协议传输的数据进行加密，从而就诞生了HTTPS。简单来说，HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全。 1.28. request.getParameter()和request.getAttribute()的区别？ a、request.getParameter()获取的类型是String；request.getAttribute()获取的类型是Objectb、request.getPrameter()获取的是POST/GET传递的参数值和URL中的参数；request.getAttribute()获取的是对象容器中的数据值/对象c、request.setAttribute()和request.getAttribute()可以发送、接收对象；request.getParamter()只能接收字符串，官方不开放request.setParamter()（也就是没有这个方法）setAttribute()和getAttribute()的传参原理：setAttribute()是应用服务器把这个对象放在该页面所对应的一块内存中去，当你的页面服务器重定向到另外一个页面时，应用服务器会把这块内存拷贝到另一个页面所对应的那块内存中。这个就可以通过getAttribute()获取到相应的参数值或者对象。 1.30. 详细描述MVC 基于java的web应用系统采用MVC设计模型，即用Model（模型）、View（视图）和Controller（控制）分离设计，这是目前web应用服务系统的主流设置方向。Model：处理业务逻辑的模块。View：负责页面显示，显示Model的处理结果给用户，主要实现数据到页面的转换过程。Controller：负责每个请求的分发，把Form数据传递给Model进行处理，处理完成后，把处理结果返回给相应的View显示给用户。 1.37. 简述web.xml的作用 属于部署描述符，在整个JAVA中只要是容器都会存在部署描述符，此部署描述符可以控制整个WEB中各个组件的运行状态，也可以配置整个窗口的状态 1.44. HTML和xml的区别？ XML是可扩展标记语言，而HTML超文本标记语言。不同之处：1、语法有所不同。XML语法比较严谨而HTML语法比较松散。2、用途不同。XML主要用于数据格式化存储而HTML主要用于网页的编辑。 1.56. Spring 在ssm中起什么作用？ Spring：轻量级框架作用：Bean工厂，用来管理Bean的生命周期和框架集成。两大核心：1、IOC/DI(控制反转/依赖注入) ：把dao依赖注入到service层，service层反转给action层，Spring顶层容器为BeanFactory。2、AOP：面向切面编程 1.57. Spring的配置文件中的内容？ 开启事务注解驱动事务管理器开启注解功能，并配置扫描包配置数据库配置SQL会话工厂，别名，映射文件不用编写Dao层的实现类 1.58. Spring主要使用了什么模式？ 工厂模式：每个Bean的创建通过方法单例模式：默认的每个Bean的作用域都是单例代理模式：关于Aop的实现通过代理模式 1.60. Mybatis的好处？把Sql语句从Java中独立出来封装了底层的JDBC，API的调用，并且能够将结果集自动转换成JavaBean对象，简化了Java数据库编程的重复工作。自己编写Sql语句，更加的灵活。入参无需用对象封装（或者map封装）,使用@Param注解","categories":[],"tags":[{"name":"java后端","slug":"java后端","permalink":"http://www.xc234.ltd/tags/java%E5%90%8E%E7%AB%AF/"}]},{"title":"blog_image_source","slug":"blog_image_source","date":"2020-01-01T09:33:47.000Z","updated":"2022-03-29T02:23:40.760Z","comments":true,"path":"2020/01/01/blog_image_source/","link":"","permalink":"http://www.xc234.ltd/2020/01/01/blog_image_source/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"学习html的笔记","slug":"学习html的笔记","date":"2018-05-12T07:49:16.000Z","updated":"2022-03-29T02:23:40.763Z","comments":true,"path":"2018/05/12/学习html的笔记/","link":"","permalink":"http://www.xc234.ltd/2018/05/12/%E5%AD%A6%E4%B9%A0html%E7%9A%84%E7%AC%94%E8%AE%B0/","excerpt":"","text":"1.初识HTML HTML全程是HyperTextMarkupLanguage(超文本标记语言) 、等成对的标签，分别叫做开放标签和闭合标签 单独呈现的标签（空元素）， 如&lt; hr/ &gt;;意为用/来关闭空元素。 html的注释为 1234567891011121314151617181920&lt;!--DOCTYPE：告诉浏览器使用什么规范（默认是html）--&gt;&lt;!DOCTYPE html&gt;&lt;!--语言 zh中文 en英文--&gt;&lt;html lang=&quot;zh&quot;&gt;&lt;!--head标签代表网页头部--&gt;&lt;head&gt;&lt;!-- meta 描述性标签，表示用来描述网站的一些信息--&gt;&lt;!-- 一般用来做SEO--&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;meta name=&quot;keywords&quot; content=&quot;hyx的java学习&quot;&gt; &lt;meta name=&quot;description&quot; content=&quot;一起来学习java&quot;&gt; &lt;!--网站标题--&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;!--body代表主体--&gt;&lt;body&gt;Hello World！&lt;/body&gt;&lt;/html&gt; 2.网页基本标签 标题标签 段落标签 换行标签 水平线标签 字体样式标签 注释和特殊符号 1234567891011121314151617181920212223242526272829303132333435363738&lt;!DOCTYOE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;基本标签&lt;/title&gt;&lt;/head&gt;&lt;/html&gt;&lt;body&gt;&lt;h1&gt;一级标签&lt;/h1&gt;&lt;!--标题标签--&gt;&lt;h2&gt;二级标签&lt;/h2&gt;&lt;h3&gt;三级标签&lt;/h3&gt;&lt;h4&gt;四级标签&lt;/h4&gt;&lt;h5&gt;五级标签&lt;/h5&gt;&lt;h6&gt;六级标签&lt;/h6&gt; &lt;!--段落标签--&gt;&lt;p&gt;p换行1&lt;/p&gt;&lt;p&gt;p换行2&lt;/p&gt;&lt;hr/&gt;&lt;!--水平线标签--&gt;换行1 &lt;br/&gt;&lt;!--换行标签--&gt;换行2 &lt;br/&gt;&lt;!--换行标签比较紧凑，段落标签有明显段间距--&gt;&lt;!--粗体 斜体--&gt;&lt;h1&gt;字体样式标签&lt;/h1&gt;粗体：&lt;strong&gt;I love you &lt;/strong&gt;&lt;br/&gt;斜体：&lt;em&gt;I love you &lt;/em&gt;&lt;br/&gt;&lt;!--特殊符号--&gt;空格：1&amp;nbsp;2&amp;nbsp;&amp;nbsp;3&amp;nbsp;&amp;nbsp;&amp;nbsp;4&lt;br/&gt;空格：1 2 3 4&lt;br/&gt;大于号&amp;gt;&lt;br/&gt;小于号&amp;rt;&lt;br/&gt;版权符号&amp;copy;&lt;br/&gt;&lt;!--特殊符号记忆：&amp;开头;结尾，只要在idea中&amp;敲出后就有提示--&gt;&lt;/body&gt;&lt;/html&gt; 图像标签 链接标签 ​ href: 必填，表示要跳转到那个页面 ​ target: 标签窗口在那里打开 ​ _blank: 在标签中打开 ​ _self: 在自己的网页中打开 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;图像和链接标签&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;!--src:资源地址 相对地址，绝对地址 ../上级地址 alt：在图片加载失败的时候，就会用文字代替 title:鼠标悬停在图片上时，所显示的名字 width height 图片的高和宽--&gt;&lt;img src=&quot;../xxx.jpg&quot; alt=&quot;oops!图像不见了&quot; title=&quot;123&quot;&gt;&lt;br/&gt;&lt;!--href：跳转页面的地址 a标签内文字：即显示的文字 可以把图片放在a标签内，点击图片跳转网页 target:表示在哪打开新网页_self:当前标签打开 _blank:新的页面中打开--&gt;&lt;a href=&quot;https://www.baidu.com&quot; target=&quot;_blank&quot; title=&quot;456&quot;&gt;自生自灭&lt;/a&gt;&lt;a href=&quot;https://www.baidu.com&quot; target=&quot;_blank&quot; title=&quot;123&quot;&gt;你xxxx不会百度吗&lt;/a&gt;&lt;br/&gt;&lt;a href=&quot;https://www.baidu.com&quot;&gt;&lt;img src=&quot;../xxx.jpg&quot; alt=&quot;oops!图像不见了&quot;&gt;&lt;/a&gt; &lt;!--锚链接 1.需要一个标记锚 2.跳转到标记 #页面内跳转--&gt;&lt;a name=&quot;top&quot;&gt;&lt;/a&gt;&lt;a href=&quot;#top&quot;&gt;回到顶部&lt;/a&gt;&lt;br/&gt;&lt;!--也可以在网址后添加#号跳到对应网站的对应位置--&gt;&lt;a href=&quot;https://www.baidu.com#down&quot;&gt;百度底部&lt;/a&gt; &lt;br/&gt; &lt;!--功能性链接邮箱链接：mailtoqq链接--&gt;&lt;a href=&quot;mailto:xxxxxxqq.com&quot;&gt;点击联系我&lt;/a&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://wpa.qq.com/msgrd?v=xxx&amp;uin=&amp;site=qq&amp;menu=yes&quot;/&gt; &lt;a target=&quot;_blank&quot; href=&quot;http://wpa.qq.com/msgrd?v=xxx&amp;uin=&amp;site=qq&amp;menu=yes&quot;&gt; &lt;img border=&quot;0&quot; src=&quot;http://wpa.qq.com/pa?p=2::52&quot; alt=&quot;点击这里加我领取小电影&quot; title=&quot;点击这里加我领取小电影&quot;/&gt;&lt;/body&gt;&lt;/html&gt; 行内元素和块元素 块元素 ​ 无论内容多少，该元素独占一行 1例如：&lt;p&gt;&lt;/p&gt;&lt;hr/&gt; &lt;h1&gt;...&lt;h6&gt; ​ 行内元素:内容撑开宽度，左右都是行内元素的可以排在一行 12例如:&lt;a&gt;&lt;strong&gt;&lt;em&gt; 3.列表标签什么是列表 列表就是信息资源的一种展示形式。它可以使信息结构化和条理化，并以列表的样式显示出来，以便浏览者能更快捷地获得相应的信息。 列表的分类： 有序列表 123456&lt;ol&gt; &lt;li&gt;1&lt;/li&gt; &lt;li&gt;2&lt;/li&gt; &lt;li&gt;3&lt;/li&gt;&lt;/ol&gt; 无序列表 1234567891011&lt;ul&gt;&lt;!--无序列表--&gt; &lt;li&gt;123 &lt;ul&gt; &lt;li&gt;1&lt;/li&gt; &lt;li&gt;2&lt;/li&gt; &lt;li&gt;3&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;2&lt;/li&gt; &lt;li&gt;3&lt;/li&gt;&lt;/ul&gt; 定义列表 12345&lt;!--自定义列表dl：标签dt：列表名称dd：列表内容--&gt; 学科 语文 数学 英语 语言 中文 英语 日语 4.表格 单元格 行 列 跨行 跨列 123456789101112131415161718192021222324&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;表格&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;!--表格table 行 tr 列 td --&gt;&lt;table border=&quot;1px&quot;&gt; &lt;tr&gt;&lt;!--跨列--&gt; &lt;td rowspan=&quot;2&quot;&gt;2-1&lt;/td&gt; &lt;td&gt;2-2&lt;/td&gt; &lt;td&gt;2-3&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;3-2&lt;/td&gt; &lt;td&gt;3-3&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/body&gt;&lt;/html&gt; 5.视频和音频 vidio audio 1234567891011121314151617&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;媒体元素&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;!--视频 src 资源路径 controls 控制面板 autoplay 自动播放--&gt;&lt;video src=&quot;xxx/xxx/xxx&quot; controls autoplay&gt;&lt;/video&gt;&lt;!--音频--&gt;&lt;audio src=&quot;xxx/xxx/xxx&quot; controls autoplay&gt;&lt;/audio&gt;&lt;/body&gt;&lt;/html&gt; 6.页面结构 元素名 描述 header 标题头部取域的内容（用于页面或者页面的一块区域） footer 标记脚部区域的内容（用于整个页面或页面的一块区域） section Web页面中一块独立区域 article 独立的文章内容 aside 相关内容或应用 nav 导航类辅助内容 1234567891011121314151617181920&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;页面结构&lt;/title&gt; &lt;/head&gt;&lt;body&gt;&lt;!--页面头部--&gt;&lt;header&gt; &lt;h2&gt;网页头部&lt;/h2&gt;&lt;/header&gt; &lt;section&gt; &lt;h2&gt;网页主体&lt;/h2&gt;&lt;/section&gt;&lt;footer&gt; &lt;h2&gt;网页脚步&lt;/h2&gt;&lt;/footer&gt;&lt;/body&gt;&lt;/html&gt; 7.iframe内联框架1&lt;iframe src=&quot;path&quot; name=&quot;mainFrame&quot; &gt;&lt;/iframe&gt; ifram标签，必须要有src属性即引用页面的地址 给标签加上name属性后，可以做a标签的target属性，即在内联窗口中打开链接 8.表单语法（重点）","categories":[],"tags":[]}],"categories":[],"tags":[{"name":"MQ","slug":"MQ","permalink":"http://www.xc234.ltd/tags/MQ/"},{"name":"test","slug":"test","permalink":"http://www.xc234.ltd/tags/test/"},{"name":"本地","slug":"本地","permalink":"http://www.xc234.ltd/tags/%E6%9C%AC%E5%9C%B0/"},{"name":"图片","slug":"图片","permalink":"http://www.xc234.ltd/tags/%E5%9B%BE%E7%89%87/"},{"name":"Redis","slug":"Redis","permalink":"http://www.xc234.ltd/tags/Redis/"},{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://www.xc234.ltd/tags/SpringCloud/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://www.xc234.ltd/tags/SpringBoot/"},{"name":"MySql","slug":"MySql","permalink":"http://www.xc234.ltd/tags/MySql/"},{"name":"索引","slug":"索引","permalink":"http://www.xc234.ltd/tags/%E7%B4%A2%E5%BC%95/"},{"name":"java后端","slug":"java后端","permalink":"http://www.xc234.ltd/tags/java%E5%90%8E%E7%AB%AF/"}]}